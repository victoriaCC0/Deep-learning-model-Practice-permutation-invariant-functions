{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EsHyLeEZT-zC",
        "htQns9cbToua",
        "edarruSBWH5e",
        "6KqHLnojdxoh",
        "TgvB93CGsUp5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## P1-permutation-invariant functions\n",
        "\n"
      ],
      "metadata": {
        "id": "WHnHoENPUYdJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### P1.1 Implement the neural network"
      ],
      "metadata": {
        "id": "EsHyLeEZT-zC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PPmVOftcZXZE"
      },
      "outputs": [],
      "source": [
        "#P1.1 Implement the neural network \n",
        "# import all the setups\n",
        "# data preprocessing modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "\n",
        "# ML modules\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda, Activation, BatchNormalization, Concatenate\n",
        "# early stopping, callback, all the steps you are running you can ask the model to stop...\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# general stuff\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the data\n",
        "df1 = pd.read_csv('/content/train-1.csv', na_values=['NA','?'])\n",
        "df2 = pd.read_csv('/content/test-1.csv', na_values=['NA','?'])\n",
        "df1.head()\n",
        "#df2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "RXxfGtvJa0u3",
        "outputId": "3996c4fd-8252-4c0a-bbc2-bbfe4b49c65c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   4.431320074018723076e-01  5.324051314609411500e-01  \\\n",
              "0                  0.270151                  0.563418   \n",
              "1                  0.571161                  0.124119   \n",
              "2                  0.414595                  0.541134   \n",
              "3                  0.069221                  0.047482   \n",
              "4                  0.685363                  0.227652   \n",
              "\n",
              "   4.377698250476299568e-01  6.196628821722993674e-02  \\\n",
              "0                  0.136042                  0.164526   \n",
              "1                  0.826382                  0.692914   \n",
              "2                  0.383968                  0.696607   \n",
              "3                  0.269938                  0.812681   \n",
              "4                  0.694577                  0.806527   \n",
              "\n",
              "   7.836767313308944383e-01  9.357891820280233031e-01  \\\n",
              "0                  0.013159                  0.731077   \n",
              "1                  0.817431                  0.573339   \n",
              "2                  0.113355                  0.591044   \n",
              "3                  0.533125                  0.091919   \n",
              "4                  0.368828                  0.295510   \n",
              "\n",
              "   9.091042324650751016e-01  6.836156825808235027e-01  \\\n",
              "0                  0.961079                  0.202600   \n",
              "1                  0.248638                  0.632073   \n",
              "2                  0.770690                  0.016159   \n",
              "3                  0.581794                  0.854649   \n",
              "4                  0.633057                  0.680897   \n",
              "\n",
              "   8.954095712546213948e-01  8.711219633267553997e-01  \\\n",
              "0                  0.921334                  0.731678   \n",
              "1                  0.606688                  0.348984   \n",
              "2                  0.291561                  0.666265   \n",
              "3                  0.298028                  0.819031   \n",
              "4                  0.293867                  0.463691   \n",
              "\n",
              "   7.336462069558589150e-01  \n",
              "0                  0.416784  \n",
              "1                  0.590013  \n",
              "2                  0.477864  \n",
              "3                  0.415577  \n",
              "4                  0.548374  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d2210da-f74d-4f43-b91f-0ba432249393\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>4.431320074018723076e-01</th>\n",
              "      <th>5.324051314609411500e-01</th>\n",
              "      <th>4.377698250476299568e-01</th>\n",
              "      <th>6.196628821722993674e-02</th>\n",
              "      <th>7.836767313308944383e-01</th>\n",
              "      <th>9.357891820280233031e-01</th>\n",
              "      <th>9.091042324650751016e-01</th>\n",
              "      <th>6.836156825808235027e-01</th>\n",
              "      <th>8.954095712546213948e-01</th>\n",
              "      <th>8.711219633267553997e-01</th>\n",
              "      <th>7.336462069558589150e-01</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.270151</td>\n",
              "      <td>0.563418</td>\n",
              "      <td>0.136042</td>\n",
              "      <td>0.164526</td>\n",
              "      <td>0.013159</td>\n",
              "      <td>0.731077</td>\n",
              "      <td>0.961079</td>\n",
              "      <td>0.202600</td>\n",
              "      <td>0.921334</td>\n",
              "      <td>0.731678</td>\n",
              "      <td>0.416784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.571161</td>\n",
              "      <td>0.124119</td>\n",
              "      <td>0.826382</td>\n",
              "      <td>0.692914</td>\n",
              "      <td>0.817431</td>\n",
              "      <td>0.573339</td>\n",
              "      <td>0.248638</td>\n",
              "      <td>0.632073</td>\n",
              "      <td>0.606688</td>\n",
              "      <td>0.348984</td>\n",
              "      <td>0.590013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.414595</td>\n",
              "      <td>0.541134</td>\n",
              "      <td>0.383968</td>\n",
              "      <td>0.696607</td>\n",
              "      <td>0.113355</td>\n",
              "      <td>0.591044</td>\n",
              "      <td>0.770690</td>\n",
              "      <td>0.016159</td>\n",
              "      <td>0.291561</td>\n",
              "      <td>0.666265</td>\n",
              "      <td>0.477864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.069221</td>\n",
              "      <td>0.047482</td>\n",
              "      <td>0.269938</td>\n",
              "      <td>0.812681</td>\n",
              "      <td>0.533125</td>\n",
              "      <td>0.091919</td>\n",
              "      <td>0.581794</td>\n",
              "      <td>0.854649</td>\n",
              "      <td>0.298028</td>\n",
              "      <td>0.819031</td>\n",
              "      <td>0.415577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.685363</td>\n",
              "      <td>0.227652</td>\n",
              "      <td>0.694577</td>\n",
              "      <td>0.806527</td>\n",
              "      <td>0.368828</td>\n",
              "      <td>0.295510</td>\n",
              "      <td>0.633057</td>\n",
              "      <td>0.680897</td>\n",
              "      <td>0.293867</td>\n",
              "      <td>0.463691</td>\n",
              "      <td>0.548374</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d2210da-f74d-4f43-b91f-0ba432249393')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d2210da-f74d-4f43-b91f-0ba432249393 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d2210da-f74d-4f43-b91f-0ba432249393');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data pre-processing\n",
        "X_train, y_train =df1.values[:, :-1], df1.values[:,-1]\n",
        "X_train = X_train.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "X_test, y_test=df2.values[:,:-1], df2.values[:,-1]\n",
        "X_test = X_test.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ],
      "metadata": {
        "id": "lQXIaJmVjclw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f2d2b40-c18e-4a44-8d8f-b7820497649e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(99999, 10) (99999,) (9999, 10) (9999,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataframe into dataset\n",
        "df1.values"
      ],
      "metadata": {
        "id": "HPtbN3u3h3F6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061690f2-9019-47ff-eebd-cbb1fb7ca20d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.70150983e-01, 5.63417802e-01, 1.36042037e-01, ...,\n",
              "        9.21333864e-01, 7.31677663e-01, 4.16784392e-01],\n",
              "       [5.71160783e-01, 1.24119348e-01, 8.26382120e-01, ...,\n",
              "        6.06687932e-01, 3.48983787e-01, 5.90013251e-01],\n",
              "       [4.14594852e-01, 5.41134012e-01, 3.83967811e-01, ...,\n",
              "        2.91560663e-01, 6.66265219e-01, 4.77864432e-01],\n",
              "       ...,\n",
              "       [8.05508169e-01, 9.60400877e-02, 8.47611912e-02, ...,\n",
              "        3.37963557e-05, 7.61717979e-01, 6.54114232e-01],\n",
              "       [7.30580235e-01, 4.99809824e-01, 6.66627622e-01, ...,\n",
              "        2.48506610e-01, 2.94085649e-01, 5.58009757e-01],\n",
              "       [4.58422766e-01, 3.85119978e-01, 4.89044667e-01, ...,\n",
              "        2.90311216e-01, 1.07715687e-01, 4.51459151e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataframe into dataset\n",
        "df2.values"
      ],
      "metadata": {
        "id": "yC9eM0JKlOwU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b121ca-1ce4-4972-8e2e-bf50662b89d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16594335, 0.44725953, 0.72739992, ..., 0.9717372 , 0.99281504,\n",
              "        0.54315887],\n",
              "       [0.55572428, 0.81401591, 0.14254006, ..., 0.74194616, 0.48272871,\n",
              "        0.52908306],\n",
              "       [0.15756796, 0.98966006, 0.10968536, ..., 0.17456261, 0.8089604 ,\n",
              "        0.74888564],\n",
              "       ...,\n",
              "       [0.69131919, 0.19276581, 0.81484175, ..., 0.20484244, 0.88124685,\n",
              "        0.81736086],\n",
              "       [0.10588788, 0.53892315, 0.24139452, ..., 0.60686661, 0.94026094,\n",
              "        0.44583685],\n",
              "       [0.06029708, 0.67284363, 0.26760506, ..., 0.75767493, 0.90645153,\n",
              "        0.6120033 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine the number of input features\n",
        "n_features = X_train.shape[1]\n",
        "n_features"
      ],
      "metadata": {
        "id": "elysm-4fljM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58a4e36-861e-4bb4-ef7f-fabbba2b216e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set the optimizer with the learning rate of 1e-4\n",
        "optimizer1 =SGD(learning_rate=1e-4)\n",
        "#compile the first model with loss MSE and metrics ACC\n",
        "combined_model.compile(loss='MSE',optimizer=optimizer1,  metrics=['acc'])\n",
        "#train the model of validation split 0.1 and batch size of 128\n",
        "history = combined_model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=2, validation_split=0.1)\n"
      ],
      "metadata": {
        "id": "baGrXg1RrLYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0280d9-cc19-456f-9930-459d62a66699"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "704/704 - 3s - loss: 0.1916 - acc: 0.0000e+00 - val_loss: 0.1512 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 2/10\n",
            "704/704 - 2s - loss: 0.1237 - acc: 0.0000e+00 - val_loss: 0.0982 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "704/704 - 2s - loss: 0.0813 - acc: 0.0000e+00 - val_loss: 0.0654 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 4/10\n",
            "704/704 - 1s - loss: 0.0552 - acc: 0.0000e+00 - val_loss: 0.0455 - val_acc: 0.0000e+00 - 1s/epoch - 2ms/step\n",
            "Epoch 5/10\n",
            "704/704 - 2s - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 6/10\n",
            "704/704 - 2s - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 7/10\n",
            "704/704 - 1s - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0225 - val_acc: 0.0000e+00 - 1s/epoch - 2ms/step\n",
            "Epoch 8/10\n",
            "704/704 - 1s - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0000e+00 - 1s/epoch - 2ms/step\n",
            "Epoch 9/10\n",
            "704/704 - 2s - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 10/10\n",
            "704/704 - 3s - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0180 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### P1.2 training the model with lat_dim=5 and 100"
      ],
      "metadata": {
        "id": "htQns9cbToua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# P1.2 train the model with lat_dim = 5 for 10 epochs\n",
        "\n",
        "#build the first function\n",
        "# define lat_dim\n",
        "lat_dim = 5\n",
        "\n",
        "model_1 = Sequential(name='function1')\n",
        "model_1.add(Dense(100, activation='relu', input_shape=(n_features,)))\n",
        "model_1.add(Dense(lat_dim, activation='softmax'))\n",
        "\n",
        "#function2\n",
        "model_2 = Sequential(name='function2')\n",
        "model_2.add(Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=True), input_shape=(lat_dim,)))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(1))\n",
        "\n",
        "\n",
        "# Combined model\n",
        "combined_input = Input(shape=model_1.input_shape[1:])\n",
        "\n",
        "model_1out = model_1(combined_input)\n",
        "model_2out = model_2(model_1out)\n",
        "\n",
        "combined_output = Concatenate()([model_1out, model_2out])\n",
        "combined_output = Dense(1)(combined_output)\n",
        "combined_model = keras.Model(inputs=combined_input, outputs=combined_output)\n",
        "\n",
        "combined_model.summary()\n",
        "\n",
        "optimizer1 =SGD(learning_rate=1e-4)\n",
        "combined_model.compile(loss='MSE',optimizer=optimizer1,  metrics=['acc'])\n",
        "history = combined_model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=2, validation_split=0.1)\n",
        "\n",
        "#Show the training and validation loss versus the number of epochs. \n",
        "# Getting necessary data for plotting\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting training and validation loss\n",
        "# \"b\" is for \"solid blue line\"\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.xscale(value='log')\n",
        "#plt.yscale(value='log')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Show also the test MSE value. \n",
        "# Model evaluation\n",
        "loss = combined_model.evaluate(X_test, y_test)\n",
        "# RMSE error. \n",
        "pred = combined_model.predict(X_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
        "print(f\"Final score (RMSE)for lat_latdim=5: {score}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QmNjO0Y8R-tZ",
        "outputId": "42958c53-3a6f-48ef-9557-e8724447aa8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"function1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 100)               1100      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 5)                 505       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,605\n",
            "Trainable params: 1,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"function2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lambda_2 (Lambda)           (None, 1)                 0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 100)               200       \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 301\n",
            "Trainable params: 301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 5)            1605        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 6)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 1)            7           ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,913\n",
            "Trainable params: 1,913\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "704/704 - 5s - loss: 0.1721 - acc: 0.0000e+00 - val_loss: 0.1037 - val_acc: 0.0000e+00 - 5s/epoch - 8ms/step\n",
            "Epoch 2/10\n",
            "704/704 - 2s - loss: 0.0713 - acc: 0.0000e+00 - val_loss: 0.0471 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "704/704 - 2s - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 4/10\n",
            "704/704 - 4s - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0216 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 5/10\n",
            "704/704 - 5s - loss: 0.0206 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0000e+00 - 5s/epoch - 7ms/step\n",
            "Epoch 6/10\n",
            "704/704 - 2s - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 8/10\n",
            "704/704 - 2s - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "704/704 - 4s - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 10/10\n",
            "704/704 - 2s - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0189 - acc: 0.0000e+00\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Final score (RMSE)for lat_latdim=5: 0.13731986284255981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Repeat this but by taking lat_dim = 100. Discuss the obtained results.\n",
        "lat_dim = 100\n",
        "model_1 = Sequential(name='function1')\n",
        "model_1.add(Dense(100, activation='relu', input_shape=(n_features,)))\n",
        "model_1.add(Dense(lat_dim, activation='softmax'))\n",
        "\n",
        "#function2\n",
        "model_2 = Sequential(name='function2')\n",
        "model_2.add(Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=True), input_shape=(lat_dim,)))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(1))\n",
        "\n",
        "\n",
        "# Combined model\n",
        "combined_input = Input(shape=model_1.input_shape[1:])\n",
        "\n",
        "model_1out = model_1(combined_input)\n",
        "model_2out = model_2(model_1out)\n",
        "\n",
        "combined_output = Concatenate()([model_1out, model_2out])\n",
        "combined_output = Dense(1)(combined_output)\n",
        "combined_model = keras.Model(inputs=combined_input, outputs=combined_output)\n",
        "\n",
        "combined_model.summary()\n",
        "\n",
        "optimizer1 =SGD(learning_rate=1e-4)\n",
        "combined_model.compile(loss='MSE',optimizer=optimizer1,  metrics=['acc'])\n",
        "history = combined_model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=2, validation_split=0.1)\n",
        "\n",
        "#Show the training and validation loss versus the number of epochs. \n",
        "# Getting necessary data for plotting\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting training and validation loss\n",
        "# \"b\" is for \"solid blue line\"\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.xscale(value='log')\n",
        "#plt.yscale(value='log')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Show also the test MSE value. \n",
        "# Model evaluation\n",
        "loss = combined_model.evaluate(X_test, y_test)\n",
        "# RMSE error. \n",
        "pred = combined_model.predict(X_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
        "print(f\"Final score (RMSE)for lat_latdim=100: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8tAwekopS6l1",
        "outputId": "bfaa68a7-0e92-42c4-c697-f4a4eb955edf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 1)            102         ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "704/704 - 3s - loss: 0.1953 - acc: 0.0000e+00 - val_loss: 0.1646 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 2/10\n",
            "704/704 - 2s - loss: 0.1420 - acc: 0.0000e+00 - val_loss: 0.1201 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "704/704 - 3s - loss: 0.1042 - acc: 0.0000e+00 - val_loss: 0.0886 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 4/10\n",
            "704/704 - 2s - loss: 0.0775 - acc: 0.0000e+00 - val_loss: 0.0665 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "704/704 - 2s - loss: 0.0588 - acc: 0.0000e+00 - val_loss: 0.0510 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "704/704 - 2s - loss: 0.0458 - acc: 0.0000e+00 - val_loss: 0.0403 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 7/10\n",
            "704/704 - 2s - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 8/10\n",
            "704/704 - 2s - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0282 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 9/10\n",
            "704/704 - 3s - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 10/10\n",
            "704/704 - 3s - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0228 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0232 - acc: 0.0000e+00\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Final score (RMSE)for lat_latdim=100: 0.1523183435201645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment on using different lat_dim:\n",
        "\n",
        "For _lat_dim_ 100, the training loss and validation loss are convergent after 3 epochs while _lat_dim_ 5 convergences after 9 epochs.\n",
        "\n",
        "In terms of the MSE, _lat_dim_ 5 has less loss than _lat_dim_ 100"
      ],
      "metadata": {
        "id": "SE0IUP05UQTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### P1.3 Train the neural network with lat_dim = 100 with different learning rate of 0.01, 0.1 and 0.5"
      ],
      "metadata": {
        "id": "edarruSBWH5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lat_dim=100 with learing rate of 0.01\n",
        "lat_dim = 100\n",
        "model_1 = Sequential(name='function1')\n",
        "model_1.add(Dense(100, activation='relu', input_shape=(n_features,)))\n",
        "model_1.add(Dense(lat_dim, activation='softmax'))\n",
        "\n",
        "#function2\n",
        "model_2 = Sequential(name='function2')\n",
        "model_2.add(Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=True), input_shape=(lat_dim,)))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(1))\n",
        "\n",
        "\n",
        "# Combined model\n",
        "combined_input = Input(shape=model_1.input_shape[1:])\n",
        "\n",
        "model_1out = model_1(combined_input)\n",
        "model_2out = model_2(model_1out)\n",
        "\n",
        "combined_output = Concatenate()([model_1out, model_2out])\n",
        "combined_output = Dense(1)(combined_output)\n",
        "combined_model = keras.Model(inputs=combined_input, outputs=combined_output)\n",
        "\n",
        "combined_model.summary()\n",
        "\n",
        "optimizer1 =SGD(learning_rate=0.01)\n",
        "combined_model.compile(loss='MSE',optimizer=optimizer1,  metrics=['acc'])\n",
        "history = combined_model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=2, validation_split=0.1)\n",
        "\n",
        "#Show the training and validation loss versus the number of epochs. \n",
        "# Getting necessary data for plotting\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting training and validation loss\n",
        "# \"b\" is for \"solid blue line\"\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.xscale(value='log')\n",
        "#plt.yscale(value='log')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Show also the test MSE value. \n",
        "# Model evaluation\n",
        "loss = combined_model.evaluate(X_test, y_test)\n",
        "# RMSE error. \n",
        "pred = combined_model.predict(X_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
        "print(f\"Final score (RMSE)for lat_latdim=5: {score}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YNZ-0DIfWbaB",
        "outputId": "ccb36b16-33cd-4694-86df-d82fbed978af"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 1)            102         ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "704/704 - 4s - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 2/10\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 4/10\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 5/10\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 6/10\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "704/704 - 3s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 8/10\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "704/704 - 2s - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0190 - acc: 0.0000e+00\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Final score (RMSE)for lat_latdim=5: 0.13787081837654114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lat_dim=100 with learing rate of 0.1\n",
        "lat_dim = 100\n",
        "model_1 = Sequential(name='function1')\n",
        "model_1.add(Dense(100, activation='relu', input_shape=(n_features,)))\n",
        "model_1.add(Dense(lat_dim, activation='softmax'))\n",
        "\n",
        "#function2\n",
        "model_2 = Sequential(name='function2')\n",
        "model_2.add(Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=True), input_shape=(lat_dim,)))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(1))\n",
        "\n",
        "\n",
        "# Combined model\n",
        "combined_input = Input(shape=model_1.input_shape[1:])\n",
        "\n",
        "model_1out = model_1(combined_input)\n",
        "model_2out = model_2(model_1out)\n",
        "\n",
        "combined_output = Concatenate()([model_1out, model_2out])\n",
        "combined_output = Dense(1)(combined_output)\n",
        "combined_model = keras.Model(inputs=combined_input, outputs=combined_output)\n",
        "\n",
        "combined_model.summary()\n",
        "\n",
        "optimizer1 =SGD(learning_rate=0.1)\n",
        "combined_model.compile(loss='MSE',optimizer=optimizer1,  metrics=['acc'])\n",
        "history = combined_model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=2, validation_split=0.1)\n",
        "\n",
        "#Show the training and validation loss versus the number of epochs. \n",
        "# Getting necessary data for plotting\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting training and validation loss\n",
        "# \"b\" is for \"solid blue line\"\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.xscale(value='log')\n",
        "#plt.yscale(value='log')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Show also the test MSE value. \n",
        "# Model evaluation\n",
        "loss = combined_model.evaluate(X_test, y_test)\n",
        "# RMSE error. \n",
        "pred = combined_model.predict(X_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
        "print(f\"Final score (RMSE)for lat_latdim=5: {score}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GF8UZRToYhqI",
        "outputId": "a036a789-6948-464e-9bc7-61d39632fed2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_35 (Dense)               (None, 1)            102         ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "704/704 - 4s - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "Epoch 2/10\n",
            "704/704 - 2s - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "704/704 - 2s - loss: 0.0187 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 4/10\n",
            "704/704 - 3s - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0184 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 5/10\n",
            "704/704 - 2s - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 6/10\n",
            "704/704 - 2s - loss: 0.0182 - acc: 0.0000e+00 - val_loss: 0.0179 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 7/10\n",
            "704/704 - 2s - loss: 0.0177 - acc: 0.0000e+00 - val_loss: 0.0175 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "704/704 - 2s - loss: 0.0167 - acc: 0.0000e+00 - val_loss: 0.0152 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 9/10\n",
            "704/704 - 2s - loss: 0.0079 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 10/10\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0036 - acc: 0.0000e+00\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Final score (RMSE)for lat_latdim=5: 0.059691786766052246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lat_dim=100 with learing rate of 0.5\n",
        "lat_dim = 100\n",
        "model_1 = Sequential(name='function1')\n",
        "model_1.add(Dense(100, activation='relu', input_shape=(n_features,)))\n",
        "model_1.add(Dense(lat_dim, activation='softmax'))\n",
        "\n",
        "#function2\n",
        "model_2 = Sequential(name='function2')\n",
        "model_2.add(Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=True), input_shape=(lat_dim,)))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(1))\n",
        "\n",
        "\n",
        "# Combined model\n",
        "combined_input = Input(shape=model_1.input_shape[1:])\n",
        "\n",
        "model_1out = model_1(combined_input)\n",
        "model_2out = model_2(model_1out)\n",
        "\n",
        "combined_output = Concatenate()([model_1out, model_2out])\n",
        "combined_output = Dense(1)(combined_output)\n",
        "combined_model = keras.Model(inputs=combined_input, outputs=combined_output)\n",
        "\n",
        "combined_model.summary()\n",
        "\n",
        "optimizer1 =SGD(learning_rate=0.5)\n",
        "combined_model.compile(loss='MSE',optimizer=optimizer1,  metrics=['acc'])\n",
        "history = combined_model.fit(X_train, y_train, batch_size=128, epochs=10, verbose=2, validation_split=0.1)\n",
        "\n",
        "#Show the training and validation loss versus the number of epochs. \n",
        "# Getting necessary data for plotting\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting training and validation loss\n",
        "# \"b\" is for \"solid blue line\"\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.xscale(value='log')\n",
        "#plt.yscale(value='log')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Show also the test MSE value. \n",
        "# Model evaluation\n",
        "loss = combined_model.evaluate(X_test, y_test)\n",
        "# RMSE error. \n",
        "pred = combined_model.predict(X_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
        "print(f\"Final score (RMSE)for lat_latdim=5: {score}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2UiFeXRlYkpv",
        "outputId": "ca861599-4763-45e5-b28d-44669f068145"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_40 (Dense)               (None, 1)            102         ['concatenate_7[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "704/704 - 3s - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 2/10\n",
            "704/704 - 2s - loss: 0.0151 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 3/10\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0061 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 4/10\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 6/10\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0062 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 7/10\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 8/10\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 9/10\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 10/10\n",
            "704/704 - 3s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0040 - acc: 0.0000e+00\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Final score (RMSE)for lat_latdim=5: 0.0633251816034317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: \n",
        "\n",
        "- For the learning rate of 0.01 and 0.5, there are some fluction of the validation loss, but all in all it is convergent\n",
        "\n",
        "- For the learning rate of 0.1 , it is convergent but both of them fall dramatically"
      ],
      "metadata": {
        "id": "4uVNzco9cKMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### P1.4 Train the neural network with lat_dim = 100 for 50 epochs with ReLU and sigmoid functions"
      ],
      "metadata": {
        "id": "6KqHLnojdxoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lat_dim=100 with 50 epoches with ReLu activation\n",
        "lat_dim = 100\n",
        "\n",
        "model_1 = Sequential(name='function1')\n",
        "model_1.add(Dense(100, activation='relu', input_shape=(n_features,)))\n",
        "model_1.add(Dense(lat_dim, activation='softmax'))\n",
        "\n",
        "#function2\n",
        "model_2 = Sequential(name='function2')\n",
        "model_2.add(Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=True), input_shape=(lat_dim,)))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(1))\n",
        "\n",
        "\n",
        "# Combined model\n",
        "combined_input = Input(shape=model_1.input_shape[1:])\n",
        "\n",
        "model_1out = model_1(combined_input)\n",
        "model_2out = model_2(model_1out)\n",
        "\n",
        "combined_output = Concatenate()([model_1out, model_2out])\n",
        "combined_output = Dense(1)(combined_output)\n",
        "combined_model = keras.Model(inputs=combined_input, outputs=combined_output)\n",
        "\n",
        "combined_model.summary()\n",
        "\n",
        "\n",
        "optimizer1 =SGD(learning_rate=1e-4)\n",
        "combined_model.compile(loss='MSE',optimizer=optimizer1,  metrics=['acc'])\n",
        "history = combined_model.fit(X_train, y_train, batch_size=128, epochs=50, verbose=2, validation_split=0.1)\n",
        "\n",
        "#Show the training and validation loss versus the number of epochs. \n",
        "# Getting necessary data for plotting\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting training and validation loss\n",
        "# \"b\" is for \"solid blue line\"\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.xscale(value='log')\n",
        "#plt.yscale(value='log')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Show also the test MSE value. \n",
        "# Model evaluation\n",
        "loss = combined_model.evaluate(X_test, y_test)\n",
        "# RMSE error. \n",
        "pred = combined_model.predict(X_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
        "print(f\"Final score (RMSE)for lat_latdim=5: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WJZ-iOl_d7JL",
        "outputId": "5ea9d139-917b-4a9a-f04a-2faa640e69ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_9[0][0]']                \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_45 (Dense)               (None, 1)            102         ['concatenate_8[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "704/704 - 4s - loss: 0.2280 - acc: 0.0000e+00 - val_loss: 0.1984 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 2/50\n",
            "704/704 - 2s - loss: 0.1759 - acc: 0.0000e+00 - val_loss: 0.1536 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 3/50\n",
            "704/704 - 2s - loss: 0.1369 - acc: 0.0000e+00 - val_loss: 0.1200 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 4/50\n",
            "704/704 - 2s - loss: 0.1075 - acc: 0.0000e+00 - val_loss: 0.0948 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "704/704 - 2s - loss: 0.0855 - acc: 0.0000e+00 - val_loss: 0.0758 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "704/704 - 4s - loss: 0.0690 - acc: 0.0000e+00 - val_loss: 0.0616 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 7/50\n",
            "704/704 - 2s - loss: 0.0565 - acc: 0.0000e+00 - val_loss: 0.0509 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 8/50\n",
            "704/704 - 2s - loss: 0.0472 - acc: 0.0000e+00 - val_loss: 0.0429 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 9/50\n",
            "704/704 - 2s - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 10/50\n",
            "704/704 - 2s - loss: 0.0349 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 11/50\n",
            "704/704 - 2s - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 12/50\n",
            "704/704 - 2s - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0265 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 13/50\n",
            "704/704 - 2s - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 14/50\n",
            "704/704 - 2s - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 15/50\n",
            "704/704 - 2s - loss: 0.0228 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 16/50\n",
            "704/704 - 2s - loss: 0.0218 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 17/50\n",
            "704/704 - 2s - loss: 0.0211 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 18/50\n",
            "704/704 - 2s - loss: 0.0205 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "704/704 - 3s - loss: 0.0201 - acc: 0.0000e+00 - val_loss: 0.0198 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 20/50\n",
            "704/704 - 2s - loss: 0.0198 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "704/704 - 2s - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 22/50\n",
            "704/704 - 2s - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0193 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 23/50\n",
            "704/704 - 2s - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0192 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 24/50\n",
            "704/704 - 2s - loss: 0.0192 - acc: 0.0000e+00 - val_loss: 0.0191 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 25/50\n",
            "704/704 - 2s - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 26/50\n",
            "704/704 - 2s - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 27/50\n",
            "704/704 - 2s - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 28/50\n",
            "704/704 - 2s - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 29/50\n",
            "704/704 - 2s - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 30/50\n",
            "704/704 - 2s - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 31/50\n",
            "704/704 - 2s - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 32/50\n",
            "704/704 - 3s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "Epoch 33/50\n",
            "704/704 - 3s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 35/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 36/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 37/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 38/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 39/50\n",
            "704/704 - 3s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 40/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 41/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 42/50\n",
            "704/704 - 3s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 43/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 44/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 45/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 46/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 47/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 48/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 49/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 50/50\n",
            "704/704 - 2s - loss: 0.0189 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwb0lEQVR4nO3dd3xUZb7H8c8vjdCroAKaoPSW0BHFiLqiUixYuK6CuhbWte+6dri4bpPd69Wrd+26roquhYuCjRKxC6KiIAoiKIiNllDTfvePcxKHmJAQMpkk832/Xuc1c54558zvGcL85jzPc55j7o6IiEhpCbEOQEREaiclCBERKZMShIiIlEkJQkREyqQEISIiZVKCEBGRMilBSI0wsxfNbEJ1bxtLZrbazI6JwnHdzA4Nn//DzG6qzLZVeJ+zzOyVqsa5h+Nmmdna6j6u1LykWAcgtZeZbY1YbQTsAgrD9Yvc/bHKHsvdj4/GtvWdu19cHccxszTgSyDZ3QvCYz8GVPrfUOKPEoSUy92bFD83s9XAr9x9TuntzCyp+EtHROoPNTHJXituQjCz35vZt8BDZtbSzF4wsx/MbFP4vEPEPtlm9qvw+UQze8PMpoXbfmlmx1dx23QzW2BmuWY2x8zuMrN/lRN3ZWK8xczeDI/3ipm1iXj9bDNbY2YbzOyGPXw+g83sWzNLjCg72cyWhM8HmdnbZrbZzNab2f+YWUo5x3rYzP4Qsf67cJ9vzOy8UtueaGYfmFmOmX1tZlMiXl4QPm42s61mNrT4s43Y/zAzW2hmW8LHwyr72eyJmXUP999sZkvNbEzEayeY2bLwmOvM7LdheZvw32ezmW00s9fNTN9XNUwfuFTV/kAr4GDgQoK/pYfC9YOAHcD/7GH/wcBnQBvgr8ADZmZV2PZx4D2gNTAFOHsP71mZGP8DOBdoC6QAxV9YPYD/DY9/YPh+HSiDu78LbANGlDru4+HzQuDKsD5DgaOBX+8hbsIYRobxHAt0Bkr3f2wDzgFaACcCk8zspPC14eFjC3dv4u5vlzp2K2AWcEdYt78Ds8ysdak6/OyzqSDmZOB54JVwv0uBx8ysa7jJAwTNlU2BXsC8sPxqYC2wH9AOuB7QvEA1TAlCqqoImOzuu9x9h7tvcPdn3H27u+cCtwJH7mH/Ne5+n7sXAo8ABxB8EVR6WzM7CBgI3Ozuee7+BjCzvDesZIwPufvn7r4DeArICMvHAS+4+wJ33wXcFH4G5XkCGA9gZk2BE8Iy3P19d3/H3QvcfTVwTxlxlOX0ML5P3H0bQUKMrF+2u3/s7kXuviR8v8ocF4KEssLdHw3jegJYDoyO2Ka8z2ZPhgBNgD+H/0bzgBcIPxsgH+hhZs3cfZO7L44oPwA42N3z3f1118RxNU4JQqrqB3ffWbxiZo3M7J6wCSaHoEmjRWQzSynfFj9x9+3h0yZ7ue2BwMaIMoCvywu4kjF+G/F8e0RMB0YeO/yC3lDeexGcLZxiZg2AU4DF7r4mjKNL2HzybRjHHwnOJiqyWwzAmlL1G2xm88MmtC3AxZU8bvGx15QqWwO0j1gv77OpMGZ3j0ymkcc9lSB5rjGz18xsaFh+G7ASeMXMVpnZtZWrhlQnJQipqtK/5q4GugKD3b0ZPzVplNdsVB3WA63MrFFEWcc9bL8vMa6PPHb4nq3L29jdlxF8ER7P7s1LEDRVLQc6h3FcX5UYCJrJIj1OcAbV0d2bA/+IOG5Fv76/IWh6i3QQsK4ScVV03I6l+g9KjuvuC919LEHz0wyCMxPcPdfdr3b3TsAY4CozO3ofY5G9pAQh1aUpQZv+5rA9e3K03zD8Rb4ImGJmKeGvz9F72GVfYnwaGGVmh4cdylOp+P/P48DlBIno36XiyAG2mlk3YFIlY3gKmGhmPcIEVTr+pgRnVDvNbBBBYir2A0GTWKdyjj0b6GJm/2FmSWZ2BtCDoDloX7xLcLZxjZklm1kWwb/R9PDf7Cwza+7u+QSfSRGAmY0ys0PDvqYtBP02e2rSkyhQgpDqcjvQEPgReAd4qYbe9yyCjt4NwB+AJwmu1yjL7VQxRndfClxC8KW/HthE0Im6J8V9APPc/ceI8t8SfHnnAveFMVcmhhfDOswjaH6ZV2qTXwNTzSwXuJnw13i473aCPpc3w5FBQ0odewMwiuAsawNwDTCqVNx7zd3zCBLC8QSf+93AOe6+PNzkbGB12NR2McG/JwSd8HOArcDbwN3uPn9fYpG9Z+r3kfrEzJ4Elrt71M9gROo7nUFInWZmA83sEDNLCIeBjiVoyxaRfaQrqaWu2x94lqDDeC0wyd0/iG1IIvWDmphERKRMamISEZEy1ZsmpjZt2nhaWtoet9m2bRuNGzeumYBqmXitu+odX1Tvvff+++//6O77lfVavUkQaWlpLFq0aI/bZGdnk5WVVTMB1TLxWnfVO76o3nvPzEpfQV9CTUwiIlImJQgRESmTEoSIiJSp3vRBiEjNy8/PZ+3atezcubPijWtA8+bN+fTTT2MdRo2rTL1TU1Pp0KEDycnJlT6uEoSIVNnatWtp2rQpaWlplH+/p5qTm5tL06ZNYx1Gjauo3u7Ohg0bWLt2Lenp6ZU+rpqYRKTKdu7cSevWrWtFcpDymRmtW7fe6zM9JQgR2SdKDnVDVf6d4j5BbN4MU6fCwoWxjkREpHaJ+wRhBpMnw2uvxToSEdlbGzZsICMjg4yMDPbff3+6du1asp6Xl7fHfRctWsRll11W4Xscdthh1RJrdnY2o0aNqpZj1ZS476Ru3hxatoTVq2MdiYjsrdatW/Phhx8CMGXKFJKTk7nhhhtKXi8oKCApqeyvuQEDBjBgwIAK3+Ott96qlljrorg/gwBIS4Mvv4x1FCJSHSZOnMjFF1/M4MGDueaaa3jvvfcYOnQomZmZHHbYYXz22WfA7r/op0yZwnnnnUdWVhadOnXijjvuKDlekyZNSrbPyspi3LhxdOvWjbPOOovi2bBnz55Nt27d6N+/P5dddlmFZwobN27kpJNOok+fPgwZMoQlS5YA8Nprr5WcAWVmZpKbm8v69esZPnw4GRkZ9OrVi9dff73aP7PyxP0ZBEB6OixfXvF2IlK+K66A8Md8tcnIgNtv3/v91q5dy1tvvUViYiI5OTm8/vrrJCUlMWfOHK6//nqeeeaZn+2zfPly5s+fT25uLl27dmXSpEk/u2bggw8+YOnSpRx44IEMGzaMN998kwEDBnDRRRexYMEC0tPTGT9+fIXxTZ48mczMTGbMmMG8efM455xz+PDDD5k2bRp33XUXw4YNY+vWraSmpnLvvfdy3HHHccMNN1BYWMj27dv3/gOpIiUIgjOIl14C96BPQkTqttNOO43ExEQAtmzZwoQJE1ixYgVmRn5+fpn7nHjiiTRo0IAGDRrQtm1bvvvuOzp06LDbNoMGDSopy8jIYPXq1TRp0oROnTqVXF8wfvx47r333j3G98Ybb5QkqREjRrBhwwZycnIYNmwYV111FWeddRannHIKHTp0YODAgZx33nnk5+dz0kknkZGRsS8fzV5RgiBIENu3ww8/QNu2sY5GpG6qyi/9aImc+vqmm27iqKOO4rnnnmP16tXlznraoEGDkueJiYkUFBRUaZt9ce2113LiiScye/Zshg0bxssvv8zw4cNZsGABs2bNYuLEiVx11VWcc8451fq+5VEfBEGCAHVUi9RHW7ZsoX379gA8/PDD1X78rl27smrVKlaHXyBPPvlkhfscccQRPPbYY0DQt9GmTRuaNWvGF198Qe/evfn973/PwIEDWb58OWvWrKFdu3ZccMEF/OpXv2Lx4sXVXofyKEEQ9EGAEoRIfXTNNddw3XXXkZmZWe2/+AEaNmzI3XffzciRI+nfvz9NmzalefPme9xnypQpvP/++/Tp04drr72WRx55BIDbb7+dXr160adPH5KTkzn++OPJzs6mb9++ZGZm8uSTT3L55ZdXex3K5e71Yunfv79XZP78+WWW5+S4g/uf/1zhIeqs8upe36ne0bVs2bIaeZ/KysnJicn75ubmurt7UVGRT5o0yf/+97/X6PtXtt5l/XsBi7yc71WdQQBNm0Lr1jqDEJGque+++8jIyKBnz55s2bKFiy66KNYhVQt1UofS05UgRKRqrrzySq688spYh1HtdAYR0sVyIiK7U4IIpaXBmjXBtRAiIqIEUSI9HXbuhO++i3UkIiK1gxJEqPhaCDUziYgElCBCulhOpO456qijePnll3cru/3225k0aVK5+2RlZbFo0SIATjjhBDZv3vyzbaZMmcK0adP2+N4zZsxg2bJlJes333wzc+bM2Yvoy1abpgVXgggpQYjUPePHj2f69Om7lU2fPr1SE+ZBMAtrixYtqvTepRPE1KlTOeaYY6p0rNpKCSLUqFEwD5OamETqjnHjxjFr1qySmwOtWbOGb775hiOOOIJJkyYxYMAAevbsyeTJk8vcPy0tjR9//BGAW2+9lS5dunD44YeXTAkOwTUOAwcOpG/fvpx66qls376dt956i5kzZ/K73/2OjIwMvvjiCyZOnMjTTz8NwNy5c8nMzKR3796cd9557Nq1q+T9Jk+eTL9+/ejduzfLK5hGOtbTgus6iAhpaTqDEKmyGMz33apVKwYNGsSLL77I2LFjeeaZZzj99NMxM2699VZatWpFYWEhRx99NEuWLKFPnz5lHuf9999n+vTpfPjhhxQUFNCvXz/69+8PwCmnnMIFF1wAwI033sgDDzzApZdeypgxYxg1ahTjxo3b7Vg7d+5k4sSJzJ07ly5dunDOOefwv//7v1xxxRUAtGnThsWLF3P33Xczbdo07r///nLrV9lpwfPz83nwwQerfVpwnUFEUIIQqXsim5meeeaZkualp556in79+pGZmcnSpUt3aw4q7fXXX+fkk0+mUaNGNGvWjDFjxpS89sknn3DEEUfQu3dvHnvsMZYuXbrHeD777DPS09Pp0qULABMmTGDBggUlr59yyikA9O/fv2SCv/K88cYbnH322UDZ04LfcccdbN68maSkJAYOHMhDDz3ElClT+Pjjj2natOkej10ZOoOIkJ4OM2ZAUREkKHWK7J0Yzfc9duxYrrzyShYvXsz27dvp378/X375JdOmTWPhwoW0bNmSiRMnsnPnziodf+LEicyYMYO+ffvy8MMPk52dvU/xFk8Zvi/ThZeeFvzZZ5+NyrTg+hqMkJYGeXmwfn2sIxGRymrSpAlHHXUU5513XklzT05ODo0bN6Z58+Z89913vPjii3s8xvDhw5kxYwY7duwgNzeX559/vuS13NxcDjjgAPLz80um6AZo2rQpubm5PztW165dWb16NStXrgTg0Ucf5cgjj6xS3So7Lfjnn38elWnBdQYRIXIkUzh9vIjUAePHj+fkk0/mgQceACiZHrtbt2507NiRYcOG7XH/fv36ccYZZ9C3b1/atm3LwIEDS1675ZZbGDx4MPvttx+DBw8uSQpnnnkmF1xwAXfccUdJ5zRAamoqDz30EKeddhoFBQUMHDiQiy++uEr1Kr5Xdp8+fWjUqNFu04LPnz+fhIQEevbsybHHHsusWbO47bbbSE5OpkmTJvzzn/+s0nvuprxpXuvasi/TfRdbvjyY9vvRRys8VJ2jaa/ji6b7ji91crpvMxtpZp+Z2Uozu7aM168ys2VmtsTM5prZwRGvTTCzFeEyIZpxFjvooOBRHdUiIlHsgzCzROAu4HigBzDezHqU2uwDYIC79wGeBv4a7tsKmAwMBgYBk82sZbRiLdawIey/vxKEiAhEt5N6ELDS3Ve5ex4wHRgbuYG7z3f34sG67wAdwufHAa+6+0Z33wS8CoyMYqwl0tN1sZzI3nBNgVwnVOXfKZqd1O2BryPW1xKcEZTnfKB4qEFZ+/6s29jMLgQuBGjXrl2Fw8+2bt36s22Stm6l/XPPsXHQIHK7dqVhw+4sX96M7Ox393isuqasuscD1Tu6mjRpwtq1a2nevDlmFvX3q0hhYWGZI4vqu4rq7e5s2bKFbdu27dXfRa0YxWRmvwQGAHs1Fszd7wXuBRgwYIBnZWXtcfvs7Gx+ts2WLTB6NOldu0JWFq+8AgsWwBFHZJGYuDfR1G5l1j0OqN7RlZ+fz9q1a1m3bl3U36sydu7cSWpqaqzDqHGVqXdqaip9+/YlOTm50seNZoJYB3SMWO8Qlu3GzI4BbgCOdPddEftmldo3OypRNm8eTML0+edA0MRUUADr1v3UaS0iZUtOTiY9PT3WYZTIzs4mMzMz1mHUuGjVO5p9EAuBzmaWbmYpwJnAzMgNzCwTuAcY4+7fR7z0MvALM2sZdk7/IiyLji5dYMUKQLO6iogUi1qCcPcC4DcEX+yfAk+5+1Izm2pmxROd3AY0Af5tZh+a2cxw343ALQRJZiEwNSyLjs6dS84glCBERAJR7YNw99nA7FJlN0c8L3fydHd/EHgwetFF6NIFHnoIcnM56KCmmGkkk4iI5mKC4AwCYMUKGjSAAw/UGYSIiBIEBGcQsFszkxKEiMQ7JQiAQw4JHiM6qtXEJCLxTgkCgvuNduy421DXtWuD4a4iIvFKCaJYqaGuhYVBkhARiVdKEMU01FVEZDdKEMW6dIFNm2DDBoovDFU/hIjEMyWIYsVDXT//nA4dgntS6wxCROKZEkSxiKGuKSnBLUeVIEQknilBFEtPh8TEko5q3RdCROKdEkSx5OQgK+hiORERQAlid6WGuq5bB3l5sQ1JRCRWlCAide4cJAh30tKgqAi+/rrCvURE6iUliEhdusC2bbB+fclQVzUziUi8UoKIFDHUVRfLiUi8U4KIFDHUtUOHYFCTRjKJSLxSgojUsSM0aAArVpCUFNyT+osvYh2UiEhsKEFESkiAQw8tGeravTssWxbjmEREYkQJorSIoa49e8Ly5Zr2W0TikxJEaZ07w8qVUFhIz57BdRBqZhKReKQEUVqXLpCfD2vW0LNnULR0aWxDEhGJBSWI0oqHuq5YQffuwdNPPoldOCIisaIEUVrEUNfGjYPpmXQGISLxSAmitHbtoEmT3TqqlSBEJB4pQZRmFpxFhENde/YMnubnxzguEZEapgRRloihrr16BckhXBURiRtKEGXp3DmYhGnXLo1kEpG4pQRRli5dgrm+V62iW7fgAmslCBGJN0oQZYkY6tqwIXTqpAQhIvFHCaIsEdN+g0YyiUh8UoIoS6tW0Lr1bkNdV6zQ7UdFJL4oQZSn1FDXgoKSVRGRuKAEUZ5Ss7qCmplEJL4oQZSnc2dYtw62bqVrV41kEpH4owRRnuI5mVauJDU1uI+QJu0TkXiiBFGeiKGuoJFMIhJ/lCDKc+ihwWNER/XKlbBzZwxjEhGpQUoQ5WnSBNq3D+45SpAgiorgs89iHJeISA2JaoIws5Fm9pmZrTSza8t4fbiZLTazAjMbV+q1QjP7MFxmRjPOcvXtCx9+CGgkk4jEn6RoHdjMEoG7gGOBtcBCM5vp7ssiNvsKmAj8toxD7HD3jGjFVyn9+sFLL8H27XTt2oikJCUIEYkf0TyDGASsdPdV7p4HTAfGRm7g7qvdfQlQFMU4qq5fv6Bd6eOPSUkJ+q2VIEQkXkTtDAJoD3wdsb4WGLwX+6ea2SKgAPizu88ovYGZXQhcCNCuXTuys7P3eMCtW7dWuE2kBrt2MRT4fPp0vtmxg7Zte7BoUROys9+r9DFqi72te32hescX1bt6RTNB7KuD3X2dmXUC5pnZx+7+ReQG7n4vcC/AgAEDPCsra48HzM7OpqJtduMOl1xCl61b6ZKVRVYWLFgAgwdn0bDh3lUm1va67vWE6h1fVO/qFc0mpnVAx4j1DmFZpbj7uvBxFZANZFZncJViFjQzLV4MBB3V7iUDm0RE6rVoJoiFQGczSzezFOBMoFKjkcyspZk1CJ+3AYYBy/a8V5T07w8ffwx5eRrJJCJxJWoJwt0LgN8ALwOfAk+5+1Izm2pmYwDMbKCZrQVOA+4xs+Kv3u7AIjP7CJhP0AcRmwTRr19wU+qlS+ncGZKTlSBEJD5EtQ/C3WcDs0uV3RzxfCFB01Pp/d4Cekcztkrr1y94XLyY5MxMunRRghCR+KArqSvSqRM0a7ZbP4QShIjEAyWIiiQkQGbmbgli1SrYti3GcYmIRJkSRGX06wcffQQFBSUd1Z9+GtuQRESiTQmiMvr1gx07YPlyjWQSkbihBFEZER3Vhx4KKSlKECJS/ylBVEbXrtCwISxeTFJSsKoEISL1nRJEZSQmQkZGSUd1795Bl4SISH2mBFFZ/frBBx9AURFDhsC6dfD11xXvJiJSVylBVFa/frB1K6xcydChQdHbb8c2JBGRaFKCqKyIjuq+fYMuibfeim1IIiLRpARRWT16BMOXFi8mORkGDtQZhIjUb5VKEGbW2MwSwuddzGyMmSVHN7RaJiUl6J0OO6qHDg26JHbsiHFcIiJRUtkziAUEd3hrD7wCnA08HK2gaq3ie0O4c9hhwSSv778f66BERKKjsgnC3H07cApwt7ufBvSMXli1VP/+sGkTrFnDkCFBkZqZRKS+qnSCMLOhwFnArLAsMToh1WIRHdVt28IhhyhBiEj9VdkEcQVwHfBceNOfTgQ38okvvXsHF82F/RCHHRaMZHKPcVwiIlFQqQTh7q+5+xh3/0vYWf2ju18W5dhqn9TUYL7viI7q776D1atjG5aISDRUdhTT42bWzMwaA58Ay8zsd9ENrZbq1y/omQ47qkHXQ4hI/VTZJqYe7p4DnAS8CKQTjGSKP/36wfffwzff0KsXNGmifggRqZ8qmyCSw+seTgJmuns+EJ8t7xEd1YmJMGiQEoSI1E+VTRD3AKuBxsACMzsYyIlWULVa375gtltH9Ucf6RakIlL/VLaT+g53b+/uJ3hgDXBUlGOrnZo0CW4IEdFRXVgICxfGOC4RkWpW2U7q5mb2dzNbFC5/IzibiE8DBsC774K7LpgTkXqrsk1MDwK5wOnhkgM8FK2gar2srGB867JltGoF3bppJJOI1D+VTRCHuPtkd18VLv8JdIpmYLXa0UcHj3PnAkEz0zvv6II5EalfKpsgdpjZ4cUrZjYMiN95TNPSoFOnkgRx2GHw44+wcmVswxIRqU5JldzuYuCfZtY8XN8ETIhOSHXE0UfDk09CQQFDhwYf41tvQefOMY5LRKSaVHYU00fu3hfoA/Rx90xgRFQjq+1GjICcHFi8mO7doXlzdVSLSP2yV3eUc/ec8IpqgKuiEE/dMSLMj3PnkpAAQ4YoQYhI/bIvtxy1aouiLmrbNpjddd48IOio/vjj4KRCRKQ+2JcEoTE7I0bAG2/Azp0MHRqMYnrvvVgHJSJSPfaYIMws18xyylhygQNrKMba6+ijYedOePttBg8OZuBQM5OI1Bd7TBDu3tTdm5WxNHX3yo6Aqr+OPDK4gdC8eTRvHtwqQhfMiUh9sS9NTNKsGQwcuNv1EO+8A0VFMY5LRKQaKEHsqxEjgo6HnByGD4fNm4P7CYmI1HVKEPvq6KOD6Vxff52RIyEhAV54IdZBiYjsOyWIfXXYYcG9qufOpXXrYFUJQkTqAyWIfZWaCsOGlfRDjBoV3Cpi3boYxyUiso+imiDMbKSZfWZmK83s2jJeH25mi82swMzGlXptgpmtCJfaPe/TiBGwZAl8/z2jRwdFs2bFNiQRkX0VtQRhZonAXcDxQA9gvJn1KLXZV8BE4PFS+7YCJgODgUHAZDNrGa1Y91nx9N/Z2XTvDunp8PzzsQ1JRGRfRfMMYhCwMrx/RB4wHRgbuYG7r3b3JUDpgaHHAa+6+0Z33wS8CoyMYqz7pn//YMjr3LmYwejRMGcObN8e68BERKoumhe7tQe+jlhfS3BGUNV925feyMwuBC4EaNeuHdnZ2Xs86NatWyvcpqp69epF4xde4N3sbDp2bMnOnX357/9ewtChG6PyfnsrmnWvzVTv+KJ6V686fTW0u98L3AswYMAAz8rK2uP22dnZVLRNlZ1+OlxxBVnp6QwdejD/+Z+wZk0frrsuOm+3t6Ja91pM9Y4vqnf1imYT0zqgY8R6h7As2vvGRnE/xLx5NGgAxx0XDHfVbUhFpK6KZoJYCHQ2s3QzSwHOBGZWct+XgV+YWcuwc/oXYVnt1bNnMAV4xHDXdevgww9jG5aISFVFLUG4ewHwG4Iv9k+Bp9x9qZlNNbMxAGY20MzWAqcB95jZ0nDfjcAtBElmITA1LKu9zILhrnPngjsnnBAU6aI5EamronodhLvPdvcu7n6Iu98alt3s7jPD5wvdvYO7N3b31u7eM2LfB9390HB5KJpxVpvjjoNvv4VFi2jbFgYP1nBXEam7dCV1dTrpJEhJgSeeAIJmpoULg5whIlLXKEFUpxYt4Pjj4cknobCw5Krq2bNjGpWISJUoQVS38ePhm2/g9dfp3Rs6dlQzk4jUTUoQ1W30aGjcGJ54ArOgmenVV4M7k4qI1CVKENWtUSMYOxaefhry8hg9GrZtgzi8uFNE6jgliGg480zYuBHmzOGoo4KcoeGuIlLXKEFEw3HHQcuW8MQTpKbCMcfoqmoRqXuUIKIhJQVOPRVmzIDt2xk9GtasCW4ZISJSVyhBRMv48bB1K8yaxdixkJwMjzwS66BERCpPCSJajjwSDjgAnniC/faDk08OEoRGM4lIXaEEES2JicEU4LNnw5YtXHBB0G/97LOxDkxEpHKUIKLpzDNh1y547jlGjIBOneC++2IdlIhI5ShBRNPgwcENqqdPJyEBLrgguB7i889jHZiISMWUIKLJLDiLmDMHfviBiRMhKUlnESJSNyhBRNv48VBYCP/+N/vvD2PGwMMPBy1PIiK1mRJEtPXuHdxtLpwC/MIL4ccf4f/+L8ZxiYhUQAmiJowfD2+8AWvWcOyxcPDBcO+9sQ5KRGTPlCBqwllnQUIC3H03CQnwq18Fdyb94otYByYiUj4liJqQlgannQb/+Ads2cK55waXSdx/f6wDExEpnxJETbnmGsjJgXvuoX17OPFEeOghyM+PdWAiImVTgqgp/foF07refjvs2sWFF8J33+lucyJSeylB1KRrroH16+Ff/2LkSOjQQZ3VIlJ7KUHUpGOOgcxMuO02Eq2I88+HV16B1atjHZiIyM8pQdQks+As4rPP4PnnOf/8oOiOO2IdmIjIzylB1LRx44JRTX/5Cx07OOecA3ffDV9/HevARER2pwRR05KS4Oqr4e234c03mTIluBXp1KmxDkxEZHdKELFw3nnQujX89a8cfDBMmhQMef3ss1gHJiLyEyWIWGjUCC69NBjjunQp118Pqalw002xDkxE5CdKELFyySXQsCFMm0bbtnDVVfDvf8PixbEOTEQkoAQRK23aBJMyPfYYrF3L1VdDq1Zw/fWxDkxEJKAEEUtXXQVFRTB1Ks2bB8nh5ZeDu86JiMSaEkQspaXB5ZcHt5h76y1+/Wto3x6uuy4Y2SQiEktKELE2ZUow58bFF9MwKZ/Jk+GddzRHk4jEnhJErDVtGlxK/fHHcMcdnHsudOkSNDcVFsY6OBGJZ0oQtcFJJwXzf0+eTNL6r7nlFli6NOi/FhGJFSWI2sAM7rwz6LC+/HLGjYMBA+B3v4Pvv491cCISr5Qgaov09OBKueeeI2H2Czz0EGzZEoyEVYe1iMSCEkRtcvXV0L07/OY39Oq0nb/8Jeisvu++WAcmIvEoqgnCzEaa2WdmttLMri3j9QZm9mT4+rtmlhaWp5nZDjP7MFz+Ec04a42UlOC+1WvWwC23cOmlcOyxcOWV8PnnsQ5OROJN1BKEmSUCdwHHAz2A8WbWo9Rm5wOb3P1Q4L+Av0S89oW7Z4TLxdGKs9YZPhwmTIBp00j4dCkPPxzM0/TLX+r+1SJSs6J5BjEIWOnuq9w9D5gOjC21zVjgkfD508DRZmZRjKluuO22YPjrOedwYMsd3HMPLFwIt9wS68BEJJ4kRfHY7YHI2+CsBQaXt427F5jZFqB1+Fq6mX0A5AA3uvvrpd/AzC4ELgRo164d2RXMUbF169YKt6ktWl99Nb1uuonvR42izY03MnJkN269dX/atv2AXr1y9vp4danu1Un1ji+qdzVz96gswDjg/oj1s4H/KbXNJ0CHiPUvgDZAA6B1WNafIIk029P79e/f3ysyf/78CrepVW691R3c//Qn37LFPT09WHJy9v5Qda7u1UT1ji+q994DFnk536vRbGJaB3SMWO8QlpW5jZklAc2BDe6+y903ALj7+wSJo0sUY62drrsOzjgDrr+eZq89z6OPBv3Xl1yioa8iEn3RTBALgc5mlm5mKcCZwMxS28wEJoTPxwHz3N3NbL+wkxsz6wR0BlZFMdbayQwefBAyM+E//oNhLZYyeTI8+ijceGOsgxOR+i5qfRAe9Cn8BngZSAQedPelZjaV4JRmJvAA8KiZrQQ2EiQRgOHAVDPLB4qAi919Y7RirdUaNYIZM2DgQBgzhpvefY9161rzxz9CixbB1dYiItEQzU5q3H02MLtU2c0Rz3cCp5Wx3zPAM9GMrU7p2BGeew6ysrAzTufuWS+xZUsy11wTJIkLLoh1gCJSH+lK6rpi6NDgIrp580i86nL++Yhzwglw0UXw5JOxDk5E6qOonkFINTv3XFi2DKZNIyUvj38/8Q+OH53EL38ZXDZxwgmxDlBE6hMliLrmr3+Fhg3hlltotGEDz//7CY46PpVTTw1uVzp8eKwDFJH6Qk1MdY0ZTJ0a3GRoxgyanT6Sl5/aQloajBoFs2bFOkARqS+UIOqqSy+Fxx+HN9+kzalHMu/xbzn0UBg9Gm69VddJiMi+U4Koy8aPhxdegBUrOOC0w3nz0VWMHx9cI3HaabB1a6wDFJG6TAmirjvuOJg3DzZtouHRh/Gvs19m2rRgVOyQIbByZawDFJG6SgmiPhg8GN54A1q3xo4fydVf/JpXZ2xj/frg+rqXXop1gCJSFylB1Bfdu8P77wd3pfvHPxhxVQZL7nmbjh2D4a933nkoW7bEOkgRqUuUIOqT1FSYNg3mz4f8fNqfcTiLjrueSy7I47nn2tOtGzz2mDqwRaRylCDqoyOPhCVL4NxzSZn2J+58dxAzrrqfjh2DO9MddRQsXRrrIEWktlOCqK+aNYP774eZM+GHHxjztwt5t8VxPHvteyxZAhkZ8NvfomYnESmXEkR9N3o0rFjBykmTsA8Wc/KfB7N+8FhuGPURf/sbHHRQMCPs2rWxDlREahsliHjQqBFrTz8dVq2CP/yBBm+/xpQZGWw89gwuGfI+//V3Jz0dzjkHPvoo1sGKSG2hBBFPmjaFG26AL7+EG2+k5duz+eMrA9jeNZPpw+5k/jMbyciAX/wiaJnatSvWAYtILClBxKOWLeGWW+Drr+Huu0lplMSpr13GV4UHsrTPeFosmsNJY4vYf3847zx45RUoKIh10CJS05Qg4lmLFjBpEixaBB98gF1wAT2+fpmnNh3L9lYdmNHmfHY98SzjjsvhgAOCTefMgR07Yh24iNQEJQgJZGTAnXfCN9/AE0+QeswRHPnDMzy281Q2J7VhfsLRtHjgb1xx7Ce0alHEiBHBScibb0JeXqyDF5Fo0P0gZHepqXDmmcGSnw9vv03C7Nn0mjWLP33/W/7Eb9lBMz5aNIg584fwx5uH8HHDwXQ7vA0DB0JmZrB06hTMTC4idZcShJQvOTm4A9Hw4fDnP8NXX8H8+TR8912GvPMOg5f8CSsshB3w9Wud+GBOL5Z6D2bSna8a96BhZje6DWhC9+7QuXOwHHggJOi8VaROUIKQyjvoIJgwIVgA27YNFi+Gd96h48KFtF+6jFGfv0hCQT5sA96Ar948iC+8E6tJ4zUOZn3ywRR0SKNBl4Np2vVA9k9LpUMH6NAB2reHAw4I8pKIxJ4ShFRd48ZwxBHBQtihlZ8fXG+xbBksW0bHZZ/S9vPVDF39Kg02fIPlO3xJsLwMm2nOt+zPd7TjHdrxHfuzrfF+FDRtBS1bYm1akdK2JakHtqJR+5Y0ateUpm0a0KJF0MfevHmwNGmiMxOR6qYEIdUrORm6dg2Wk0/GgNTi1/LygqG1a9bA6tX4N+tJXfMt+3/1HW2/+Y6+P3xE6uaXSd2WE5yBfFv2W+SRTC5NyaEZm2jKVzRlO43YldiI/KRG5Cc3oqBBI4oaNGR7kfNVszfx1FSsQQNomEpCagMSUlOw1BQSUpJJSE0hMfWnx8QGSSSkJJHYIImk1OAxsUESiSmJJCQnkpiSWPI8qUFYlpxAQlLCT49JRmJikLTKW8x+/txMfTdSeyhBSM1JSYFDDgkWKEkeqaW3y8uDzZth48Zg2bSJgu83sv2bTeT9mEv+xlwKNuViW3JplpNL86252K7tJO76kaRd20nK305KznYaFG4jpWhXuYkmmoowikjAw8fdF6MQw6uwBAyM3cpKv34Qxpfh6k/lu6+XzkMekZki9ym9/0/2PpN5lLPfAe58Xk3vUX69a5/8Fl3hh6xqP64ShNQ+KSnQtm2whJKAZlU4VPb8+WQNGxZcFr5zZ/C4axfk5eG78ijYkU/etjwKtgXPC7bnUZhXSOGugpKlKK+Aol35eEEhRfmFeGEhnl8YrBcU4oVFUFgUPhb+9FjkUFQERUW4O4TluO+2uDsU+c/Kf7ZAsH34aBFlP83hHjzfvn07jRo2wgi3L1ayT6kParc54H96bhHlkVtYOXPG72km+fL2KU9VZqXfuWMnqQ1/9pNjrw9mVXr32Mlrvl9UjqsEIfWbWZBwUlKCqUYiXwKSw6W+yc7OZmBWVqzDqHHxXO9oULeeiIiUSQlCRETKpAQhIiJlUoIQEZEyKUGIiEiZlCBERKRMShAiIlImJQgRESmT+V5e3VhbmdkPwJoKNmsD/FgD4dRG8Vp31Tu+qN5772B3L/NS7HqTICrDzBa5+4BYxxEL8Vp31Tu+qN7VS01MIiJSJiUIEREpU7wliHtjHUAMxWvdVe/4onpXo7jqgxARkcqLtzMIERGpJCUIEREpU9wkCDMbaWafmdlKM7s21vFEi5k9aGbfm9knEWWtzOxVM1sRPraMZYzRYGYdzWy+mS0zs6VmdnlYXq/rbmapZvaemX0U1vs/w/J0M3s3/Ht/0sxSYh1rNJhZopl9YGYvhOvxUu/VZvaxmX1oZovCsmr/W4+LBGFmicBdwPFAD2C8mfWIbVRR8zAwslTZtcBcd+8MzA3X65sC4Gp37wEMAS4J/43re913ASPcvS+QAYw0syHAX4D/cvdDgU3A+bELMaouBz6NWI+XegMc5e4ZEdc/VPvfelwkCGAQsNLdV7l7HjAdGBvjmKLC3RcAG0sVjwUeCZ8/ApxUkzHVBHdf7+6Lw+e5BF8a7anndffA1nC1+A6qDowAng7L6129AcysA3AicH+4bsRBvfeg2v/W4yVBtAe+jlhfG5bFi3buvj58/i3QLpbBRJuZpQGZwLvEQd3DZpYPge+BV4EvgM3uXhBuUl//3m8HrgGKwvXWxEe9IfgR8IqZvW9mF4Zl1f63nrSvB5C6xd3dzOrt2GYzawI8A1zh7jnBj8pAfa27uxcCGWbWAngO6BbbiKLPzEYB37v7+2aWFeNwYuFwd19nZm2BV81seeSL1fW3Hi9nEOuAjhHrHcKyePGdmR0AED5+H+N4osLMkgmSw2Pu/mxYHBd1B3D3zcB8YCjQwsyKfwDWx7/3YcAYM1tN0GQ8Avhv6n+9AXD3deHj9wQ/CgYRhb/1eEkQC4HO4QiHFOBMYGaMY6pJM4EJ4fMJwP/FMJaoCNufHwA+dfe/R7xUr+tuZvuFZw6YWUPgWIL+l/nAuHCzeldvd7/O3Tu4exrB/+d57n4W9bzeAGbW2MyaFj8HfgF8QhT+1uPmSmozO4GgzTIReNDdb41tRNFhZk8AWQTT/34HTAZmAE8BBxFMiX66u5fuyK7TzOxw4HXgY35qk76eoB+i3tbdzPoQdEgmEvzge8rdp5pZJ4Jf1q2AD4Bfuvuu2EUaPWET02/dfVQ81Dus43PhahLwuLvfamatqea/9bhJECIisnfipYlJRET2khKEiIiUSQlCRETKpAQhIiJlUoIQEZEyKUGIVMDMCsNZM4uXapvwz8zSImfeFalNNNWGSMV2uHtGrIMQqWk6gxCponBO/r+G8/K/Z2aHhuVpZjbPzJaY2VwzOygsb2dmz4X3bvjIzA4LD5VoZveF93N4JbwiGjO7LLy/xRIzmx6jakocU4IQqVjDUk1MZ0S8tsXdewP/Q3ClPsCdwCPu3gd4DLgjLL8DeC28d0M/YGlY3hm4y917ApuBU8Pya4HM8DgXR6dqIuXTldQiFTCzre7epIzy1QQ361kVThT4rbu3NrMfgQPcPT8sX+/ubczsB6BD5NQP4dTkr4Y3ecHMfg8ku/sfzOwlYCvBVCkzIu77IFIjdAYhsm+8nOd7I3KuoEJ+6hs8keBOiP2AhRGzlIrUCCUIkX1zRsTj2+HztwhmGAU4i2ASQQhuAzkJSm7y07y8g5pZAtDR3ecDvweaAz87ixGJJv0iEalYw/CObcVecvfioa4tzWwJwVnA+LDsUuAhM/sd8ANwblh+OXCvmZ1PcKYwCVhP2RKBf4VJxIA7wvs9iNQY9UGIVFHYBzHA3X+MdSwi0aAmJhERKZPOIEREpEw6gxARkTIpQYiISJmUIEREpExKECIiUiYlCBERKdP/A5HeYN4MMf7BAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0191 - acc: 0.0000e+00\n",
            "313/313 [==============================] - 1s 4ms/step\n",
            "Final score (RMSE)for lat_latdim=5: 0.13809992372989655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lat_dim=100 for 50 epochs with sigmoid activation function\n",
        "lat_dim = 100\n",
        "model_1 = Sequential(name='function1')\n",
        "model_1.add(Dense(100, activation='relu', input_shape=(n_features,)))\n",
        "model_1.add(Dense(lat_dim, activation='softmax'))\n",
        "\n",
        "#function2\n",
        "model_2 = Sequential(name='function2')\n",
        "model_2.add(Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=True), input_shape=(lat_dim,)))\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "model_2.add(Dense(1))\n",
        "\n",
        "\n",
        "# Combined model\n",
        "combined_input = Input(shape=model_1.input_shape[1:])\n",
        "\n",
        "model_1out = model_1(combined_input)\n",
        "model_2out = model_2(model_1out)\n",
        "\n",
        "combined_output = Concatenate()([model_1out, model_2out])\n",
        "combined_output = Dense(1)(combined_output)\n",
        "combined_model = keras.Model(inputs=combined_input, outputs=combined_output)\n",
        "\n",
        "combined_model.summary()\n",
        "\n",
        "optimizer1 =SGD(learning_rate=0.5)\n",
        "combined_model.compile(loss='MSE',optimizer=optimizer1,  metrics=['acc'])\n",
        "history = combined_model.fit(X_train, y_train, batch_size=128, epochs=50, verbose=2, validation_split=0.1)\n",
        "\n",
        "#Show the training and validation loss versus the number of epochs. \n",
        "# Getting necessary data for plotting\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Plotting training and validation loss\n",
        "# \"b\" is for \"solid blue line\"\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "# r is for \"solid red line\"\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "#plt.xscale(value='log')\n",
        "#plt.yscale(value='log')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "#Show also the test MSE value. \n",
        "# Model evaluation\n",
        "loss = combined_model.evaluate(X_test, y_test)\n",
        "# RMSE error. \n",
        "pred = combined_model.predict(X_test)\n",
        "score = np.sqrt(metrics.mean_squared_error(pred, y_test))\n",
        "print(f\"Final score (RMSE)for lat_latdim=5: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MF_mUOFXfdJG",
        "outputId": "54952436-80b8-4b46-d013-d27d64ecb4de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_10 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_50 (Dense)               (None, 1)            102         ['concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "704/704 - 3s - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 2/50\n",
            "704/704 - 2s - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0180 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 3/50\n",
            "704/704 - 2s - loss: 0.0059 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 4/50\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "704/704 - 3s - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 7/50\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 8/50\n",
            "704/704 - 3s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 9/50\n",
            "704/704 - 4s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "Epoch 10/50\n",
            "704/704 - 4s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 11/50\n",
            "704/704 - 3s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "Epoch 12/50\n",
            "704/704 - 4s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "Epoch 13/50\n",
            "704/704 - 3s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0076 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 14/50\n",
            "704/704 - 4s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 15/50\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0052 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 16/50\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "704/704 - 3s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 18/50\n",
            "704/704 - 3s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 19/50\n",
            "704/704 - 4s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 20/50\n",
            "704/704 - 3s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "Epoch 21/50\n",
            "704/704 - 3s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 22/50\n",
            "704/704 - 2s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 23/50\n",
            "704/704 - 4s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 24/50\n",
            "704/704 - 3s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0058 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 25/50\n",
            "704/704 - 3s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 26/50\n",
            "704/704 - 3s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0044 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 27/50\n",
            "704/704 - 4s - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "Epoch 28/50\n",
            "704/704 - 3s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "Epoch 29/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0047 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 30/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 31/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0082 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 32/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 33/50\n",
            "704/704 - 3s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 35/50\n",
            "704/704 - 3s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 36/50\n",
            "704/704 - 3s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "Epoch 37/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 38/50\n",
            "704/704 - 3s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0034 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 40/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0060 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 41/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0045 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 42/50\n",
            "704/704 - 2s - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 43/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0035 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 44/50\n",
            "704/704 - 3s - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0039 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "704/704 - 2s - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 46/50\n",
            "704/704 - 2s - loss: 0.0035 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "Epoch 47/50\n",
            "704/704 - 2s - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0033 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "704/704 - 2s - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 49/50\n",
            "704/704 - 2s - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0031 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "704/704 - 2s - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0038 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0039 - acc: 0.0000e+00\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Final score (RMSE)for lat_latdim=5: 0.06229390949010849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment for the result:\n",
        "\n",
        "model with relu converges smoothly, while model with sigmoid converges with some fluctuation.\n",
        "In terms of the value of the loss, model with sigmoid has lower loss than the model with relu."
      ],
      "metadata": {
        "id": "EjWOKja2qe5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### P1.5 Evaluate the model"
      ],
      "metadata": {
        "id": "TgvB93CGsUp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#P1.5 evaluate the model\n",
        "from numpy.lib.function_base import average\n",
        "# define the model for the evaluation\n",
        "def used_model(lat_dim):\n",
        "  model_1 = Sequential(name='function1')\n",
        "  model_1.add(Dense(100, activation='relu', input_shape=(n_features,)))\n",
        "  model_1.add(Dense(lat_dim, activation='softmax'))\n",
        "  model_2 = Sequential(name='function2')\n",
        "  model_2.add(Lambda(lambda x: tf.reduce_sum(x, axis=1, keepdims=True), input_shape=(lat_dim,)))\n",
        "  model_2.add(Dense(100, activation='relu'))\n",
        "  model_2.add(Dense(1))\n",
        "  combined_input = Input(shape=model_1.input_shape[1:])\n",
        "  model_1out = model_1(combined_input)\n",
        "  model_2out = model_2(model_1out)\n",
        "  combined_output = Concatenate()([model_1out, model_2out])\n",
        "  combined_output = Dense(1)(combined_output)\n",
        "  combined_model = keras.Model(inputs=combined_input, outputs=combined_output)\n",
        "  combined_model.summary()\n",
        "\n",
        "  optimizer1 =SGD(learning_rate=1e-4)\n",
        "  combined_model.compile(loss='MSE',optimizer=optimizer1,  metrics=['acc'])\n",
        "  return combined_model\n",
        "\n",
        "#define the list of lat_dim in [1, 2, ..., 10, 20, 30, ..., 100]\n",
        "lat_dim1=[i for i in range(1, 10, 1)]\n",
        "lat_dim2=[i for i in range(10, 101, 10)]\n",
        "lat_dim3=lat_dim1 + lat_dim2\n",
        "print(lat_dim3)\n",
        "\n",
        "#set the list of the mean test MSE \n",
        "mean_test_MSE=[]\n",
        "\n",
        "# loop each lat_dim \n",
        "for lat_dim in lat_dim3:\n",
        "  #Visualize which lat_dim is now\n",
        "  print(f\"Now is the model with lat_dim '{lat_dim}' \")\n",
        "  #the best model (minMSE) of each run among five epochs\n",
        "  epoch_best_loss=[]\n",
        "  #loop five runs per lat_dim\n",
        "  for n in range(5):\n",
        "    #Visualize which run is now for the specific lat_dim\n",
        "    print(f\"this is the {n+1} run for lat_dim: '{lat_dim}' \")\n",
        "    # activate the model for each lat_dim for each run\n",
        "    test_model=used_model(lat_dim)\n",
        "    # loop five epochs\n",
        "    for m in range(5):\n",
        "      #list for MSE for each epoch in each run\n",
        "      epoch_loss=[]\n",
        "      #run the model\n",
        "      history = test_model.fit(X_train, y_train, batch_size=128, epochs=1, verbose=2, validation_split=0.1)\n",
        "      #get the MSE for each epoch in each run\n",
        "      mse_per_epoch = history.history['val_loss']\n",
        "      #print it to visualize the number of MSE\n",
        "      print(f'loss of latdim {lat_dim} for the {n+1} run in {m+1} epoch is {mse_per_epoch} ')\n",
        "      #append it in the list for the MSE\n",
        "      epoch_loss.append(mse_per_epoch)\n",
        "    #get the index of minimum MSE in each loop of run\n",
        "    best_epoch_loss_index=epoch_loss.index(min(epoch_loss))\n",
        "    #get the value of minimum MSE in each epoch loop of run among 5 epochs\n",
        "    best_epoch_loss=min(epoch_loss)\n",
        "    #Append the minimum MSE in each loop of run among 5 epochs\n",
        "    epoch_best_loss.append(best_epoch_loss)\n",
        "    #average the list to get the mean Test MSE for each lat_dim\n",
        "    avg_epoch_best_loss = average(epoch_best_loss)\n",
        "  #Visualize the mean test MSE of each latdim\n",
        "  print(f'mean Test MSE for latdim  {lat_dim} among 5 runs for 5 epochs is {avg_epoch_best_loss}')\n",
        "  #Append the mean Test MSE to the list\n",
        "  mean_test_MSE.append(avg_epoch_best_loss)\n",
        "  #Visualize the list\n",
        "  print(mean_test_MSE)\n",
        "\n",
        "#import the library for the plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the mean Test MSE versus the lat_dim\n",
        "plt.plot(lat_dim3, mean_test_MSE, label='Test MSE')\n",
        "plt.xlabel('lat_dim')\n",
        "plt.ylabel('mean test MSE')\n",
        "plt.title('mean test MSE Versus lat_dim')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pXlHUHn7smKu",
        "outputId": "a7cc43c4-1260-4da5-d48e-be6f88467ca5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
            "Now is the model with lat_dim '1' \n",
            "this is the 1 run for lat_dim: '1' \n",
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 1)            1201        ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenate)   (None, 2)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_55 (Dense)               (None, 1)            3           ['concatenate_10[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,505\n",
            "Trainable params: 1,505\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.1223 - acc: 0.0000e+00 - val_loss: 0.0801 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 1 for the 1 run in 1 epoch is [0.08005395531654358] \n",
            "704/704 - 2s - loss: 0.0588 - acc: 0.0000e+00 - val_loss: 0.0424 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 1 for the 1 run in 2 epoch is [0.04236474260687828] \n",
            "704/704 - 2s - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 1 run in 3 epoch is [0.027866192162036896] \n",
            "704/704 - 2s - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0223 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 1 run in 4 epoch is [0.02230546623468399] \n",
            "704/704 - 2s - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0202 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 1 run in 5 epoch is [0.02017955854535103] \n",
            "this is the 2 run for lat_dim: '1' \n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 1)            1201        ['input_12[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenate)   (None, 2)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_60 (Dense)               (None, 1)            3           ['concatenate_11[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,505\n",
            "Trainable params: 1,505\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.0609 - acc: 0.0000e+00 - val_loss: 0.0501 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 1 for the 2 run in 1 epoch is [0.050088103860616684] \n",
            "704/704 - 2s - loss: 0.0422 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 2 run in 2 epoch is [0.03629978001117706] \n",
            "704/704 - 2s - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 2 run in 3 epoch is [0.02861950919032097] \n",
            "704/704 - 1s - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0243 - val_acc: 0.0000e+00 - 1s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 2 run in 4 epoch is [0.024345001205801964] \n",
            "704/704 - 2s - loss: 0.0229 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 2 run in 5 epoch is [0.021959088742733] \n",
            "this is the 3 run for lat_dim: '1' \n",
            "Model: \"model_12\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_13 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 1)            1201        ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenate)   (None, 2)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_65 (Dense)               (None, 1)            3           ['concatenate_12[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,505\n",
            "Trainable params: 1,505\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.1096 - acc: 0.0000e+00 - val_loss: 0.0655 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 1 for the 3 run in 1 epoch is [0.0655188038945198] \n",
            "704/704 - 2s - loss: 0.0467 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 1 for the 3 run in 2 epoch is [0.03308936953544617] \n",
            "704/704 - 2s - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 3 run in 3 epoch is [0.023120883852243423] \n",
            "704/704 - 2s - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0201 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 3 run in 4 epoch is [0.020122068002820015] \n",
            "704/704 - 2s - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0193 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 1 for the 3 run in 5 epoch is [0.019252857193350792] \n",
            "this is the 4 run for lat_dim: '1' \n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_14 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 1)            1201        ['input_14[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenate)   (None, 2)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_70 (Dense)               (None, 1)            3           ['concatenate_13[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,505\n",
            "Trainable params: 1,505\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 5s - loss: 1.6691 - acc: 0.0000e+00 - val_loss: 0.6380 - val_acc: 0.0000e+00 - 5s/epoch - 8ms/step\n",
            "loss of latdim 1 for the 4 run in 1 epoch is [0.6379638314247131] \n",
            "704/704 - 2s - loss: 0.2991 - acc: 0.0000e+00 - val_loss: 0.1075 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 4 run in 2 epoch is [0.1075219139456749] \n",
            "704/704 - 2s - loss: 0.0562 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 1 for the 4 run in 3 epoch is [0.029075482860207558] \n",
            "704/704 - 3s - loss: 0.0231 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 1 for the 4 run in 4 epoch is [0.01991870440542698] \n",
            "704/704 - 3s - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0190 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 1 for the 4 run in 5 epoch is [0.01900329627096653] \n",
            "this is the 5 run for lat_dim: '1' \n",
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 1)            1201        ['input_15[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenate)   (None, 2)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_75 (Dense)               (None, 1)            3           ['concatenate_14[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,505\n",
            "Trainable params: 1,505\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.0447 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 1 for the 5 run in 1 epoch is [0.0368066169321537] \n",
            "704/704 - 2s - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 5 run in 2 epoch is [0.027663428336381912] \n",
            "704/704 - 2s - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 5 run in 3 epoch is [0.02318388782441616] \n",
            "704/704 - 3s - loss: 0.0219 - acc: 0.0000e+00 - val_loss: 0.0210 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 1 for the 5 run in 4 epoch is [0.020996218547225] \n",
            "704/704 - 2s - loss: 0.0204 - acc: 0.0000e+00 - val_loss: 0.0199 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 1 for the 5 run in 5 epoch is [0.019934244453907013] \n",
            "mean Test MSE for latdim  1 among 5 runs for 5 epochs is 0.02006580904126167\n",
            "[0.02006580904126167]\n",
            "Now is the model with lat_dim '2' \n",
            "this is the 1 run for lat_dim: '2' \n",
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_16 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 2)            1302        ['input_16[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenate)   (None, 3)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_80 (Dense)               (None, 1)            4           ['concatenate_15[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,607\n",
            "Trainable params: 1,607\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.7038 - acc: 0.0000e+00 - val_loss: 0.2139 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 1 run in 1 epoch is [0.2138654738664627] \n",
            "704/704 - 2s - loss: 0.0962 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 1 run in 2 epoch is [0.03748483955860138] \n",
            "704/704 - 3s - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 2 for the 1 run in 3 epoch is [0.019951486960053444] \n",
            "704/704 - 2s - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0184 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 1 run in 4 epoch is [0.018441567197442055] \n",
            "704/704 - 2s - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 1 run in 5 epoch is [0.01832479238510132] \n",
            "this is the 2 run for lat_dim: '2' \n",
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_17 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 2)            1302        ['input_17[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenate)   (None, 3)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_85 (Dense)               (None, 1)            4           ['concatenate_16[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,607\n",
            "Trainable params: 1,607\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.1049 - acc: 0.0000e+00 - val_loss: 0.0522 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 2 run in 1 epoch is [0.052205890417099] \n",
            "704/704 - 2s - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 2 run in 2 epoch is [0.023530034348368645] \n",
            "704/704 - 3s - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0173 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 2 for the 2 run in 3 epoch is [0.01730578951537609] \n",
            "704/704 - 2s - loss: 0.0166 - acc: 0.0000e+00 - val_loss: 0.0159 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 2 run in 4 epoch is [0.015858832746744156] \n",
            "704/704 - 2s - loss: 0.0158 - acc: 0.0000e+00 - val_loss: 0.0154 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 2 run in 5 epoch is [0.015437150374054909] \n",
            "this is the 3 run for lat_dim: '2' \n",
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_18 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 2)            1302        ['input_18[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_17 (Concatenate)   (None, 3)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_90 (Dense)               (None, 1)            4           ['concatenate_17[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,607\n",
            "Trainable params: 1,607\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 3 run in 1 epoch is [0.02435067482292652] \n",
            "704/704 - 2s - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0226 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 3 run in 2 epoch is [0.022610411047935486] \n",
            "704/704 - 2s - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 3 run in 3 epoch is [0.021504636853933334] \n",
            "704/704 - 2s - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 3 run in 4 epoch is [0.02079898677766323] \n",
            "704/704 - 2s - loss: 0.0206 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 3 run in 5 epoch is [0.020346423611044884] \n",
            "this is the 4 run for lat_dim: '2' \n",
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_19 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 2)            1302        ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_18 (Concatenate)   (None, 3)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_95 (Dense)               (None, 1)            4           ['concatenate_18[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,607\n",
            "Trainable params: 1,607\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.0231 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 4 run in 1 epoch is [0.01825314201414585] \n",
            "704/704 - 2s - loss: 0.0165 - acc: 0.0000e+00 - val_loss: 0.0153 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 4 run in 2 epoch is [0.015266568399965763] \n",
            "704/704 - 2s - loss: 0.0148 - acc: 0.0000e+00 - val_loss: 0.0145 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 4 run in 3 epoch is [0.014499766752123833] \n",
            "704/704 - 2s - loss: 0.0144 - acc: 0.0000e+00 - val_loss: 0.0143 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 4 run in 4 epoch is [0.014283987693488598] \n",
            "704/704 - 2s - loss: 0.0143 - acc: 0.0000e+00 - val_loss: 0.0142 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 4 run in 5 epoch is [0.01421038806438446] \n",
            "this is the 5 run for lat_dim: '2' \n",
            "Model: \"model_19\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_20 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 2)            1302        ['input_20[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_19 (Concatenate)   (None, 3)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_100 (Dense)              (None, 1)            4           ['concatenate_19[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,607\n",
            "Trainable params: 1,607\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.0852 - acc: 0.0000e+00 - val_loss: 0.0657 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 5 run in 1 epoch is [0.06574580073356628] \n",
            "704/704 - 2s - loss: 0.0538 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 5 run in 2 epoch is [0.04283284768462181] \n",
            "704/704 - 2s - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 5 run in 3 epoch is [0.030184008181095123] \n",
            "704/704 - 2s - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0233 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 2 for the 5 run in 4 epoch is [0.023261141031980515] \n",
            "704/704 - 2s - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 2 for the 5 run in 5 epoch is [0.019497999921441078] \n",
            "mean Test MSE for latdim  2 among 5 runs for 5 epochs is 0.01756335087120533\n",
            "[0.02006580904126167, 0.01756335087120533]\n",
            "Now is the model with lat_dim '3' \n",
            "this is the 1 run for lat_dim: '3' \n",
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 3)            1403        ['input_21[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_20 (Concatenate)   (None, 4)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_105 (Dense)              (None, 1)            5           ['concatenate_20[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,709\n",
            "Trainable params: 1,709\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 3 for the 1 run in 1 epoch is [0.023828765377402306] \n",
            "704/704 - 3s - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 3 for the 1 run in 2 epoch is [0.023496141657233238] \n",
            "704/704 - 5s - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0233 - val_acc: 0.0000e+00 - 5s/epoch - 7ms/step\n",
            "loss of latdim 3 for the 1 run in 3 epoch is [0.02331501804292202] \n",
            "704/704 - 3s - loss: 0.0231 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 3 for the 1 run in 4 epoch is [0.023156369104981422] \n",
            "704/704 - 2s - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 1 run in 5 epoch is [0.023001547902822495] \n",
            "this is the 2 run for lat_dim: '3' \n",
            "Model: \"model_21\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_22 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 3)            1403        ['input_22[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenate)   (None, 4)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_110 (Dense)              (None, 1)            5           ['concatenate_21[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,709\n",
            "Trainable params: 1,709\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2339 - acc: 0.0000e+00 - val_loss: 0.1158 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 3 for the 2 run in 1 epoch is [0.11575238406658173] \n",
            "704/704 - 2s - loss: 0.0720 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 2 run in 2 epoch is [0.04276067763566971] \n",
            "704/704 - 2s - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 2 run in 3 epoch is [0.023781906813383102] \n",
            "704/704 - 2s - loss: 0.0210 - acc: 0.0000e+00 - val_loss: 0.0189 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 2 run in 4 epoch is [0.01890830509364605] \n",
            "704/704 - 2s - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0176 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 2 run in 5 epoch is [0.017637867480516434] \n",
            "this is the 3 run for lat_dim: '3' \n",
            "Model: \"model_22\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_23 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 3)            1403        ['input_23[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenate)   (None, 4)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_115 (Dense)              (None, 1)            5           ['concatenate_22[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,709\n",
            "Trainable params: 1,709\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.4358 - acc: 0.0000e+00 - val_loss: 0.2885 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 3 for the 3 run in 1 epoch is [0.288482666015625] \n",
            "704/704 - 2s - loss: 0.2028 - acc: 0.0000e+00 - val_loss: 0.1341 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 3 for the 3 run in 2 epoch is [0.13410355150699615] \n",
            "704/704 - 2s - loss: 0.0955 - acc: 0.0000e+00 - val_loss: 0.0643 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 3 run in 3 epoch is [0.06434328854084015] \n",
            "704/704 - 2s - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 3 run in 4 epoch is [0.034102246165275574] \n",
            "704/704 - 3s - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0215 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 3 for the 3 run in 5 epoch is [0.02154136821627617] \n",
            "this is the 4 run for lat_dim: '3' \n",
            "Model: \"model_23\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_24 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 3)            1403        ['input_24[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenate)   (None, 4)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_120 (Dense)              (None, 1)            5           ['concatenate_23[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,709\n",
            "Trainable params: 1,709\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.0884 - acc: 0.0000e+00 - val_loss: 0.0728 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 3 for the 4 run in 1 epoch is [0.07281740754842758] \n",
            "704/704 - 2s - loss: 0.0624 - acc: 0.0000e+00 - val_loss: 0.0524 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 3 for the 4 run in 2 epoch is [0.05239162594079971] \n",
            "704/704 - 2s - loss: 0.0459 - acc: 0.0000e+00 - val_loss: 0.0395 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 4 run in 3 epoch is [0.03947659581899643] \n",
            "704/704 - 2s - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 3 for the 4 run in 4 epoch is [0.031361840665340424] \n",
            "704/704 - 4s - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0263 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 3 for the 4 run in 5 epoch is [0.02629927359521389] \n",
            "this is the 5 run for lat_dim: '3' \n",
            "Model: \"model_24\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_25 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 3)            1403        ['input_25[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenate)   (None, 4)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_125 (Dense)              (None, 1)            5           ['concatenate_24[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,709\n",
            "Trainable params: 1,709\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.0993 - acc: 0.0000e+00 - val_loss: 0.0488 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 3 for the 5 run in 1 epoch is [0.04884492605924606] \n",
            "704/704 - 3s - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0253 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 3 for the 5 run in 2 epoch is [0.025281723588705063] \n",
            "704/704 - 2s - loss: 0.0227 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 5 run in 3 epoch is [0.021230075508356094] \n",
            "704/704 - 2s - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0205 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 5 run in 4 epoch is [0.020487261936068535] \n",
            "704/704 - 2s - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0203 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 3 for the 5 run in 5 epoch is [0.020276451483368874] \n",
            "mean Test MSE for latdim  3 among 5 runs for 5 epochs is 0.02175130173563957\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957]\n",
            "Now is the model with lat_dim '4' \n",
            "this is the 1 run for lat_dim: '4' \n",
            "Model: \"model_25\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_26 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 4)            1504        ['input_26[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenate)   (None, 5)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_130 (Dense)              (None, 1)            6           ['concatenate_25[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,811\n",
            "Trainable params: 1,811\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 5s - loss: 0.0591 - acc: 0.0000e+00 - val_loss: 0.0508 - val_acc: 0.0000e+00 - 5s/epoch - 7ms/step\n",
            "loss of latdim 4 for the 1 run in 1 epoch is [0.05081920325756073] \n",
            "704/704 - 3s - loss: 0.0451 - acc: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 4 for the 1 run in 2 epoch is [0.03957726061344147] \n",
            "704/704 - 3s - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 4 for the 1 run in 3 epoch is [0.03214673325419426] \n",
            "704/704 - 6s - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00 - 6s/epoch - 8ms/step\n",
            "loss of latdim 4 for the 1 run in 4 epoch is [0.027237769216299057] \n",
            "704/704 - 2s - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0240 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 4 for the 1 run in 5 epoch is [0.02399372309446335] \n",
            "this is the 2 run for lat_dim: '4' \n",
            "Model: \"model_26\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_27 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 4)            1504        ['input_27[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_26 (Concatenate)   (None, 5)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_135 (Dense)              (None, 1)            6           ['concatenate_26[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,811\n",
            "Trainable params: 1,811\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 5s - loss: 0.6340 - acc: 0.0000e+00 - val_loss: 0.5174 - val_acc: 0.0000e+00 - 5s/epoch - 8ms/step\n",
            "loss of latdim 4 for the 2 run in 1 epoch is [0.5173680782318115] \n",
            "704/704 - 3s - loss: 0.4297 - acc: 0.0000e+00 - val_loss: 0.3490 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 4 for the 2 run in 2 epoch is [0.348974347114563] \n",
            "704/704 - 3s - loss: 0.2891 - acc: 0.0000e+00 - val_loss: 0.2338 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 4 for the 2 run in 3 epoch is [0.23382721841335297] \n",
            "704/704 - 4s - loss: 0.1935 - acc: 0.0000e+00 - val_loss: 0.1562 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 4 for the 2 run in 4 epoch is [0.1562471240758896] \n",
            "704/704 - 4s - loss: 0.1296 - acc: 0.0000e+00 - val_loss: 0.1049 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 4 for the 2 run in 5 epoch is [0.10485155135393143] \n",
            "this is the 3 run for lat_dim: '4' \n",
            "Model: \"model_27\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_28 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 4)            1504        ['input_28[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_27 (Concatenate)   (None, 5)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_140 (Dense)              (None, 1)            6           ['concatenate_27[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,811\n",
            "Trainable params: 1,811\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.3518 - acc: 0.0000e+00 - val_loss: 0.2186 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 4 for the 3 run in 1 epoch is [0.21863313019275665] \n",
            "704/704 - 2s - loss: 0.1503 - acc: 0.0000e+00 - val_loss: 0.0983 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 4 for the 3 run in 2 epoch is [0.09826378524303436] \n",
            "704/704 - 3s - loss: 0.0712 - acc: 0.0000e+00 - val_loss: 0.0502 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 4 for the 3 run in 3 epoch is [0.05018167942762375] \n",
            "704/704 - 2s - loss: 0.0396 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 4 for the 3 run in 4 epoch is [0.031161731109023094] \n",
            "704/704 - 2s - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0238 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 4 for the 3 run in 5 epoch is [0.023788247257471085] \n",
            "this is the 4 run for lat_dim: '4' \n",
            "Model: \"model_28\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_29 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 4)            1504        ['input_29[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_28 (Concatenate)   (None, 5)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_145 (Dense)              (None, 1)            6           ['concatenate_28[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,811\n",
            "Trainable params: 1,811\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.1268 - acc: 0.0000e+00 - val_loss: 0.1004 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 4 for the 4 run in 1 epoch is [0.10039836168289185] \n",
            "704/704 - 2s - loss: 0.0828 - acc: 0.0000e+00 - val_loss: 0.0664 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 4 for the 4 run in 2 epoch is [0.06636951863765717] \n",
            "704/704 - 2s - loss: 0.0557 - acc: 0.0000e+00 - val_loss: 0.0455 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 4 for the 4 run in 3 epoch is [0.045501817017793655] \n",
            "704/704 - 2s - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0327 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 4 for the 4 run in 4 epoch is [0.032729435712099075] \n",
            "704/704 - 2s - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 4 for the 4 run in 5 epoch is [0.02493610791862011] \n",
            "this is the 5 run for lat_dim: '4' \n",
            "Model: \"model_29\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_30 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 4)            1504        ['input_30[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_29 (Concatenate)   (None, 5)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_150 (Dense)              (None, 1)            6           ['concatenate_29[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,811\n",
            "Trainable params: 1,811\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0213 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 4 for the 5 run in 1 epoch is [0.021306868642568588] \n",
            "704/704 - 3s - loss: 0.0202 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 4 for the 5 run in 2 epoch is [0.018818872049450874] \n",
            "704/704 - 2s - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0176 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 4 for the 5 run in 3 epoch is [0.01758553273975849] \n",
            "704/704 - 2s - loss: 0.0174 - acc: 0.0000e+00 - val_loss: 0.0170 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 4 for the 5 run in 4 epoch is [0.016964051872491837] \n",
            "704/704 - 2s - loss: 0.0170 - acc: 0.0000e+00 - val_loss: 0.0166 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 4 for the 5 run in 5 epoch is [0.016649369150400162] \n",
            "mean Test MSE for latdim  4 among 5 runs for 5 epochs is 0.038843799754977225\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225]\n",
            "Now is the model with lat_dim '5' \n",
            "this is the 1 run for lat_dim: '5' \n",
            "Model: \"model_30\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_31 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 5)            1605        ['input_31[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_30 (Concatenate)   (None, 6)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_155 (Dense)              (None, 1)            7           ['concatenate_30[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,913\n",
            "Trainable params: 1,913\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 6s - loss: 0.1151 - acc: 0.0000e+00 - val_loss: 0.0719 - val_acc: 0.0000e+00 - 6s/epoch - 8ms/step\n",
            "loss of latdim 5 for the 1 run in 1 epoch is [0.0719379335641861] \n",
            "704/704 - 3s - loss: 0.0517 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 5 for the 1 run in 2 epoch is [0.03663237392902374] \n",
            "704/704 - 2s - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 1 run in 3 epoch is [0.02474149316549301] \n",
            "704/704 - 2s - loss: 0.0227 - acc: 0.0000e+00 - val_loss: 0.0209 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 1 run in 4 epoch is [0.020858902484178543] \n",
            "704/704 - 4s - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0196 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 5 for the 1 run in 5 epoch is [0.019617540761828423] \n",
            "this is the 2 run for lat_dim: '5' \n",
            "Model: \"model_31\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_32 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 5)            1605        ['input_32[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_31 (Concatenate)   (None, 6)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_160 (Dense)              (None, 1)            7           ['concatenate_31[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,913\n",
            "Trainable params: 1,913\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.8611 - acc: 0.0000e+00 - val_loss: 0.5568 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 5 for the 2 run in 1 epoch is [0.5568071007728577] \n",
            "704/704 - 2s - loss: 0.3798 - acc: 0.0000e+00 - val_loss: 0.2398 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 5 for the 2 run in 2 epoch is [0.23984196782112122] \n",
            "704/704 - 2s - loss: 0.1619 - acc: 0.0000e+00 - val_loss: 0.1018 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 2 run in 3 epoch is [0.10179292410612106] \n",
            "704/704 - 3s - loss: 0.0713 - acc: 0.0000e+00 - val_loss: 0.0480 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 5 for the 2 run in 4 epoch is [0.04802475497126579] \n",
            "704/704 - 2s - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 2 run in 5 epoch is [0.028689468279480934] \n",
            "this is the 3 run for lat_dim: '5' \n",
            "Model: \"model_32\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_33 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 5)            1605        ['input_33[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_32 (Concatenate)   (None, 6)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_165 (Dense)              (None, 1)            7           ['concatenate_32[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,913\n",
            "Trainable params: 1,913\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 5 for the 3 run in 1 epoch is [0.029426364228129387] \n",
            "704/704 - 2s - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 3 run in 2 epoch is [0.02578810416162014] \n",
            "704/704 - 2s - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 3 run in 3 epoch is [0.0234840027987957] \n",
            "704/704 - 2s - loss: 0.0229 - acc: 0.0000e+00 - val_loss: 0.0220 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 3 run in 4 epoch is [0.02201768010854721] \n",
            "704/704 - 2s - loss: 0.0217 - acc: 0.0000e+00 - val_loss: 0.0211 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 3 run in 5 epoch is [0.02107688970863819] \n",
            "this is the 4 run for lat_dim: '5' \n",
            "Model: \"model_33\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_34 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 5)            1605        ['input_34[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 6)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_170 (Dense)              (None, 1)            7           ['concatenate_33[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,913\n",
            "Trainable params: 1,913\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.1284 - acc: 0.0000e+00 - val_loss: 0.0944 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 5 for the 4 run in 1 epoch is [0.09438369423151016] \n",
            "704/704 - 2s - loss: 0.0736 - acc: 0.0000e+00 - val_loss: 0.0558 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 4 run in 2 epoch is [0.05583970248699188] \n",
            "704/704 - 2s - loss: 0.0452 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 5 for the 4 run in 3 epoch is [0.03596430644392967] \n",
            "704/704 - 2s - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 5 for the 4 run in 4 epoch is [0.025827858597040176] \n",
            "704/704 - 2s - loss: 0.0232 - acc: 0.0000e+00 - val_loss: 0.0207 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 5 for the 4 run in 5 epoch is [0.020711833611130714] \n",
            "this is the 5 run for lat_dim: '5' \n",
            "Model: \"model_34\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_35 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 5)            1605        ['input_35[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 6)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_175 (Dense)              (None, 1)            7           ['concatenate_34[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,913\n",
            "Trainable params: 1,913\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.5777 - acc: 0.0000e+00 - val_loss: 0.4024 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 5 for the 5 run in 1 epoch is [0.40235093235969543] \n",
            "704/704 - 2s - loss: 0.2963 - acc: 0.0000e+00 - val_loss: 0.2089 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 5 for the 5 run in 2 epoch is [0.20886127650737762] \n",
            "704/704 - 2s - loss: 0.1549 - acc: 0.0000e+00 - val_loss: 0.1102 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 5 for the 5 run in 3 epoch is [0.11024484783411026] \n",
            "704/704 - 2s - loss: 0.0837 - acc: 0.0000e+00 - val_loss: 0.0616 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 5 for the 5 run in 4 epoch is [0.06160935014486313] \n",
            "704/704 - 3s - loss: 0.0490 - acc: 0.0000e+00 - val_loss: 0.0384 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 5 for the 5 run in 5 epoch is [0.03843144327402115] \n",
            "mean Test MSE for latdim  5 among 5 runs for 5 epochs is 0.025705435127019883\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883]\n",
            "Now is the model with lat_dim '6' \n",
            "this is the 1 run for lat_dim: '6' \n",
            "Model: \"model_35\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_36 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 6)            1706        ['input_36[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, 7)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_180 (Dense)              (None, 1)            8           ['concatenate_35[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,015\n",
            "Trainable params: 2,015\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.1241 - acc: 0.0000e+00 - val_loss: 0.0768 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 6 for the 1 run in 1 epoch is [0.07682879269123077] \n",
            "704/704 - 2s - loss: 0.0543 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 1 run in 2 epoch is [0.03754093497991562] \n",
            "704/704 - 2s - loss: 0.0299 - acc: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 6 for the 1 run in 3 epoch is [0.02411273866891861] \n",
            "704/704 - 2s - loss: 0.0217 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 6 for the 1 run in 4 epoch is [0.01972673274576664] \n",
            "704/704 - 2s - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 6 for the 1 run in 5 epoch is [0.018336618319153786] \n",
            "this is the 2 run for lat_dim: '6' \n",
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_37 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 6)            1706        ['input_37[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenate)   (None, 7)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_185 (Dense)              (None, 1)            8           ['concatenate_36[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,015\n",
            "Trainable params: 2,015\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.0190 - acc: 0.0000e+00 - val_loss: 0.0187 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 6 for the 2 run in 1 epoch is [0.01874781958758831] \n",
            "704/704 - 2s - loss: 0.0188 - acc: 0.0000e+00 - val_loss: 0.0186 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 6 for the 2 run in 2 epoch is [0.018557481467723846] \n",
            "704/704 - 2s - loss: 0.0186 - acc: 0.0000e+00 - val_loss: 0.0184 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 6 for the 2 run in 3 epoch is [0.018424520269036293] \n",
            "704/704 - 3s - loss: 0.0185 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 6 for the 2 run in 4 epoch is [0.01833161525428295] \n",
            "704/704 - 2s - loss: 0.0184 - acc: 0.0000e+00 - val_loss: 0.0183 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 2 run in 5 epoch is [0.018265854567289352] \n",
            "this is the 3 run for lat_dim: '6' \n",
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_38 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 6)            1706        ['input_38[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_37 (Concatenate)   (None, 7)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_190 (Dense)              (None, 1)            8           ['concatenate_37[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,015\n",
            "Trainable params: 2,015\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.3001 - acc: 0.0000e+00 - val_loss: 0.2154 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 6 for the 3 run in 1 epoch is [0.21543605625629425] \n",
            "704/704 - 2s - loss: 0.1638 - acc: 0.0000e+00 - val_loss: 0.1205 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 3 run in 2 epoch is [0.12052498757839203] \n",
            "704/704 - 2s - loss: 0.0938 - acc: 0.0000e+00 - val_loss: 0.0710 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 3 run in 3 epoch is [0.07097411900758743] \n",
            "704/704 - 2s - loss: 0.0572 - acc: 0.0000e+00 - val_loss: 0.0451 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 6 for the 3 run in 4 epoch is [0.045079831033945084] \n",
            "704/704 - 2s - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 3 run in 5 epoch is [0.03173794969916344] \n",
            "this is the 4 run for lat_dim: '6' \n",
            "Model: \"model_38\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_39 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 6)            1706        ['input_39[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_38 (Concatenate)   (None, 7)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_195 (Dense)              (None, 1)            8           ['concatenate_38[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,015\n",
            "Trainable params: 2,015\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.2764 - acc: 0.0000e+00 - val_loss: 0.1736 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 6 for the 4 run in 1 epoch is [0.17360347509384155] \n",
            "704/704 - 2s - loss: 0.1180 - acc: 0.0000e+00 - val_loss: 0.0756 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 4 run in 2 epoch is [0.07557140290737152] \n",
            "704/704 - 2s - loss: 0.0538 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 4 run in 3 epoch is [0.03712477907538414] \n",
            "704/704 - 2s - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 6 for the 4 run in 4 epoch is [0.02288971096277237] \n",
            "704/704 - 2s - loss: 0.0201 - acc: 0.0000e+00 - val_loss: 0.0178 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 4 run in 5 epoch is [0.017837485298514366] \n",
            "this is the 5 run for lat_dim: '6' \n",
            "Model: \"model_39\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_40 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 6)            1706        ['input_40[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_39 (Concatenate)   (None, 7)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_200 (Dense)              (None, 1)            8           ['concatenate_39[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,015\n",
            "Trainable params: 2,015\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.1301 - acc: 0.0000e+00 - val_loss: 0.0863 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 6 for the 5 run in 1 epoch is [0.086343914270401] \n",
            "704/704 - 2s - loss: 0.0638 - acc: 0.0000e+00 - val_loss: 0.0463 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 5 run in 2 epoch is [0.04632502421736717] \n",
            "704/704 - 2s - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 5 run in 3 epoch is [0.030581453815102577] \n",
            "704/704 - 3s - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 6 for the 5 run in 4 epoch is [0.0244921687990427] \n",
            "704/704 - 2s - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0222 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 6 for the 5 run in 5 epoch is [0.022163422778248787] \n",
            "mean Test MSE for latdim  6 among 5 runs for 5 epochs is 0.021668266132473947\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947]\n",
            "Now is the model with lat_dim '7' \n",
            "this is the 1 run for lat_dim: '7' \n",
            "Model: \"model_40\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_41 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 7)            1807        ['input_41[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_40 (Concatenate)   (None, 8)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_205 (Dense)              (None, 1)            9           ['concatenate_40[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,117\n",
            "Trainable params: 2,117\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.1096 - acc: 0.0000e+00 - val_loss: 0.0761 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 1 run in 1 epoch is [0.07608181238174438] \n",
            "704/704 - 2s - loss: 0.0575 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 7 for the 1 run in 2 epoch is [0.04234388470649719] \n",
            "704/704 - 3s - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0278 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 7 for the 1 run in 3 epoch is [0.027843991294503212] \n",
            "704/704 - 2s - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 7 for the 1 run in 4 epoch is [0.021889938041567802] \n",
            "704/704 - 2s - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0195 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 1 run in 5 epoch is [0.019518692046403885] \n",
            "this is the 2 run for lat_dim: '7' \n",
            "Model: \"model_41\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_42 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 7)            1807        ['input_42[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_41 (Concatenate)   (None, 8)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_210 (Dense)              (None, 1)            9           ['concatenate_41[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,117\n",
            "Trainable params: 2,117\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.1985 - acc: 0.0000e+00 - val_loss: 0.1457 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 2 run in 1 epoch is [0.14567945897579193] \n",
            "704/704 - 3s - loss: 0.1124 - acc: 0.0000e+00 - val_loss: 0.0840 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 7 for the 2 run in 2 epoch is [0.0840199738740921] \n",
            "704/704 - 2s - loss: 0.0667 - acc: 0.0000e+00 - val_loss: 0.0515 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 2 run in 3 epoch is [0.051492851227521896] \n",
            "704/704 - 2s - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 2 run in 4 epoch is [0.03437255695462227] \n",
            "704/704 - 2s - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 7 for the 2 run in 5 epoch is [0.025580842047929764] \n",
            "this is the 3 run for lat_dim: '7' \n",
            "Model: \"model_42\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_43 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 7)            1807        ['input_43[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_42 (Concatenate)   (None, 8)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_215 (Dense)              (None, 1)            9           ['concatenate_42[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,117\n",
            "Trainable params: 2,117\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.0826 - acc: 0.0000e+00 - val_loss: 0.0577 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 7 for the 3 run in 1 epoch is [0.057667024433612823] \n",
            "704/704 - 3s - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 7 for the 3 run in 2 epoch is [0.03419164568185806] \n",
            "704/704 - 3s - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 7 for the 3 run in 3 epoch is [0.0242423415184021] \n",
            "704/704 - 2s - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0200 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 7 for the 3 run in 4 epoch is [0.02003864198923111] \n",
            "704/704 - 4s - loss: 0.0192 - acc: 0.0000e+00 - val_loss: 0.0182 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 7 for the 3 run in 5 epoch is [0.018211035057902336] \n",
            "this is the 4 run for lat_dim: '7' \n",
            "Model: \"model_43\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_44 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 7)            1807        ['input_44[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_43 (Concatenate)   (None, 8)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_220 (Dense)              (None, 1)            9           ['concatenate_43[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,117\n",
            "Trainable params: 2,117\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 6s - loss: 0.1714 - acc: 0.0000e+00 - val_loss: 0.1128 - val_acc: 0.0000e+00 - 6s/epoch - 9ms/step\n",
            "loss of latdim 7 for the 4 run in 1 epoch is [0.11277984827756882] \n",
            "704/704 - 2s - loss: 0.0823 - acc: 0.0000e+00 - val_loss: 0.0581 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 4 run in 2 epoch is [0.058079712092876434] \n",
            "704/704 - 2s - loss: 0.0456 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 4 run in 3 epoch is [0.03552776575088501] \n",
            "704/704 - 2s - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 4 run in 4 epoch is [0.026381833478808403] \n",
            "704/704 - 2s - loss: 0.0244 - acc: 0.0000e+00 - val_loss: 0.0227 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 4 run in 5 epoch is [0.022699149325489998] \n",
            "this is the 5 run for lat_dim: '7' \n",
            "Model: \"model_44\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_45 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 7)            1807        ['input_45[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_44 (Concatenate)   (None, 8)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_225 (Dense)              (None, 1)            9           ['concatenate_44[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,117\n",
            "Trainable params: 2,117\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.0957 - acc: 0.0000e+00 - val_loss: 0.0754 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 7 for the 5 run in 1 epoch is [0.07544735819101334] \n",
            "704/704 - 2s - loss: 0.0626 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 5 run in 2 epoch is [0.050675518810749054] \n",
            "704/704 - 2s - loss: 0.0433 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 5 run in 3 epoch is [0.03624472767114639] \n",
            "704/704 - 2s - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0279 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 5 run in 4 epoch is [0.02789955772459507] \n",
            "704/704 - 2s - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 7 for the 5 run in 5 epoch is [0.023083973675966263] \n",
            "mean Test MSE for latdim  7 among 5 runs for 5 epochs is 0.02181873843073845\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845]\n",
            "Now is the model with lat_dim '8' \n",
            "this is the 1 run for lat_dim: '8' \n",
            "Model: \"model_45\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_46 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 8)            1908        ['input_46[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenate)   (None, 9)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_230 (Dense)              (None, 1)            10          ['concatenate_45[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,219\n",
            "Trainable params: 2,219\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 6s - loss: 0.4839 - acc: 0.0000e+00 - val_loss: 0.3411 - val_acc: 0.0000e+00 - 6s/epoch - 8ms/step\n",
            "loss of latdim 8 for the 1 run in 1 epoch is [0.34114184975624084] \n",
            "704/704 - 2s - loss: 0.2553 - acc: 0.0000e+00 - val_loss: 0.1836 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 1 run in 2 epoch is [0.18362191319465637] \n",
            "704/704 - 2s - loss: 0.1398 - acc: 0.0000e+00 - val_loss: 0.1027 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 1 run in 3 epoch is [0.10270484536886215] \n",
            "704/704 - 2s - loss: 0.0804 - acc: 0.0000e+00 - val_loss: 0.0610 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 1 run in 4 epoch is [0.0610298290848732] \n",
            "704/704 - 2s - loss: 0.0500 - acc: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 1 run in 5 epoch is [0.04017292708158493] \n",
            "this is the 2 run for lat_dim: '8' \n",
            "Model: \"model_46\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_47 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 8)            1908        ['input_47[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_46 (Concatenate)   (None, 9)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_235 (Dense)              (None, 1)            10          ['concatenate_46[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,219\n",
            "Trainable params: 2,219\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2556 - acc: 0.0000e+00 - val_loss: 0.1818 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 8 for the 2 run in 1 epoch is [0.1818360537290573] \n",
            "704/704 - 2s - loss: 0.1364 - acc: 0.0000e+00 - val_loss: 0.0986 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 2 run in 2 epoch is [0.09863528609275818] \n",
            "704/704 - 2s - loss: 0.0760 - acc: 0.0000e+00 - val_loss: 0.0572 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 2 run in 3 epoch is [0.05717584118247032] \n",
            "704/704 - 3s - loss: 0.0462 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 8 for the 2 run in 4 epoch is [0.036910898983478546] \n",
            "704/704 - 2s - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 2 run in 5 epoch is [0.027141448110342026] \n",
            "this is the 3 run for lat_dim: '8' \n",
            "Model: \"model_47\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_48 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 8)            1908        ['input_48[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_47 (Concatenate)   (None, 9)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_240 (Dense)              (None, 1)            10          ['concatenate_47[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,219\n",
            "Trainable params: 2,219\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.1141 - acc: 0.0000e+00 - val_loss: 0.0897 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 3 run in 1 epoch is [0.08969442546367645] \n",
            "704/704 - 2s - loss: 0.0739 - acc: 0.0000e+00 - val_loss: 0.0595 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 3 run in 2 epoch is [0.0595293752849102] \n",
            "704/704 - 2s - loss: 0.0504 - acc: 0.0000e+00 - val_loss: 0.0419 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 3 run in 3 epoch is [0.04187839850783348] \n",
            "704/704 - 2s - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.0315 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 3 run in 4 epoch is [0.0315169095993042] \n",
            "704/704 - 2s - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0254 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 3 run in 5 epoch is [0.025422951206564903] \n",
            "this is the 4 run for lat_dim: '8' \n",
            "Model: \"model_48\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_49 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 8)            1908        ['input_49[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_48 (Concatenate)   (None, 9)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_245 (Dense)              (None, 1)            10          ['concatenate_48[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,219\n",
            "Trainable params: 2,219\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.2098 - acc: 0.0000e+00 - val_loss: 0.1751 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 4 run in 1 epoch is [0.17505642771720886] \n",
            "704/704 - 2s - loss: 0.1497 - acc: 0.0000e+00 - val_loss: 0.1254 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 4 run in 2 epoch is [0.12536416947841644] \n",
            "704/704 - 2s - loss: 0.1079 - acc: 0.0000e+00 - val_loss: 0.0909 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 4 run in 3 epoch is [0.09087548404932022] \n",
            "704/704 - 2s - loss: 0.0789 - acc: 0.0000e+00 - val_loss: 0.0671 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 4 run in 4 epoch is [0.06713707745075226] \n",
            "704/704 - 2s - loss: 0.0591 - acc: 0.0000e+00 - val_loss: 0.0509 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 4 run in 5 epoch is [0.05092883110046387] \n",
            "this is the 5 run for lat_dim: '8' \n",
            "Model: \"model_49\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_50 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 8)            1908        ['input_50[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_49 (Concatenate)   (None, 9)            0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_250 (Dense)              (None, 1)            10          ['concatenate_49[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,219\n",
            "Trainable params: 2,219\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.4716 - acc: 0.0000e+00 - val_loss: 0.3956 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 8 for the 5 run in 1 epoch is [0.3956108093261719] \n",
            "704/704 - 2s - loss: 0.3384 - acc: 0.0000e+00 - val_loss: 0.2844 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 5 run in 2 epoch is [0.28441011905670166] \n",
            "704/704 - 2s - loss: 0.2442 - acc: 0.0000e+00 - val_loss: 0.2057 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 5 run in 3 epoch is [0.2056923657655716] \n",
            "704/704 - 3s - loss: 0.1774 - acc: 0.0000e+00 - val_loss: 0.1500 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 8 for the 5 run in 4 epoch is [0.1500249207019806] \n",
            "704/704 - 2s - loss: 0.1302 - acc: 0.0000e+00 - val_loss: 0.1107 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 8 for the 5 run in 5 epoch is [0.11069614440202713] \n",
            "mean Test MSE for latdim  8 among 5 runs for 5 epochs is 0.05087246038019657\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657]\n",
            "Now is the model with lat_dim '9' \n",
            "this is the 1 run for lat_dim: '9' \n",
            "Model: \"model_50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_51 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 9)            2009        ['input_51[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_50 (Concatenate)   (None, 10)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_255 (Dense)              (None, 1)            11          ['concatenate_50[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,321\n",
            "Trainable params: 2,321\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.2158 - acc: 0.0000e+00 - val_loss: 0.1747 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 9 for the 1 run in 1 epoch is [0.1747104674577713] \n",
            "704/704 - 2s - loss: 0.1448 - acc: 0.0000e+00 - val_loss: 0.1173 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 1 run in 2 epoch is [0.11726205796003342] \n",
            "704/704 - 2s - loss: 0.0977 - acc: 0.0000e+00 - val_loss: 0.0796 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 1 run in 3 epoch is [0.07960707694292068] \n",
            "704/704 - 3s - loss: 0.0671 - acc: 0.0000e+00 - val_loss: 0.0554 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 9 for the 1 run in 4 epoch is [0.05544576421380043] \n",
            "704/704 - 2s - loss: 0.0477 - acc: 0.0000e+00 - val_loss: 0.0403 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 1 run in 5 epoch is [0.040316950529813766] \n",
            "this is the 2 run for lat_dim: '9' \n",
            "Model: \"model_51\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_52 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 9)            2009        ['input_52[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_51 (Concatenate)   (None, 10)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_260 (Dense)              (None, 1)            11          ['concatenate_51[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,321\n",
            "Trainable params: 2,321\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.2098 - acc: 0.0000e+00 - val_loss: 0.1585 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 9 for the 2 run in 1 epoch is [0.15852056443691254] \n",
            "704/704 - 2s - loss: 0.1255 - acc: 0.0000e+00 - val_loss: 0.0966 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 2 run in 2 epoch is [0.0965699553489685] \n",
            "704/704 - 2s - loss: 0.0781 - acc: 0.0000e+00 - val_loss: 0.0616 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 2 run in 3 epoch is [0.06161647289991379] \n",
            "704/704 - 2s - loss: 0.0514 - acc: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 2 run in 4 epoch is [0.04201256483793259] \n",
            "704/704 - 2s - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 9 for the 2 run in 5 epoch is [0.03116689994931221] \n",
            "this is the 3 run for lat_dim: '9' \n",
            "Model: \"model_52\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_53 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 9)            2009        ['input_53[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_52 (Concatenate)   (None, 10)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_265 (Dense)              (None, 1)            11          ['concatenate_52[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,321\n",
            "Trainable params: 2,321\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.3996 - acc: 0.0000e+00 - val_loss: 0.2477 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 9 for the 3 run in 1 epoch is [0.24772609770298004] \n",
            "704/704 - 2s - loss: 0.1681 - acc: 0.0000e+00 - val_loss: 0.1067 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 3 run in 2 epoch is [0.10672308504581451] \n",
            "704/704 - 2s - loss: 0.0749 - acc: 0.0000e+00 - val_loss: 0.0505 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 3 run in 3 epoch is [0.05045785382390022] \n",
            "704/704 - 2s - loss: 0.0386 - acc: 0.0000e+00 - val_loss: 0.0294 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 3 run in 4 epoch is [0.029370438307523727] \n",
            "704/704 - 3s - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 9 for the 3 run in 5 epoch is [0.02190876193344593] \n",
            "this is the 4 run for lat_dim: '9' \n",
            "Model: \"model_53\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_54 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 9)            2009        ['input_54[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_53 (Concatenate)   (None, 10)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_270 (Dense)              (None, 1)            11          ['concatenate_53[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,321\n",
            "Trainable params: 2,321\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.6585 - acc: 0.0000e+00 - val_loss: 0.4932 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 9 for the 4 run in 1 epoch is [0.4931677281856537] \n",
            "704/704 - 2s - loss: 0.3784 - acc: 0.0000e+00 - val_loss: 0.2777 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 4 run in 2 epoch is [0.2777399718761444] \n",
            "704/704 - 2s - loss: 0.2099 - acc: 0.0000e+00 - val_loss: 0.1512 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 4 run in 3 epoch is [0.1512209177017212] \n",
            "704/704 - 3s - loss: 0.1140 - acc: 0.0000e+00 - val_loss: 0.0824 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 9 for the 4 run in 4 epoch is [0.08241958916187286] \n",
            "704/704 - 2s - loss: 0.0638 - acc: 0.0000e+00 - val_loss: 0.0480 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 4 run in 5 epoch is [0.0479927733540535] \n",
            "this is the 5 run for lat_dim: '9' \n",
            "Model: \"model_54\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_55 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 9)            2009        ['input_55[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_54 (Concatenate)   (None, 10)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_275 (Dense)              (None, 1)            11          ['concatenate_54[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,321\n",
            "Trainable params: 2,321\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2443 - acc: 0.0000e+00 - val_loss: 0.1859 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 9 for the 5 run in 1 epoch is [0.18586264550685883] \n",
            "704/704 - 2s - loss: 0.1475 - acc: 0.0000e+00 - val_loss: 0.1133 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 5 run in 2 epoch is [0.11325943470001221] \n",
            "704/704 - 2s - loss: 0.0911 - acc: 0.0000e+00 - val_loss: 0.0711 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 9 for the 5 run in 3 epoch is [0.07107141613960266] \n",
            "704/704 - 3s - loss: 0.0585 - acc: 0.0000e+00 - val_loss: 0.0469 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 9 for the 5 run in 4 epoch is [0.04691753908991814] \n",
            "704/704 - 2s - loss: 0.0400 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 9 for the 5 run in 5 epoch is [0.03334662318229675] \n",
            "mean Test MSE for latdim  9 among 5 runs for 5 epochs is 0.034946401789784434\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434]\n",
            "Now is the model with lat_dim '10' \n",
            "this is the 1 run for lat_dim: '10' \n",
            "Model: \"model_55\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_56 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 10)           2110        ['input_56[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_55 (Concatenate)   (None, 11)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_280 (Dense)              (None, 1)            12          ['concatenate_55[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,423\n",
            "Trainable params: 2,423\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.2442 - acc: 0.0000e+00 - val_loss: 0.2047 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 10 for the 1 run in 1 epoch is [0.20470121502876282] \n",
            "704/704 - 2s - loss: 0.1756 - acc: 0.0000e+00 - val_loss: 0.1477 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 10 for the 1 run in 2 epoch is [0.14771334826946259] \n",
            "704/704 - 2s - loss: 0.1274 - acc: 0.0000e+00 - val_loss: 0.1078 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 10 for the 1 run in 3 epoch is [0.10777667164802551] \n",
            "704/704 - 3s - loss: 0.0937 - acc: 0.0000e+00 - val_loss: 0.0799 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 10 for the 1 run in 4 epoch is [0.07985000312328339] \n",
            "704/704 - 2s - loss: 0.0701 - acc: 0.0000e+00 - val_loss: 0.0604 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 10 for the 1 run in 5 epoch is [0.060372136533260345] \n",
            "this is the 2 run for lat_dim: '10' \n",
            "Model: \"model_56\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_57 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 10)           2110        ['input_57[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_56 (Concatenate)   (None, 11)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_285 (Dense)              (None, 1)            12          ['concatenate_56[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,423\n",
            "Trainable params: 2,423\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.5737 - acc: 0.0000e+00 - val_loss: 0.4762 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 10 for the 2 run in 1 epoch is [0.47623056173324585] \n",
            "704/704 - 2s - loss: 0.4020 - acc: 0.0000e+00 - val_loss: 0.3327 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 10 for the 2 run in 2 epoch is [0.33268803358078003] \n",
            "704/704 - 2s - loss: 0.2802 - acc: 0.0000e+00 - val_loss: 0.2310 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 10 for the 2 run in 3 epoch is [0.23102208971977234] \n",
            "704/704 - 2s - loss: 0.1943 - acc: 0.0000e+00 - val_loss: 0.1597 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 10 for the 2 run in 4 epoch is [0.159686878323555] \n",
            "704/704 - 2s - loss: 0.1344 - acc: 0.0000e+00 - val_loss: 0.1105 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 10 for the 2 run in 5 epoch is [0.11045969277620316] \n",
            "this is the 3 run for lat_dim: '10' \n",
            "Model: \"model_57\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_58 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 10)           2110        ['input_58[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_57 (Concatenate)   (None, 11)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_290 (Dense)              (None, 1)            12          ['concatenate_57[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,423\n",
            "Trainable params: 2,423\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2380 - acc: 0.0000e+00 - val_loss: 0.1823 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 10 for the 3 run in 1 epoch is [0.18225006759166718] \n",
            "704/704 - 2s - loss: 0.1440 - acc: 0.0000e+00 - val_loss: 0.1096 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 10 for the 3 run in 2 epoch is [0.10959532111883163] \n",
            "704/704 - 2s - loss: 0.0870 - acc: 0.0000e+00 - val_loss: 0.0668 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 10 for the 3 run in 3 epoch is [0.06676160544157028] \n",
            "704/704 - 2s - loss: 0.0542 - acc: 0.0000e+00 - val_loss: 0.0427 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 10 for the 3 run in 4 epoch is [0.042745426297187805] \n",
            "704/704 - 3s - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 10 for the 3 run in 5 epoch is [0.02988332509994507] \n",
            "this is the 4 run for lat_dim: '10' \n",
            "Model: \"model_58\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_59 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 10)           2110        ['input_59[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_58 (Concatenate)   (None, 11)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_295 (Dense)              (None, 1)            12          ['concatenate_58[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,423\n",
            "Trainable params: 2,423\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.1355 - acc: 0.0000e+00 - val_loss: 0.1022 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 10 for the 4 run in 1 epoch is [0.1021576002240181] \n",
            "704/704 - 2s - loss: 0.0814 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 10 for the 4 run in 2 epoch is [0.06308825314044952] \n",
            "704/704 - 2s - loss: 0.0519 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 10 for the 4 run in 3 epoch is [0.04184269160032272] \n",
            "704/704 - 3s - loss: 0.0360 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 10 for the 4 run in 4 epoch is [0.030467480421066284] \n",
            "704/704 - 2s - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0245 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 10 for the 4 run in 5 epoch is [0.024497855454683304] \n",
            "this is the 5 run for lat_dim: '10' \n",
            "Model: \"model_59\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_60 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 10)           2110        ['input_60[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_59 (Concatenate)   (None, 11)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_300 (Dense)              (None, 1)            12          ['concatenate_59[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,423\n",
            "Trainable params: 2,423\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 10 for the 5 run in 1 epoch is [0.02659543976187706] \n",
            "704/704 - 2s - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0230 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 10 for the 5 run in 2 epoch is [0.0230304766446352] \n",
            "704/704 - 2s - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 10 for the 5 run in 3 epoch is [0.0208022128790617] \n",
            "704/704 - 2s - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0194 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 10 for the 5 run in 4 epoch is [0.019406652078032494] \n",
            "704/704 - 2s - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0185 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 10 for the 5 run in 5 epoch is [0.01853431575000286] \n",
            "mean Test MSE for latdim  10 among 5 runs for 5 epochs is 0.04874946512281895\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895]\n",
            "Now is the model with lat_dim '20' \n",
            "this is the 1 run for lat_dim: '20' \n",
            "Model: \"model_60\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_61 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 20)           3120        ['input_61[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_60 (Concatenate)   (None, 21)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_305 (Dense)              (None, 1)            22          ['concatenate_60[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,443\n",
            "Trainable params: 3,443\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.2446 - acc: 0.0000e+00 - val_loss: 0.2026 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 20 for the 1 run in 1 epoch is [0.20259788632392883] \n",
            "loss of latdim 20 for the 1 run in 2 epoch is [0.1429956704378128] \n",
            "704/704 - 2s - loss: 0.1221 - acc: 0.0000e+00 - val_loss: 0.1021 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 1 run in 3 epoch is [0.10208334028720856] \n",
            "704/704 - 2s - loss: 0.0879 - acc: 0.0000e+00 - val_loss: 0.0741 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 1 run in 4 epoch is [0.07414291054010391] \n",
            "704/704 - 2s - loss: 0.0646 - acc: 0.0000e+00 - val_loss: 0.0551 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 1 run in 5 epoch is [0.05511850491166115] \n",
            "this is the 2 run for lat_dim: '20' \n",
            "Model: \"model_61\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_62 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 20)           3120        ['input_62[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_61 (Concatenate)   (None, 21)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_310 (Dense)              (None, 1)            22          ['concatenate_61[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,443\n",
            "Trainable params: 3,443\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.2987 - acc: 0.0000e+00 - val_loss: 0.2377 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 20 for the 2 run in 1 epoch is [0.23771697282791138] \n",
            "704/704 - 2s - loss: 0.1952 - acc: 0.0000e+00 - val_loss: 0.1565 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 20 for the 2 run in 2 epoch is [0.15653139352798462] \n",
            "704/704 - 2s - loss: 0.1296 - acc: 0.0000e+00 - val_loss: 0.1048 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 2 run in 3 epoch is [0.10480143129825592] \n",
            "704/704 - 2s - loss: 0.0878 - acc: 0.0000e+00 - val_loss: 0.0719 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 2 run in 4 epoch is [0.07186312228441238] \n",
            "704/704 - 2s - loss: 0.0612 - acc: 0.0000e+00 - val_loss: 0.0511 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 2 run in 5 epoch is [0.051067233085632324] \n",
            "this is the 3 run for lat_dim: '20' \n",
            "Model: \"model_62\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_63 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 20)           3120        ['input_63[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_62 (Concatenate)   (None, 21)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_315 (Dense)              (None, 1)            22          ['concatenate_62[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,443\n",
            "Trainable params: 3,443\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.1812 - acc: 0.0000e+00 - val_loss: 0.1566 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 20 for the 3 run in 1 epoch is [0.1565752625465393] \n",
            "704/704 - 2s - loss: 0.1383 - acc: 0.0000e+00 - val_loss: 0.1200 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 20 for the 3 run in 2 epoch is [0.12000047415494919] \n",
            "704/704 - 2s - loss: 0.1066 - acc: 0.0000e+00 - val_loss: 0.0930 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 3 run in 3 epoch is [0.09301664680242538] \n",
            "704/704 - 2s - loss: 0.0833 - acc: 0.0000e+00 - val_loss: 0.0731 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 3 run in 4 epoch is [0.07312233000993729] \n",
            "704/704 - 2s - loss: 0.0660 - acc: 0.0000e+00 - val_loss: 0.0585 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 3 run in 5 epoch is [0.05845187231898308] \n",
            "this is the 4 run for lat_dim: '20' \n",
            "Model: \"model_63\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_64 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 20)           3120        ['input_64[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_63 (Concatenate)   (None, 21)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_320 (Dense)              (None, 1)            22          ['concatenate_63[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,443\n",
            "Trainable params: 3,443\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2899 - acc: 0.0000e+00 - val_loss: 0.2418 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 20 for the 4 run in 1 epoch is [0.24182043969631195] \n",
            "704/704 - 2s - loss: 0.2069 - acc: 0.0000e+00 - val_loss: 0.1740 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 4 run in 2 epoch is [0.17399077117443085] \n",
            "704/704 - 2s - loss: 0.1501 - acc: 0.0000e+00 - val_loss: 0.1272 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 20 for the 4 run in 3 epoch is [0.12715335190296173] \n",
            "704/704 - 2s - loss: 0.1106 - acc: 0.0000e+00 - val_loss: 0.0945 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 20 for the 4 run in 4 epoch is [0.09448406100273132] \n",
            "704/704 - 3s - loss: 0.0830 - acc: 0.0000e+00 - val_loss: 0.0716 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 20 for the 4 run in 5 epoch is [0.0715857520699501] \n",
            "this is the 5 run for lat_dim: '20' \n",
            "Model: \"model_64\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_65 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 20)           3120        ['input_65[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_64 (Concatenate)   (None, 21)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_325 (Dense)              (None, 1)            22          ['concatenate_64[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,443\n",
            "Trainable params: 3,443\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2760 - acc: 0.0000e+00 - val_loss: 0.2198 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 20 for the 5 run in 1 epoch is [0.2197854220867157] \n",
            "704/704 - 2s - loss: 0.1809 - acc: 0.0000e+00 - val_loss: 0.1455 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 20 for the 5 run in 2 epoch is [0.14551451802253723] \n",
            "704/704 - 2s - loss: 0.1210 - acc: 0.0000e+00 - val_loss: 0.0984 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 20 for the 5 run in 3 epoch is [0.09836717694997787] \n",
            "704/704 - 3s - loss: 0.0829 - acc: 0.0000e+00 - val_loss: 0.0684 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 20 for the 5 run in 4 epoch is [0.06835027039051056] \n",
            "704/704 - 2s - loss: 0.0587 - acc: 0.0000e+00 - val_loss: 0.0493 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 20 for the 5 run in 5 epoch is [0.04934841766953468] \n",
            "mean Test MSE for latdim  20 among 5 runs for 5 epochs is 0.057114356011152265\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895, 0.057114356011152265]\n",
            "Now is the model with lat_dim '30' \n",
            "this is the 1 run for lat_dim: '30' \n",
            "Model: \"model_65\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_66 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 30)           4130        ['input_66[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_65 (Concatenate)   (None, 31)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_330 (Dense)              (None, 1)            32          ['concatenate_65[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,463\n",
            "Trainable params: 4,463\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2736 - acc: 0.0000e+00 - val_loss: 0.2337 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 30 for the 1 run in 1 epoch is [0.23373857140541077] \n",
            "704/704 - 2s - loss: 0.2042 - acc: 0.0000e+00 - val_loss: 0.1755 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 30 for the 1 run in 2 epoch is [0.17549504339694977] \n",
            "704/704 - 3s - loss: 0.1544 - acc: 0.0000e+00 - val_loss: 0.1335 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 30 for the 1 run in 3 epoch is [0.13347308337688446] \n",
            "704/704 - 2s - loss: 0.1183 - acc: 0.0000e+00 - val_loss: 0.1029 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 30 for the 1 run in 4 epoch is [0.10293221473693848] \n",
            "704/704 - 2s - loss: 0.0919 - acc: 0.0000e+00 - val_loss: 0.0806 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 30 for the 1 run in 5 epoch is [0.08063562959432602] \n",
            "this is the 2 run for lat_dim: '30' \n",
            "Model: \"model_66\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_67 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 30)           4130        ['input_67[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_66 (Concatenate)   (None, 31)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_335 (Dense)              (None, 1)            32          ['concatenate_66[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,463\n",
            "Trainable params: 4,463\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2264 - acc: 0.0000e+00 - val_loss: 0.1887 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 30 for the 2 run in 1 epoch is [0.18874721229076385] \n",
            "704/704 - 2s - loss: 0.1615 - acc: 0.0000e+00 - val_loss: 0.1353 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 30 for the 2 run in 2 epoch is [0.13532862067222595] \n",
            "704/704 - 4s - loss: 0.1165 - acc: 0.0000e+00 - val_loss: 0.0982 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 30 for the 2 run in 3 epoch is [0.09820477664470673] \n",
            "704/704 - 4s - loss: 0.0853 - acc: 0.0000e+00 - val_loss: 0.0725 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 30 for the 2 run in 4 epoch is [0.07247555255889893] \n",
            "704/704 - 3s - loss: 0.0637 - acc: 0.0000e+00 - val_loss: 0.0548 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 30 for the 2 run in 5 epoch is [0.05476699769496918] \n",
            "this is the 3 run for lat_dim: '30' \n",
            "Model: \"model_67\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_68 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 30)           4130        ['input_68[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_67 (Concatenate)   (None, 31)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_340 (Dense)              (None, 1)            32          ['concatenate_67[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,463\n",
            "Trainable params: 4,463\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.2230 - acc: 0.0000e+00 - val_loss: 0.1800 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 30 for the 3 run in 1 epoch is [0.17997010052204132] \n",
            "704/704 - 3s - loss: 0.1491 - acc: 0.0000e+00 - val_loss: 0.1204 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 30 for the 3 run in 2 epoch is [0.12036178261041641] \n",
            "704/704 - 3s - loss: 0.1002 - acc: 0.0000e+00 - val_loss: 0.0813 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 30 for the 3 run in 3 epoch is [0.08128207176923752] \n",
            "704/704 - 4s - loss: 0.0685 - acc: 0.0000e+00 - val_loss: 0.0563 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 30 for the 3 run in 4 epoch is [0.056274354457855225] \n",
            "704/704 - 2s - loss: 0.0484 - acc: 0.0000e+00 - val_loss: 0.0407 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 30 for the 3 run in 5 epoch is [0.04070548340678215] \n",
            "this is the 4 run for lat_dim: '30' \n",
            "Model: \"model_68\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_69 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 30)           4130        ['input_69[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_68 (Concatenate)   (None, 31)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_345 (Dense)              (None, 1)            32          ['concatenate_68[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,463\n",
            "Trainable params: 4,463\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.2800 - acc: 0.0000e+00 - val_loss: 0.2321 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 30 for the 4 run in 1 epoch is [0.23207169771194458] \n",
            "704/704 - 3s - loss: 0.1980 - acc: 0.0000e+00 - val_loss: 0.1661 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 30 for the 4 run in 2 epoch is [0.16607879102230072] \n",
            "704/704 - 3s - loss: 0.1432 - acc: 0.0000e+00 - val_loss: 0.1214 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 30 for the 4 run in 3 epoch is [0.1213841438293457] \n",
            "704/704 - 2s - loss: 0.1058 - acc: 0.0000e+00 - val_loss: 0.0906 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 30 for the 4 run in 4 epoch is [0.09056166559457779] \n",
            "704/704 - 2s - loss: 0.0799 - acc: 0.0000e+00 - val_loss: 0.0692 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 30 for the 4 run in 5 epoch is [0.06915204972028732] \n",
            "this is the 5 run for lat_dim: '30' \n",
            "Model: \"model_69\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_70 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 30)           4130        ['input_70[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_69 (Concatenate)   (None, 31)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_350 (Dense)              (None, 1)            32          ['concatenate_69[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,463\n",
            "Trainable params: 4,463\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.2271 - acc: 0.0000e+00 - val_loss: 0.1963 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 30 for the 5 run in 1 epoch is [0.1963251531124115] \n",
            "704/704 - 3s - loss: 0.1732 - acc: 0.0000e+00 - val_loss: 0.1503 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 30 for the 5 run in 2 epoch is [0.150333970785141] \n",
            "704/704 - 2s - loss: 0.1334 - acc: 0.0000e+00 - val_loss: 0.1163 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 30 for the 5 run in 3 epoch is [0.11632023006677628] \n",
            "704/704 - 2s - loss: 0.1039 - acc: 0.0000e+00 - val_loss: 0.0911 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 30 for the 5 run in 4 epoch is [0.09113508462905884] \n",
            "704/704 - 4s - loss: 0.0820 - acc: 0.0000e+00 - val_loss: 0.0725 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 30 for the 5 run in 5 epoch is [0.07246807217597961] \n",
            "mean Test MSE for latdim  30 among 5 runs for 5 epochs is 0.06354564651846886\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895, 0.057114356011152265, 0.06354564651846886]\n",
            "Now is the model with lat_dim '40' \n",
            "this is the 1 run for lat_dim: '40' \n",
            "Model: \"model_70\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_71 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 40)           5140        ['input_71[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_70 (Concatenate)   (None, 41)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_355 (Dense)              (None, 1)            42          ['concatenate_70[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,483\n",
            "Trainable params: 5,483\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.1848 - acc: 0.0000e+00 - val_loss: 0.1595 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 40 for the 1 run in 1 epoch is [0.15953996777534485] \n",
            "704/704 - 2s - loss: 0.1408 - acc: 0.0000e+00 - val_loss: 0.1220 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 40 for the 1 run in 2 epoch is [0.12201762944459915] \n",
            "704/704 - 2s - loss: 0.1083 - acc: 0.0000e+00 - val_loss: 0.0943 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 40 for the 1 run in 3 epoch is [0.09432723373174667] \n",
            "704/704 - 2s - loss: 0.0843 - acc: 0.0000e+00 - val_loss: 0.0739 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 40 for the 1 run in 4 epoch is [0.07392077147960663] \n",
            "704/704 - 3s - loss: 0.0666 - acc: 0.0000e+00 - val_loss: 0.0589 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 40 for the 1 run in 5 epoch is [0.05892152711749077] \n",
            "this is the 2 run for lat_dim: '40' \n",
            "Model: \"model_71\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_72 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 40)           5140        ['input_72[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_71 (Concatenate)   (None, 41)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_360 (Dense)              (None, 1)            42          ['concatenate_71[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,483\n",
            "Trainable params: 5,483\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2402 - acc: 0.0000e+00 - val_loss: 0.1986 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 40 for the 2 run in 1 epoch is [0.1985827386379242] \n",
            "704/704 - 2s - loss: 0.1685 - acc: 0.0000e+00 - val_loss: 0.1400 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 40 for the 2 run in 2 epoch is [0.14001597464084625] \n",
            "704/704 - 3s - loss: 0.1197 - acc: 0.0000e+00 - val_loss: 0.1001 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 40 for the 2 run in 3 epoch is [0.10013753920793533] \n",
            "704/704 - 2s - loss: 0.0864 - acc: 0.0000e+00 - val_loss: 0.0730 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 40 for the 2 run in 4 epoch is [0.07295285910367966] \n",
            "704/704 - 3s - loss: 0.0637 - acc: 0.0000e+00 - val_loss: 0.0545 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 40 for the 2 run in 5 epoch is [0.05451979488134384] \n",
            "this is the 3 run for lat_dim: '40' \n",
            "Model: \"model_72\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_73 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 40)           5140        ['input_73[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_72 (Concatenate)   (None, 41)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_365 (Dense)              (None, 1)            42          ['concatenate_72[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,483\n",
            "Trainable params: 5,483\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2514 - acc: 0.0000e+00 - val_loss: 0.2175 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 40 for the 3 run in 1 epoch is [0.21746496856212616] \n",
            "704/704 - 2s - loss: 0.1917 - acc: 0.0000e+00 - val_loss: 0.1662 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 40 for the 3 run in 2 epoch is [0.16623182594776154] \n",
            "704/704 - 3s - loss: 0.1472 - acc: 0.0000e+00 - val_loss: 0.1281 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 40 for the 3 run in 3 epoch is [0.12810726463794708] \n",
            "704/704 - 2s - loss: 0.1140 - acc: 0.0000e+00 - val_loss: 0.0997 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 40 for the 3 run in 4 epoch is [0.09974215179681778] \n",
            "704/704 - 2s - loss: 0.0894 - acc: 0.0000e+00 - val_loss: 0.0787 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 40 for the 3 run in 5 epoch is [0.07865622639656067] \n",
            "this is the 4 run for lat_dim: '40' \n",
            "Model: \"model_73\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_74 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 40)           5140        ['input_74[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_73 (Concatenate)   (None, 41)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_370 (Dense)              (None, 1)            42          ['concatenate_73[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,483\n",
            "Trainable params: 5,483\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 6s - loss: 0.2815 - acc: 0.0000e+00 - val_loss: 0.2327 - val_acc: 0.0000e+00 - 6s/epoch - 8ms/step\n",
            "loss of latdim 40 for the 4 run in 1 epoch is [0.23266975581645966] \n",
            "704/704 - 2s - loss: 0.1980 - acc: 0.0000e+00 - val_loss: 0.1655 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 40 for the 4 run in 2 epoch is [0.16549748182296753] \n",
            "704/704 - 2s - loss: 0.1424 - acc: 0.0000e+00 - val_loss: 0.1202 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 40 for the 4 run in 3 epoch is [0.12017598748207092] \n",
            "704/704 - 2s - loss: 0.1045 - acc: 0.0000e+00 - val_loss: 0.0891 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 40 for the 4 run in 4 epoch is [0.08912662416696548] \n",
            "704/704 - 3s - loss: 0.0784 - acc: 0.0000e+00 - val_loss: 0.0677 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 40 for the 4 run in 5 epoch is [0.06770189106464386] \n",
            "this is the 5 run for lat_dim: '40' \n",
            "Model: \"model_74\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_75 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 40)           5140        ['input_75[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_74 (Concatenate)   (None, 41)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_375 (Dense)              (None, 1)            42          ['concatenate_74[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,483\n",
            "Trainable params: 5,483\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.1906 - acc: 0.0000e+00 - val_loss: 0.1563 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 40 for the 5 run in 1 epoch is [0.15627501904964447] \n",
            "704/704 - 3s - loss: 0.1317 - acc: 0.0000e+00 - val_loss: 0.1084 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 40 for the 5 run in 2 epoch is [0.10840709507465363] \n",
            "704/704 - 2s - loss: 0.0921 - acc: 0.0000e+00 - val_loss: 0.0765 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 40 for the 5 run in 3 epoch is [0.07651787996292114] \n",
            "704/704 - 4s - loss: 0.0659 - acc: 0.0000e+00 - val_loss: 0.0556 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 40 for the 5 run in 4 epoch is [0.05555170401930809] \n",
            "704/704 - 2s - loss: 0.0488 - acc: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 40 for the 5 run in 5 epoch is [0.04198530316352844] \n",
            "mean Test MSE for latdim  40 among 5 runs for 5 epochs is 0.060356948524713516\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895, 0.057114356011152265, 0.06354564651846886, 0.060356948524713516]\n",
            "Now is the model with lat_dim '50' \n",
            "this is the 1 run for lat_dim: '50' \n",
            "Model: \"model_75\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_76 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 50)           6150        ['input_76[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_75 (Concatenate)   (None, 51)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_380 (Dense)              (None, 1)            52          ['concatenate_75[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,503\n",
            "Trainable params: 6,503\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.1945 - acc: 0.0000e+00 - val_loss: 0.1591 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 50 for the 1 run in 1 epoch is [0.15906500816345215] \n",
            "704/704 - 3s - loss: 0.1336 - acc: 0.0000e+00 - val_loss: 0.1096 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 50 for the 1 run in 2 epoch is [0.10960598289966583] \n",
            "704/704 - 2s - loss: 0.0928 - acc: 0.0000e+00 - val_loss: 0.0768 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 50 for the 1 run in 3 epoch is [0.07679751515388489] \n",
            "704/704 - 3s - loss: 0.0659 - acc: 0.0000e+00 - val_loss: 0.0553 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 50 for the 1 run in 4 epoch is [0.05532047897577286] \n",
            "704/704 - 4s - loss: 0.0484 - acc: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 50 for the 1 run in 5 epoch is [0.04146444424986839] \n",
            "this is the 2 run for lat_dim: '50' \n",
            "Model: \"model_76\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_77 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 50)           6150        ['input_77[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_76 (Concatenate)   (None, 51)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_385 (Dense)              (None, 1)            52          ['concatenate_76[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,503\n",
            "Trainable params: 6,503\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.2250 - acc: 0.0000e+00 - val_loss: 0.1944 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 50 for the 2 run in 1 epoch is [0.19442644715309143] \n",
            "704/704 - 2s - loss: 0.1714 - acc: 0.0000e+00 - val_loss: 0.1486 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 50 for the 2 run in 2 epoch is [0.1485990583896637] \n",
            "704/704 - 3s - loss: 0.1317 - acc: 0.0000e+00 - val_loss: 0.1146 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 50 for the 2 run in 3 epoch is [0.11461121588945389] \n",
            "704/704 - 2s - loss: 0.1022 - acc: 0.0000e+00 - val_loss: 0.0894 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 50 for the 2 run in 4 epoch is [0.08942180126905441] \n",
            "704/704 - 2s - loss: 0.0803 - acc: 0.0000e+00 - val_loss: 0.0708 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 50 for the 2 run in 5 epoch is [0.07076998054981232] \n",
            "this is the 3 run for lat_dim: '50' \n",
            "Model: \"model_77\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_78 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 50)           6150        ['input_78[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_77 (Concatenate)   (None, 51)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_390 (Dense)              (None, 1)            52          ['concatenate_77[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,503\n",
            "Trainable params: 6,503\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2627 - acc: 0.0000e+00 - val_loss: 0.2266 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 50 for the 3 run in 1 epoch is [0.22661958634853363] \n",
            "704/704 - 4s - loss: 0.1994 - acc: 0.0000e+00 - val_loss: 0.1726 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 50 for the 3 run in 2 epoch is [0.17258502542972565] \n",
            "704/704 - 2s - loss: 0.1526 - acc: 0.0000e+00 - val_loss: 0.1326 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 50 for the 3 run in 3 epoch is [0.1325618326663971] \n",
            "704/704 - 3s - loss: 0.1178 - acc: 0.0000e+00 - val_loss: 0.1029 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 50 for the 3 run in 4 epoch is [0.10290078073740005] \n",
            "704/704 - 3s - loss: 0.0921 - acc: 0.0000e+00 - val_loss: 0.0809 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 50 for the 3 run in 5 epoch is [0.0808965414762497] \n",
            "this is the 4 run for lat_dim: '50' \n",
            "Model: \"model_78\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_79 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 50)           6150        ['input_79[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_78 (Concatenate)   (None, 51)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_395 (Dense)              (None, 1)            52          ['concatenate_78[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,503\n",
            "Trainable params: 6,503\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.2568 - acc: 0.0000e+00 - val_loss: 0.2163 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 50 for the 4 run in 1 epoch is [0.21625353395938873] \n",
            "704/704 - 2s - loss: 0.1867 - acc: 0.0000e+00 - val_loss: 0.1585 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 50 for the 4 run in 2 epoch is [0.1585141271352768] \n",
            "704/704 - 2s - loss: 0.1380 - acc: 0.0000e+00 - val_loss: 0.1180 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 50 for the 4 run in 3 epoch is [0.11799194663763046] \n",
            "704/704 - 2s - loss: 0.1036 - acc: 0.0000e+00 - val_loss: 0.0892 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 50 for the 4 run in 4 epoch is [0.08923500031232834] \n",
            "704/704 - 2s - loss: 0.0791 - acc: 0.0000e+00 - val_loss: 0.0688 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 50 for the 4 run in 5 epoch is [0.06875400990247726] \n",
            "this is the 5 run for lat_dim: '50' \n",
            "Model: \"model_79\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_80 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 50)           6150        ['input_80[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_79 (Concatenate)   (None, 51)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_400 (Dense)              (None, 1)            52          ['concatenate_79[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,503\n",
            "Trainable params: 6,503\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.1916 - acc: 0.0000e+00 - val_loss: 0.1585 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 50 for the 5 run in 1 epoch is [0.15854047238826752] \n",
            "704/704 - 3s - loss: 0.1344 - acc: 0.0000e+00 - val_loss: 0.1114 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 50 for the 5 run in 2 epoch is [0.11135882884263992] \n",
            "704/704 - 3s - loss: 0.0949 - acc: 0.0000e+00 - val_loss: 0.0791 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 50 for the 5 run in 3 epoch is [0.07905654609203339] \n",
            "704/704 - 2s - loss: 0.0681 - acc: 0.0000e+00 - val_loss: 0.0573 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 50 for the 5 run in 4 epoch is [0.057330790907144547] \n",
            "704/704 - 2s - loss: 0.0502 - acc: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 50 for the 5 run in 5 epoch is [0.043000202625989914] \n",
            "mean Test MSE for latdim  50 among 5 runs for 5 epochs is 0.06097703576087952\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895, 0.057114356011152265, 0.06354564651846886, 0.060356948524713516, 0.06097703576087952]\n",
            "Now is the model with lat_dim '60' \n",
            "this is the 1 run for lat_dim: '60' \n",
            "Model: \"model_80\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_81 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 60)           7160        ['input_81[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_80 (Concatenate)   (None, 61)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_405 (Dense)              (None, 1)            62          ['concatenate_80[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,523\n",
            "Trainable params: 7,523\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 5s - loss: 0.2264 - acc: 0.0000e+00 - val_loss: 0.1967 - val_acc: 0.0000e+00 - 5s/epoch - 8ms/step\n",
            "loss of latdim 60 for the 1 run in 1 epoch is [0.19668644666671753] \n",
            "704/704 - 2s - loss: 0.1742 - acc: 0.0000e+00 - val_loss: 0.1518 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 60 for the 1 run in 2 epoch is [0.15176883339881897] \n",
            "704/704 - 2s - loss: 0.1350 - acc: 0.0000e+00 - val_loss: 0.1181 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 60 for the 1 run in 3 epoch is [0.11812618374824524] \n",
            "704/704 - 2s - loss: 0.1057 - acc: 0.0000e+00 - val_loss: 0.0929 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 60 for the 1 run in 4 epoch is [0.09294643998146057] \n",
            "704/704 - 2s - loss: 0.0838 - acc: 0.0000e+00 - val_loss: 0.0741 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 60 for the 1 run in 5 epoch is [0.07411304861307144] \n",
            "this is the 2 run for lat_dim: '60' \n",
            "Model: \"model_81\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_82 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 60)           7160        ['input_82[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_81 (Concatenate)   (None, 61)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_410 (Dense)              (None, 1)            62          ['concatenate_81[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,523\n",
            "Trainable params: 7,523\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 6s - loss: 0.2055 - acc: 0.0000e+00 - val_loss: 0.1739 - val_acc: 0.0000e+00 - 6s/epoch - 8ms/step\n",
            "loss of latdim 60 for the 2 run in 1 epoch is [0.17390742897987366] \n",
            "704/704 - 3s - loss: 0.1504 - acc: 0.0000e+00 - val_loss: 0.1274 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 60 for the 2 run in 2 epoch is [0.12740083038806915] \n",
            "704/704 - 2s - loss: 0.1106 - acc: 0.0000e+00 - val_loss: 0.0941 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 60 for the 2 run in 3 epoch is [0.09406863898038864] \n",
            "704/704 - 4s - loss: 0.0822 - acc: 0.0000e+00 - val_loss: 0.0704 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 60 for the 2 run in 4 epoch is [0.07040908932685852] \n",
            "704/704 - 2s - loss: 0.0622 - acc: 0.0000e+00 - val_loss: 0.0538 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 60 for the 2 run in 5 epoch is [0.053796544671058655] \n",
            "this is the 3 run for lat_dim: '60' \n",
            "Model: \"model_82\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_83 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 60)           7160        ['input_83[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_82 (Concatenate)   (None, 61)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_415 (Dense)              (None, 1)            62          ['concatenate_82[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,523\n",
            "Trainable params: 7,523\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2538 - acc: 0.0000e+00 - val_loss: 0.2196 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 60 for the 3 run in 1 epoch is [0.21963471174240112] \n",
            "704/704 - 2s - loss: 0.1939 - acc: 0.0000e+00 - val_loss: 0.1684 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 60 for the 3 run in 2 epoch is [0.16840797662734985] \n",
            "704/704 - 3s - loss: 0.1494 - acc: 0.0000e+00 - val_loss: 0.1303 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 60 for the 3 run in 3 epoch is [0.1303400844335556] \n",
            "704/704 - 4s - loss: 0.1163 - acc: 0.0000e+00 - val_loss: 0.1020 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 60 for the 3 run in 4 epoch is [0.10201859474182129] \n",
            "704/704 - 2s - loss: 0.0917 - acc: 0.0000e+00 - val_loss: 0.0809 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 60 for the 3 run in 5 epoch is [0.0809115469455719] \n",
            "this is the 4 run for lat_dim: '60' \n",
            "Model: \"model_83\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_84 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 60)           7160        ['input_84[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_83 (Concatenate)   (None, 61)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_420 (Dense)              (None, 1)            62          ['concatenate_83[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,523\n",
            "Trainable params: 7,523\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2471 - acc: 0.0000e+00 - val_loss: 0.2107 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 60 for the 4 run in 1 epoch is [0.21072836220264435] \n",
            "704/704 - 4s - loss: 0.1835 - acc: 0.0000e+00 - val_loss: 0.1570 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 60 for the 4 run in 2 epoch is [0.1570006161928177] \n",
            "704/704 - 3s - loss: 0.1374 - acc: 0.0000e+00 - val_loss: 0.1181 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 60 for the 4 run in 3 epoch is [0.11806566268205643] \n",
            "704/704 - 2s - loss: 0.1039 - acc: 0.0000e+00 - val_loss: 0.0898 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 60 for the 4 run in 4 epoch is [0.08977349102497101] \n",
            "704/704 - 4s - loss: 0.0796 - acc: 0.0000e+00 - val_loss: 0.0693 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 60 for the 4 run in 5 epoch is [0.06928321719169617] \n",
            "this is the 5 run for lat_dim: '60' \n",
            "Model: \"model_84\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_85 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 60)           7160        ['input_85[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_84 (Concatenate)   (None, 61)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_425 (Dense)              (None, 1)            62          ['concatenate_84[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,523\n",
            "Trainable params: 7,523\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.2196 - acc: 0.0000e+00 - val_loss: 0.1877 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 60 for the 5 run in 1 epoch is [0.1876821517944336] \n",
            "704/704 - 4s - loss: 0.1637 - acc: 0.0000e+00 - val_loss: 0.1402 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 60 for the 5 run in 2 epoch is [0.1401783525943756] \n",
            "704/704 - 3s - loss: 0.1227 - acc: 0.0000e+00 - val_loss: 0.1054 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 60 for the 5 run in 3 epoch is [0.10538338869810104] \n",
            "704/704 - 2s - loss: 0.0928 - acc: 0.0000e+00 - val_loss: 0.0801 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 60 for the 5 run in 4 epoch is [0.08007325232028961] \n",
            "704/704 - 2s - loss: 0.0711 - acc: 0.0000e+00 - val_loss: 0.0618 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 60 for the 5 run in 5 epoch is [0.0618218258023262] \n",
            "mean Test MSE for latdim  60 among 5 runs for 5 epochs is 0.06798523664474487\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895, 0.057114356011152265, 0.06354564651846886, 0.060356948524713516, 0.06097703576087952, 0.06798523664474487]\n",
            "Now is the model with lat_dim '70' \n",
            "this is the 1 run for lat_dim: '70' \n",
            "Model: \"model_85\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_86 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 70)           8170        ['input_86[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_85 (Concatenate)   (None, 71)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_430 (Dense)              (None, 1)            72          ['concatenate_85[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,543\n",
            "Trainable params: 8,543\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.2395 - acc: 0.0000e+00 - val_loss: 0.2075 - val_acc: 0.0000e+00 - 4s/epoch - 6ms/step\n",
            "loss of latdim 70 for the 1 run in 1 epoch is [0.2074931114912033] \n",
            "704/704 - 2s - loss: 0.1834 - acc: 0.0000e+00 - val_loss: 0.1594 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 1 run in 2 epoch is [0.15943238139152527] \n",
            "704/704 - 2s - loss: 0.1416 - acc: 0.0000e+00 - val_loss: 0.1236 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 1 run in 3 epoch is [0.12361884862184525] \n",
            "704/704 - 2s - loss: 0.1104 - acc: 0.0000e+00 - val_loss: 0.0969 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 1 run in 4 epoch is [0.0969075858592987] \n",
            "704/704 - 2s - loss: 0.0872 - acc: 0.0000e+00 - val_loss: 0.0770 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 1 run in 5 epoch is [0.07697398960590363] \n",
            "this is the 2 run for lat_dim: '70' \n",
            "Model: \"model_86\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_87 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 70)           8170        ['input_87[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_86 (Concatenate)   (None, 71)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_435 (Dense)              (None, 1)            72          ['concatenate_86[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,543\n",
            "Trainable params: 8,543\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.2122 - acc: 0.0000e+00 - val_loss: 0.1836 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 70 for the 2 run in 1 epoch is [0.18360133469104767] \n",
            "704/704 - 2s - loss: 0.1620 - acc: 0.0000e+00 - val_loss: 0.1405 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 2 run in 2 epoch is [0.14048802852630615] \n",
            "704/704 - 2s - loss: 0.1245 - acc: 0.0000e+00 - val_loss: 0.1083 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 2 run in 3 epoch is [0.10831186175346375] \n",
            "704/704 - 2s - loss: 0.0965 - acc: 0.0000e+00 - val_loss: 0.0844 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 2 run in 4 epoch is [0.0843694880604744] \n",
            "704/704 - 2s - loss: 0.0757 - acc: 0.0000e+00 - val_loss: 0.0666 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 2 run in 5 epoch is [0.06662212312221527] \n",
            "this is the 3 run for lat_dim: '70' \n",
            "Model: \"model_87\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_88 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 70)           8170        ['input_88[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_87 (Concatenate)   (None, 71)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_440 (Dense)              (None, 1)            72          ['concatenate_87[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,543\n",
            "Trainable params: 8,543\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2545 - acc: 0.0000e+00 - val_loss: 0.2168 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 70 for the 3 run in 1 epoch is [0.21682323515415192] \n",
            "704/704 - 2s - loss: 0.1887 - acc: 0.0000e+00 - val_loss: 0.1615 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 3 run in 2 epoch is [0.16145391762256622] \n",
            "704/704 - 2s - loss: 0.1413 - acc: 0.0000e+00 - val_loss: 0.1215 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 3 run in 3 epoch is [0.12146418541669846] \n",
            "704/704 - 2s - loss: 0.1070 - acc: 0.0000e+00 - val_loss: 0.0925 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 3 run in 4 epoch is [0.09251254051923752] \n",
            "704/704 - 2s - loss: 0.0821 - acc: 0.0000e+00 - val_loss: 0.0716 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 3 run in 5 epoch is [0.07156242430210114] \n",
            "this is the 4 run for lat_dim: '70' \n",
            "Model: \"model_88\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_89 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 70)           8170        ['input_89[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_88 (Concatenate)   (None, 71)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_445 (Dense)              (None, 1)            72          ['concatenate_88[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,543\n",
            "Trainable params: 8,543\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 4s - loss: 0.2704 - acc: 0.0000e+00 - val_loss: 0.2306 - val_acc: 0.0000e+00 - 4s/epoch - 5ms/step\n",
            "loss of latdim 70 for the 4 run in 1 epoch is [0.23057040572166443] \n",
            "704/704 - 2s - loss: 0.2011 - acc: 0.0000e+00 - val_loss: 0.1725 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 4 run in 2 epoch is [0.17252804338932037] \n",
            "704/704 - 2s - loss: 0.1515 - acc: 0.0000e+00 - val_loss: 0.1308 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 4 run in 3 epoch is [0.13083982467651367] \n",
            "704/704 - 2s - loss: 0.1158 - acc: 0.0000e+00 - val_loss: 0.1006 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 70 for the 4 run in 4 epoch is [0.10060878098011017] \n",
            "704/704 - 2s - loss: 0.0897 - acc: 0.0000e+00 - val_loss: 0.0786 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 4 run in 5 epoch is [0.07857853919267654] \n",
            "this is the 5 run for lat_dim: '70' \n",
            "Model: \"model_89\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_90 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 70)           8170        ['input_90[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_89 (Concatenate)   (None, 71)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_450 (Dense)              (None, 1)            72          ['concatenate_89[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,543\n",
            "Trainable params: 8,543\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2401 - acc: 0.0000e+00 - val_loss: 0.2009 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 70 for the 5 run in 1 epoch is [0.20089595019817352] \n",
            "704/704 - 2s - loss: 0.1725 - acc: 0.0000e+00 - val_loss: 0.1454 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 5 run in 2 epoch is [0.14542065560817719] \n",
            "704/704 - 2s - loss: 0.1259 - acc: 0.0000e+00 - val_loss: 0.1069 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 5 run in 3 epoch is [0.10685095191001892] \n",
            "704/704 - 3s - loss: 0.0933 - acc: 0.0000e+00 - val_loss: 0.0799 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 70 for the 5 run in 4 epoch is [0.0799032598733902] \n",
            "704/704 - 2s - loss: 0.0705 - acc: 0.0000e+00 - val_loss: 0.0610 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 70 for the 5 run in 5 epoch is [0.06101314723491669] \n",
            "mean Test MSE for latdim  70 among 5 runs for 5 epochs is 0.07095004469156266\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895, 0.057114356011152265, 0.06354564651846886, 0.060356948524713516, 0.06097703576087952, 0.06798523664474487, 0.07095004469156266]\n",
            "Now is the model with lat_dim '80' \n",
            "this is the 1 run for lat_dim: '80' \n",
            "Model: \"model_90\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_91 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 80)           9180        ['input_91[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_90 (Concatenate)   (None, 81)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_455 (Dense)              (None, 1)            82          ['concatenate_90[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,563\n",
            "Trainable params: 9,563\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 2s - loss: 0.2508 - acc: 0.0000e+00 - val_loss: 0.2163 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 80 for the 1 run in 1 epoch is [0.2163301259279251] \n",
            "704/704 - 2s - loss: 0.1902 - acc: 0.0000e+00 - val_loss: 0.1645 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 80 for the 1 run in 2 epoch is [0.16449321806430817] \n",
            "704/704 - 2s - loss: 0.1453 - acc: 0.0000e+00 - val_loss: 0.1260 - val_acc: 0.0000e+00 - 2s/epoch - 4ms/step\n",
            "loss of latdim 80 for the 1 run in 3 epoch is [0.126044362783432] \n",
            "704/704 - 3s - loss: 0.1119 - acc: 0.0000e+00 - val_loss: 0.0976 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 80 for the 1 run in 4 epoch is [0.09755701571702957] \n",
            "704/704 - 2s - loss: 0.0872 - acc: 0.0000e+00 - val_loss: 0.0765 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 80 for the 1 run in 5 epoch is [0.07649008929729462] \n",
            "this is the 2 run for lat_dim: '80' \n",
            "Model: \"model_91\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_92 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 80)           9180        ['input_92[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_91 (Concatenate)   (None, 81)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_460 (Dense)              (None, 1)            82          ['concatenate_91[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,563\n",
            "Trainable params: 9,563\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.1953 - acc: 0.0000e+00 - val_loss: 0.1624 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 80 for the 2 run in 1 epoch is [0.16239148378372192] \n",
            "704/704 - 2s - loss: 0.1379 - acc: 0.0000e+00 - val_loss: 0.1143 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 2 run in 2 epoch is [0.11434236168861389] \n",
            "704/704 - 2s - loss: 0.0973 - acc: 0.0000e+00 - val_loss: 0.0808 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 2 run in 3 epoch is [0.08080911636352539] \n",
            "704/704 - 2s - loss: 0.0693 - acc: 0.0000e+00 - val_loss: 0.0581 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 2 run in 4 epoch is [0.05809418857097626] \n",
            "704/704 - 3s - loss: 0.0506 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 80 for the 2 run in 5 epoch is [0.04317509010434151] \n",
            "this is the 3 run for lat_dim: '80' \n",
            "Model: \"model_92\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_93 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 80)           9180        ['input_93[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_92 (Concatenate)   (None, 81)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_465 (Dense)              (None, 1)            82          ['concatenate_92[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,563\n",
            "Trainable params: 9,563\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2442 - acc: 0.0000e+00 - val_loss: 0.2120 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 80 for the 3 run in 1 epoch is [0.21196730434894562] \n",
            "704/704 - 2s - loss: 0.1875 - acc: 0.0000e+00 - val_loss: 0.1633 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 3 run in 2 epoch is [0.16329222917556763] \n",
            "704/704 - 2s - loss: 0.1452 - acc: 0.0000e+00 - val_loss: 0.1269 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 80 for the 3 run in 3 epoch is [0.1269179880619049] \n",
            "704/704 - 2s - loss: 0.1135 - acc: 0.0000e+00 - val_loss: 0.0997 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 3 run in 4 epoch is [0.09971826523542404] \n",
            "704/704 - 2s - loss: 0.0898 - acc: 0.0000e+00 - val_loss: 0.0794 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 80 for the 3 run in 5 epoch is [0.0793721154332161] \n",
            "this is the 4 run for lat_dim: '80' \n",
            "Model: \"model_93\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_94 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 80)           9180        ['input_94[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_93 (Concatenate)   (None, 81)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_470 (Dense)              (None, 1)            82          ['concatenate_93[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,563\n",
            "Trainable params: 9,563\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2497 - acc: 0.0000e+00 - val_loss: 0.2167 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 80 for the 4 run in 1 epoch is [0.21666967868804932] \n",
            "704/704 - 2s - loss: 0.1916 - acc: 0.0000e+00 - val_loss: 0.1667 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 4 run in 2 epoch is [0.16671240329742432] \n",
            "704/704 - 2s - loss: 0.1480 - acc: 0.0000e+00 - val_loss: 0.1293 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 4 run in 3 epoch is [0.12925156950950623] \n",
            "704/704 - 2s - loss: 0.1154 - acc: 0.0000e+00 - val_loss: 0.1012 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 4 run in 4 epoch is [0.10119098424911499] \n",
            "704/704 - 2s - loss: 0.0909 - acc: 0.0000e+00 - val_loss: 0.0802 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 4 run in 5 epoch is [0.08019100874662399] \n",
            "this is the 5 run for lat_dim: '80' \n",
            "Model: \"model_94\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_95 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 80)           9180        ['input_95[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_94 (Concatenate)   (None, 81)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_475 (Dense)              (None, 1)            82          ['concatenate_94[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,563\n",
            "Trainable params: 9,563\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2472 - acc: 0.0000e+00 - val_loss: 0.2145 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 80 for the 5 run in 1 epoch is [0.21454638242721558] \n",
            "704/704 - 2s - loss: 0.1898 - acc: 0.0000e+00 - val_loss: 0.1653 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 5 run in 2 epoch is [0.16526956856250763] \n",
            "704/704 - 2s - loss: 0.1469 - acc: 0.0000e+00 - val_loss: 0.1284 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 5 run in 3 epoch is [0.12836229801177979] \n",
            "704/704 - 2s - loss: 0.1147 - acc: 0.0000e+00 - val_loss: 0.1007 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 80 for the 5 run in 4 epoch is [0.100728340446949] \n",
            "704/704 - 3s - loss: 0.0906 - acc: 0.0000e+00 - val_loss: 0.0800 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 80 for the 5 run in 5 epoch is [0.08003377914428711] \n",
            "mean Test MSE for latdim  80 among 5 runs for 5 epochs is 0.07185241654515266\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895, 0.057114356011152265, 0.06354564651846886, 0.060356948524713516, 0.06097703576087952, 0.06798523664474487, 0.07095004469156266, 0.07185241654515266]\n",
            "Now is the model with lat_dim '90' \n",
            "this is the 1 run for lat_dim: '90' \n",
            "Model: \"model_95\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_96 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 90)           10190       ['input_96[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_95 (Concatenate)   (None, 91)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_480 (Dense)              (None, 1)            92          ['concatenate_95[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,583\n",
            "Trainable params: 10,583\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2137 - acc: 0.0000e+00 - val_loss: 0.1832 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 90 for the 1 run in 1 epoch is [0.1831965148448944] \n",
            "704/704 - 2s - loss: 0.1603 - acc: 0.0000e+00 - val_loss: 0.1377 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 1 run in 2 epoch is [0.13772760331630707] \n",
            "704/704 - 2s - loss: 0.1210 - acc: 0.0000e+00 - val_loss: 0.1044 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 1 run in 3 epoch is [0.10439810901880264] \n",
            "704/704 - 3s - loss: 0.0923 - acc: 0.0000e+00 - val_loss: 0.0801 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 90 for the 1 run in 4 epoch is [0.08011111617088318] \n",
            "704/704 - 2s - loss: 0.0714 - acc: 0.0000e+00 - val_loss: 0.0624 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 1 run in 5 epoch is [0.06244601309299469] \n",
            "this is the 2 run for lat_dim: '90' \n",
            "Model: \"model_96\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_97 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 90)           10190       ['input_97[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_96 (Concatenate)   (None, 91)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_485 (Dense)              (None, 1)            92          ['concatenate_96[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,583\n",
            "Trainable params: 10,583\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2140 - acc: 0.0000e+00 - val_loss: 0.1810 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 90 for the 2 run in 1 epoch is [0.1809724122285843] \n",
            "704/704 - 2s - loss: 0.1561 - acc: 0.0000e+00 - val_loss: 0.1320 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 2 run in 2 epoch is [0.13198161125183105] \n",
            "704/704 - 2s - loss: 0.1141 - acc: 0.0000e+00 - val_loss: 0.0966 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 2 run in 3 epoch is [0.09663421660661697] \n",
            "704/704 - 2s - loss: 0.0840 - acc: 0.0000e+00 - val_loss: 0.0715 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 2 run in 4 epoch is [0.07151082158088684] \n",
            "704/704 - 2s - loss: 0.0628 - acc: 0.0000e+00 - val_loss: 0.0540 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 2 run in 5 epoch is [0.05396319553256035] \n",
            "this is the 3 run for lat_dim: '90' \n",
            "Model: \"model_97\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_98 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 90)           10190       ['input_98[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_97 (Concatenate)   (None, 91)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_490 (Dense)              (None, 1)            92          ['concatenate_97[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,583\n",
            "Trainable params: 10,583\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2309 - acc: 0.0000e+00 - val_loss: 0.1981 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 90 for the 3 run in 1 epoch is [0.19812163710594177] \n",
            "704/704 - 3s - loss: 0.1739 - acc: 0.0000e+00 - val_loss: 0.1502 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 90 for the 3 run in 2 epoch is [0.15023544430732727] \n",
            "704/704 - 2s - loss: 0.1329 - acc: 0.0000e+00 - val_loss: 0.1156 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 3 run in 3 epoch is [0.11558570712804794] \n",
            "704/704 - 2s - loss: 0.1030 - acc: 0.0000e+00 - val_loss: 0.0903 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 3 run in 4 epoch is [0.09028839319944382] \n",
            "704/704 - 2s - loss: 0.0812 - acc: 0.0000e+00 - val_loss: 0.0717 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 3 run in 5 epoch is [0.07172810286283493] \n",
            "this is the 4 run for lat_dim: '90' \n",
            "Model: \"model_98\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_99 (InputLayer)          [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 90)           10190       ['input_99[0][0]']               \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_98 (Concatenate)   (None, 91)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_495 (Dense)              (None, 1)            92          ['concatenate_98[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,583\n",
            "Trainable params: 10,583\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2828 - acc: 0.0000e+00 - val_loss: 0.2388 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 90 for the 4 run in 1 epoch is [0.23880279064178467] \n",
            "704/704 - 3s - loss: 0.2066 - acc: 0.0000e+00 - val_loss: 0.1757 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 90 for the 4 run in 2 epoch is [0.17573897540569305] \n",
            "704/704 - 2s - loss: 0.1532 - acc: 0.0000e+00 - val_loss: 0.1313 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 4 run in 3 epoch is [0.13129359483718872] \n",
            "704/704 - 2s - loss: 0.1154 - acc: 0.0000e+00 - val_loss: 0.0996 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 4 run in 4 epoch is [0.0996081754565239] \n",
            "704/704 - 2s - loss: 0.0883 - acc: 0.0000e+00 - val_loss: 0.0769 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 4 run in 5 epoch is [0.07685429602861404] \n",
            "this is the 5 run for lat_dim: '90' \n",
            "Model: \"model_99\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_100 (InputLayer)         [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 90)           10190       ['input_100[0][0]']              \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_99 (Concatenate)   (None, 91)           0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_500 (Dense)              (None, 1)            92          ['concatenate_99[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,583\n",
            "Trainable params: 10,583\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2105 - acc: 0.0000e+00 - val_loss: 0.1772 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 90 for the 5 run in 1 epoch is [0.17724928259849548] \n",
            "704/704 - 2s - loss: 0.1527 - acc: 0.0000e+00 - val_loss: 0.1290 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 5 run in 2 epoch is [0.12896336615085602] \n",
            "704/704 - 2s - loss: 0.1117 - acc: 0.0000e+00 - val_loss: 0.0948 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 5 run in 3 epoch is [0.094758540391922] \n",
            "704/704 - 2s - loss: 0.0827 - acc: 0.0000e+00 - val_loss: 0.0708 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 5 run in 4 epoch is [0.07083547860383987] \n",
            "704/704 - 2s - loss: 0.0626 - acc: 0.0000e+00 - val_loss: 0.0542 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 90 for the 5 run in 5 epoch is [0.05422981083393097] \n",
            "mean Test MSE for latdim  90 among 5 runs for 5 epochs is 0.06384428367018699\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895, 0.057114356011152265, 0.06354564651846886, 0.060356948524713516, 0.06097703576087952, 0.06798523664474487, 0.07095004469156266, 0.07185241654515266, 0.06384428367018699]\n",
            "Now is the model with lat_dim '100' \n",
            "this is the 1 run for lat_dim: '100' \n",
            "Model: \"model_100\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_101 (InputLayer)         [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_101[0][0]']              \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_100 (Concatenate)  (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_505 (Dense)              (None, 1)            102         ['concatenate_100[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2711 - acc: 0.0000e+00 - val_loss: 0.2334 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 100 for the 1 run in 1 epoch is [0.23343420028686523] \n",
            "704/704 - 2s - loss: 0.2052 - acc: 0.0000e+00 - val_loss: 0.1776 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 1 run in 2 epoch is [0.17756196856498718] \n",
            "704/704 - 2s - loss: 0.1570 - acc: 0.0000e+00 - val_loss: 0.1366 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 1 run in 3 epoch is [0.1365738958120346] \n",
            "704/704 - 2s - loss: 0.1216 - acc: 0.0000e+00 - val_loss: 0.1063 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 100 for the 1 run in 4 epoch is [0.10633584856987] \n",
            "704/704 - 2s - loss: 0.0953 - acc: 0.0000e+00 - val_loss: 0.0839 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 1 run in 5 epoch is [0.08394451439380646] \n",
            "this is the 2 run for lat_dim: '100' \n",
            "Model: \"model_101\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_102 (InputLayer)         [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_102[0][0]']              \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_101 (Concatenate)  (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_510 (Dense)              (None, 1)            102         ['concatenate_101[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2514 - acc: 0.0000e+00 - val_loss: 0.2176 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 100 for the 2 run in 1 epoch is [0.2176235169172287] \n",
            "704/704 - 2s - loss: 0.1920 - acc: 0.0000e+00 - val_loss: 0.1666 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 2 run in 2 epoch is [0.16662229597568512] \n",
            "704/704 - 2s - loss: 0.1476 - acc: 0.0000e+00 - val_loss: 0.1286 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 2 run in 3 epoch is [0.12857471406459808] \n",
            "704/704 - 2s - loss: 0.1145 - acc: 0.0000e+00 - val_loss: 0.1002 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 2 run in 4 epoch is [0.10021744668483734] \n",
            "704/704 - 2s - loss: 0.0898 - acc: 0.0000e+00 - val_loss: 0.0791 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 2 run in 5 epoch is [0.07907751202583313] \n",
            "this is the 3 run for lat_dim: '100' \n",
            "Model: \"model_102\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_103 (InputLayer)         [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_103[0][0]']              \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_102 (Concatenate)  (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_515 (Dense)              (None, 1)            102         ['concatenate_102[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2451 - acc: 0.0000e+00 - val_loss: 0.2124 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 100 for the 3 run in 1 epoch is [0.21244215965270996] \n",
            "704/704 - 2s - loss: 0.1876 - acc: 0.0000e+00 - val_loss: 0.1630 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 3 run in 2 epoch is [0.16296550631523132] \n",
            "704/704 - 2s - loss: 0.1445 - acc: 0.0000e+00 - val_loss: 0.1259 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 3 run in 3 epoch is [0.12588660418987274] \n",
            "704/704 - 2s - loss: 0.1122 - acc: 0.0000e+00 - val_loss: 0.0981 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 3 run in 4 epoch is [0.09814131259918213] \n",
            "704/704 - 2s - loss: 0.0880 - acc: 0.0000e+00 - val_loss: 0.0774 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 3 run in 5 epoch is [0.07743009924888611] \n",
            "this is the 4 run for lat_dim: '100' \n",
            "Model: \"model_103\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_104 (InputLayer)         [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_104[0][0]']              \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_103 (Concatenate)  (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_520 (Dense)              (None, 1)            102         ['concatenate_103[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2131 - acc: 0.0000e+00 - val_loss: 0.1841 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 100 for the 4 run in 1 epoch is [0.18408387899398804] \n",
            "704/704 - 2s - loss: 0.1623 - acc: 0.0000e+00 - val_loss: 0.1407 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 100 for the 4 run in 2 epoch is [0.14073386788368225] \n",
            "704/704 - 2s - loss: 0.1247 - acc: 0.0000e+00 - val_loss: 0.1086 - val_acc: 0.0000e+00 - 2s/epoch - 2ms/step\n",
            "loss of latdim 100 for the 4 run in 3 epoch is [0.10861184448003769] \n",
            "704/704 - 2s - loss: 0.0969 - acc: 0.0000e+00 - val_loss: 0.0848 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 4 run in 4 epoch is [0.08482052385807037] \n",
            "704/704 - 2s - loss: 0.0762 - acc: 0.0000e+00 - val_loss: 0.0672 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 4 run in 5 epoch is [0.06722119450569153] \n",
            "this is the 5 run for lat_dim: '100' \n",
            "Model: \"model_104\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_105 (InputLayer)         [(None, 10)]         0           []                               \n",
            "                                                                                                  \n",
            " function1 (Sequential)         (None, 100)          11200       ['input_105[0][0]']              \n",
            "                                                                                                  \n",
            " function2 (Sequential)         (None, 1)            301         ['function1[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_104 (Concatenate)  (None, 101)          0           ['function1[0][0]',              \n",
            "                                                                  'function2[0][0]']              \n",
            "                                                                                                  \n",
            " dense_525 (Dense)              (None, 1)            102         ['concatenate_104[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,603\n",
            "Trainable params: 11,603\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "704/704 - 3s - loss: 0.2252 - acc: 0.0000e+00 - val_loss: 0.1936 - val_acc: 0.0000e+00 - 3s/epoch - 5ms/step\n",
            "loss of latdim 100 for the 5 run in 1 epoch is [0.1936250627040863] \n",
            "704/704 - 2s - loss: 0.1697 - acc: 0.0000e+00 - val_loss: 0.1461 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 5 run in 2 epoch is [0.14614985883235931] \n",
            "704/704 - 2s - loss: 0.1286 - acc: 0.0000e+00 - val_loss: 0.1110 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 5 run in 3 epoch is [0.11102176457643509] \n",
            "704/704 - 3s - loss: 0.0982 - acc: 0.0000e+00 - val_loss: 0.0852 - val_acc: 0.0000e+00 - 3s/epoch - 4ms/step\n",
            "loss of latdim 100 for the 5 run in 4 epoch is [0.08517717570066452] \n",
            "704/704 - 2s - loss: 0.0759 - acc: 0.0000e+00 - val_loss: 0.0663 - val_acc: 0.0000e+00 - 2s/epoch - 3ms/step\n",
            "loss of latdim 100 for the 5 run in 5 epoch is [0.06628897041082382] \n",
            "mean Test MSE for latdim  100 among 5 runs for 5 epochs is 0.07479245811700821\n",
            "[0.02006580904126167, 0.01756335087120533, 0.02175130173563957, 0.038843799754977225, 0.025705435127019883, 0.021668266132473947, 0.02181873843073845, 0.05087246038019657, 0.034946401789784434, 0.04874946512281895, 0.057114356011152265, 0.06354564651846886, 0.060356948524713516, 0.06097703576087952, 0.06798523664474487, 0.07095004469156266, 0.07185241654515266, 0.06384428367018699, 0.07479245811700821]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# P2-permutation-equivariant functions"
      ],
      "metadata": {
        "id": "F50vng04_nSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### P2.1 Implement the neural network"
      ],
      "metadata": {
        "id": "-dPWJmCd_8dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ML modules\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Input, Lambda, Activation, Conv1D\n",
        "# early stopping, callback, all the steps you are running you can ask the model to stop...\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# general stuff\n",
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# data reading\n",
        "df1 = pd.read_csv('/content/xtrain-2.csv', na_values=['NA','?'])\n",
        "df2 = pd.read_csv('/content/xtest-2.csv', na_values=['NA','?'])\n",
        "df3 = pd.read_csv('/content/ytrain-2.csv', na_values=['NA','?'])\n",
        "df4 = pd.read_csv('/content/ytest-2.csv', na_values=['NA','?'])\n",
        "\n",
        "# data pre-processing\n",
        "\n",
        "X_train = df1.astype('float32')\n",
        "y_train = df3.astype('float32')\n",
        "\n",
        "X_test = df2.astype('float32')\n",
        "y_test = df4.astype('float32')\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "df1.values\n",
        "df2.values\n",
        "df3.values\n",
        "df4.values\n",
        "\n",
        "n_features = X_train.shape[1]\n",
        "n_features\n"
      ],
      "metadata": {
        "id": "MOWjM9KZ_2on",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd146476-2fa2-4cfa-d8e1-1317feb69ec4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(97750, 16) (200000, 6) (97747, 16) (200000, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the model\n",
        "#the name of the model\n",
        "\n",
        "\n",
        "def eq_model(num):\n",
        "  model=Sequential([\n",
        "      Conv1D(filters=10, kernel_size=3, strides=1, padding='same', input_shape=(X_train.shape[1], 1)),\n",
        "      keras.layers.ReLU(),\n",
        "      Conv1D(filters=10, kernel_size=3, strides=1, padding='same'),\n",
        "      keras.layers.ReLU(),\n",
        "      keras.layers.Flatten(),\n",
        "      Dense(units=100),\n",
        "      keras.layers.ReLU(),\n",
        "      Dense(units=y_train.shape[1])\n",
        "])\n",
        "  \n",
        "#set the optimizer with the learning rate of 1e-4 and epsilon of 1e-3\n",
        "  optimizer1 =Adam(learning_rate=1e-4,epsilon=1e-3)\n",
        "#compile the first model with loss MSE and metrics ACC\n",
        "  model.compile(loss='MSE',optimizer='Adam',  metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "#train the model of validation split 0.1 and batch size of 128\n",
        "for num in [(2,10), (2,100), (2,200),(3,5),(3,10),(3,100),(3,200)]:\n",
        "  model_4=eq_model(num)\n",
        "  history = model_4.fit(X_train, y_train, batch_size=300, epochs=100, verbose=2, validation_split=0.1)\n",
        "  train_loss=history.history[\"loss\"]\n",
        "  val_loss=history.history[\"val_loss\"]\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "metadata": {
        "id": "xoxMvGx51MW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2642bca-b560-45c9-e28e-5c7a4da3d9f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "294/294 - 3s - loss: 29438602.0000 - acc: 0.9898 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 9ms/step\n",
            "Epoch 2/100\n",
            "294/294 - 2s - loss: 5.4017 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 3/100\n",
            "294/294 - 2s - loss: 3.2007 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 8ms/step\n",
            "Epoch 4/100\n",
            "294/294 - 3s - loss: 3.1376 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 9ms/step\n",
            "Epoch 5/100\n",
            "294/294 - 3s - loss: 22.0095 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 10ms/step\n",
            "Epoch 6/100\n",
            "294/294 - 3s - loss: 10.4507 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 10ms/step\n",
            "Epoch 7/100\n",
            "294/294 - 3s - loss: 30.6513 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 10ms/step\n",
            "Epoch 8/100\n",
            "294/294 - 3s - loss: 9.2601 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 9ms/step\n",
            "Epoch 9/100\n",
            "294/294 - 3s - loss: 43.3917 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 10ms/step\n",
            "Epoch 10/100\n",
            "294/294 - 3s - loss: 36.5045 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 10ms/step\n",
            "Epoch 11/100\n",
            "294/294 - 3s - loss: 48.6480 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 10ms/step\n",
            "Epoch 12/100\n",
            "294/294 - 1s - loss: 52.5977 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "294/294 - 1s - loss: 84.7910 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "294/294 - 2s - loss: 98.3914 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "294/294 - 2s - loss: 19.8842 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "294/294 - 2s - loss: 660.4274 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "294/294 - 2s - loss: 813.7438 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 18/100\n",
            "294/294 - 2s - loss: 1.0492 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "294/294 - 2s - loss: 0.9337 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 20/100\n",
            "294/294 - 2s - loss: 0.9870 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "294/294 - 1s - loss: 835.2359 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "294/294 - 2s - loss: 0.6191 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "294/294 - 2s - loss: 136.7869 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "294/294 - 2s - loss: 125.9080 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 25/100\n",
            "294/294 - 2s - loss: 333.4232 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 26/100\n",
            "294/294 - 2s - loss: 192.7723 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "294/294 - 1s - loss: 337.3193 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "294/294 - 1s - loss: 452.1886 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "294/294 - 2s - loss: 536.6003 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "294/294 - 2s - loss: 693.0807 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "294/294 - 2s - loss: 653.5947 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 32/100\n",
            "294/294 - 2s - loss: 562.8270 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 33/100\n",
            "294/294 - 2s - loss: 487.9703 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "294/294 - 2s - loss: 565.7991 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "294/294 - 2s - loss: 1849.8951 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "294/294 - 2s - loss: 0.6035 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "294/294 - 2s - loss: 1289.6581 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "294/294 - 2s - loss: 57.5885 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "294/294 - 2s - loss: 447.8766 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "294/294 - 2s - loss: 852.5727 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "294/294 - 2s - loss: 212.7232 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "294/294 - 2s - loss: 753.8318 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "294/294 - 1s - loss: 527.8146 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "294/294 - 2s - loss: 666.7535 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "294/294 - 2s - loss: 328.9857 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 46/100\n",
            "294/294 - 2s - loss: 757.3710 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 47/100\n",
            "294/294 - 2s - loss: 1195.5490 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "294/294 - 1s - loss: 134.0731 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "294/294 - 2s - loss: 301.6693 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "294/294 - 2s - loss: 619.8127 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "294/294 - 2s - loss: 820.4679 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "294/294 - 2s - loss: 416.5493 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "294/294 - 2s - loss: 792.0801 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 54/100\n",
            "294/294 - 2s - loss: 391.8137 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "294/294 - 1s - loss: 556.2380 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "294/294 - 1s - loss: 615.7596 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "294/294 - 1s - loss: 1792.0773 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "294/294 - 1s - loss: 28.1976 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "294/294 - 2s - loss: 258.1880 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "294/294 - 2s - loss: 662.9027 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "294/294 - 2s - loss: 748.6715 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "294/294 - 1s - loss: 39.6853 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "294/294 - 2s - loss: 599.2993 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "294/294 - 2s - loss: 754.9840 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "294/294 - 2s - loss: 431.2757 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "294/294 - 2s - loss: 415.5661 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "294/294 - 2s - loss: 1001.2452 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "294/294 - 2s - loss: 2.2762 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "294/294 - 2s - loss: 557.9161 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "294/294 - 2s - loss: 5742.5688 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "294/294 - 2s - loss: 0.1537 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 72/100\n",
            "294/294 - 1s - loss: 0.1621 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "294/294 - 2s - loss: 459.5764 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "294/294 - 2s - loss: 1133.5549 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "294/294 - 2s - loss: 25.7916 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 76/100\n",
            "294/294 - 2s - loss: 29.8991 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "294/294 - 2s - loss: 444.3221 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "294/294 - 2s - loss: 946.3064 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "294/294 - 1s - loss: 58.8324 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "294/294 - 2s - loss: 564.3598 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "294/294 - 2s - loss: 942.7369 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 82/100\n",
            "294/294 - 2s - loss: 61.5921 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 83/100\n",
            "294/294 - 1s - loss: 1136.9943 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "294/294 - 2s - loss: 2.4640 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "294/294 - 2s - loss: 430.6576 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "294/294 - 2s - loss: 282.0413 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 87/100\n",
            "294/294 - 2s - loss: 708.1322 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "294/294 - 2s - loss: 750.5432 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "294/294 - 2s - loss: 21.4450 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 90/100\n",
            "294/294 - 2s - loss: 686.3665 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "294/294 - 2s - loss: 377.6703 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "294/294 - 2s - loss: 448.6044 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "294/294 - 2s - loss: 621.0162 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "294/294 - 2s - loss: 1596.9996 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 95/100\n",
            "294/294 - 2s - loss: 121.4336 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 96/100\n",
            "294/294 - 2s - loss: 126.3183 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "294/294 - 1s - loss: 419.4123 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "294/294 - 2s - loss: 475.7376 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "294/294 - 2s - loss: 560.0393 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "294/294 - 1s - loss: 912.0143 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 1/100\n",
            "294/294 - 3s - loss: 37738696.0000 - acc: 0.9932 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 9ms/step\n",
            "Epoch 2/100\n",
            "294/294 - 2s - loss: 16.1412 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "294/294 - 2s - loss: 67.9488 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 4/100\n",
            "294/294 - 2s - loss: 341.7028 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "294/294 - 2s - loss: 3.5820 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "294/294 - 2s - loss: 3.3687 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "294/294 - 2s - loss: 3.2468 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 8/100\n",
            "294/294 - 2s - loss: 3.1086 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "294/294 - 2s - loss: 2.9478 - acc: 0.9999 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "294/294 - 2s - loss: 2.7878 - acc: 0.9999 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "294/294 - 1s - loss: 3.2058 - acc: 0.9999 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "294/294 - 2s - loss: 215.0810 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "294/294 - 2s - loss: 30.9121 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 14/100\n",
            "294/294 - 2s - loss: 67.6651 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 15/100\n",
            "294/294 - 2s - loss: 87.9938 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "294/294 - 2s - loss: 235.4674 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "294/294 - 2s - loss: 1.6446 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "294/294 - 1s - loss: 132.6691 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "294/294 - 2s - loss: 168.1490 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 20/100\n",
            "294/294 - 2s - loss: 137.0888 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 21/100\n",
            "294/294 - 2s - loss: 144.5888 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "294/294 - 2s - loss: 118.0200 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 23/100\n",
            "294/294 - 2s - loss: 231.4874 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "294/294 - 2s - loss: 206.9712 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "294/294 - 1s - loss: 252.2784 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "294/294 - 2s - loss: 112.3482 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "294/294 - 2s - loss: 185.5175 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 28/100\n",
            "294/294 - 2s - loss: 268.0887 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 29/100\n",
            "294/294 - 2s - loss: 692.3293 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "294/294 - 2s - loss: 897.7872 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 31/100\n",
            "294/294 - 2s - loss: 116.1393 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "294/294 - 2s - loss: 637.1262 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "294/294 - 1s - loss: 461.7438 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "294/294 - 2s - loss: 368.3099 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "294/294 - 2s - loss: 952.0046 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "294/294 - 2s - loss: 124.6517 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "294/294 - 2s - loss: 640.4848 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "294/294 - 2s - loss: 396.8557 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "294/294 - 1s - loss: 393.9329 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "294/294 - 2s - loss: 482.1868 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "294/294 - 2s - loss: 829.1263 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "294/294 - 2s - loss: 290.6586 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 43/100\n",
            "294/294 - 2s - loss: 595.9976 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "294/294 - 2s - loss: 325.2437 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "294/294 - 2s - loss: 752.0974 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "294/294 - 2s - loss: 662.4119 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 47/100\n",
            "294/294 - 2s - loss: 435.8141 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "294/294 - 2s - loss: 399.7691 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "294/294 - 2s - loss: 323.6048 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 50/100\n",
            "294/294 - 2s - loss: 358.0124 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "294/294 - 2s - loss: 811.7357 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "294/294 - 2s - loss: 632.0692 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "294/294 - 2s - loss: 279.9085 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 54/100\n",
            "294/294 - 2s - loss: 936.6904 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "294/294 - 1s - loss: 69.9813 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "294/294 - 2s - loss: 921.7529 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "294/294 - 2s - loss: 48.8313 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "294/294 - 2s - loss: 970.6142 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 59/100\n",
            "294/294 - 2s - loss: 154.4935 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "294/294 - 2s - loss: 614.7688 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "294/294 - 1s - loss: 333.3864 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "294/294 - 1s - loss: 396.1011 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "294/294 - 2s - loss: 1102.2760 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "294/294 - 1s - loss: 209.8580 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "294/294 - 1s - loss: 345.2113 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "294/294 - 2s - loss: 505.1227 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "294/294 - 2s - loss: 474.8967 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "294/294 - 2s - loss: 515.0771 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "294/294 - 1s - loss: 616.6901 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "294/294 - 2s - loss: 433.2347 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 71/100\n",
            "294/294 - 1s - loss: 1385.4358 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "294/294 - 2s - loss: 46.8742 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "294/294 - 2s - loss: 260.2009 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "294/294 - 2s - loss: 785.1296 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "294/294 - 2s - loss: 515.4596 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "294/294 - 2s - loss: 650.9891 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "294/294 - 2s - loss: 299.4583 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 78/100\n",
            "294/294 - 2s - loss: 848.1737 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "294/294 - 2s - loss: 466.9024 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "294/294 - 1s - loss: 30.1084 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "294/294 - 1s - loss: 1408.3041 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "294/294 - 1s - loss: 151.6741 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "294/294 - 1s - loss: 140.2064 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "294/294 - 2s - loss: 677.8915 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 85/100\n",
            "294/294 - 2s - loss: 443.6331 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 86/100\n",
            "294/294 - 1s - loss: 494.1126 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "294/294 - 2s - loss: 542.5424 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 88/100\n",
            "294/294 - 1s - loss: 260.0190 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "294/294 - 2s - loss: 468.3976 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "294/294 - 1s - loss: 353.0407 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "294/294 - 2s - loss: 499.3465 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "294/294 - 2s - loss: 332.6686 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 93/100\n",
            "294/294 - 2s - loss: 647.5184 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "294/294 - 2s - loss: 385.6547 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "294/294 - 2s - loss: 1072.5161 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "294/294 - 1s - loss: 36.0440 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "294/294 - 2s - loss: 556.9667 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "294/294 - 1s - loss: 314.6212 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "294/294 - 2s - loss: 295.8983 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 8ms/step\n",
            "Epoch 100/100\n",
            "294/294 - 2s - loss: 732.7501 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 1/100\n",
            "294/294 - 2s - loss: 32480094.0000 - acc: 0.9908 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "294/294 - 2s - loss: 54.4367 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "294/294 - 2s - loss: 11.2066 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "294/294 - 2s - loss: 3.9621 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 5/100\n",
            "294/294 - 2s - loss: 3.7127 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "294/294 - 2s - loss: 4.6221 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "294/294 - 1s - loss: 3.6037 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "294/294 - 1s - loss: 3.4149 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "294/294 - 1s - loss: 3.2164 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "294/294 - 1s - loss: 3.0125 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "294/294 - 2s - loss: 7.9968 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 12/100\n",
            "294/294 - 2s - loss: 45.5181 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "294/294 - 2s - loss: 3.8368 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "294/294 - 2s - loss: 56.1640 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 15/100\n",
            "294/294 - 2s - loss: 13.5142 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "294/294 - 2s - loss: 43.0443 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "294/294 - 2s - loss: 19.5627 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "294/294 - 2s - loss: 62.2326 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 19/100\n",
            "294/294 - 2s - loss: 8.9961 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 20/100\n",
            "294/294 - 1s - loss: 78.5104 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "294/294 - 2s - loss: 70.2098 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "294/294 - 2s - loss: 88.4606 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "294/294 - 2s - loss: 93.5012 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "294/294 - 2s - loss: 97.4636 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "294/294 - 2s - loss: 93.8422 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 26/100\n",
            "294/294 - 2s - loss: 140.3537 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 27/100\n",
            "294/294 - 2s - loss: 526.3948 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "294/294 - 2s - loss: 337.9901 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "294/294 - 2s - loss: 635.6122 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "294/294 - 1s - loss: 541.1536 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "294/294 - 2s - loss: 789.8470 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "294/294 - 2s - loss: 1479.4080 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 33/100\n",
            "294/294 - 2s - loss: 0.3116 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 8ms/step\n",
            "Epoch 34/100\n",
            "294/294 - 2s - loss: 765.6022 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "294/294 - 2s - loss: 649.3304 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "294/294 - 2s - loss: 538.5672 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "294/294 - 2s - loss: 819.9601 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "294/294 - 2s - loss: 938.0273 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "294/294 - 2s - loss: 127.9452 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 40/100\n",
            "294/294 - 2s - loss: 803.1024 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "294/294 - 2s - loss: 576.2242 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "294/294 - 2s - loss: 931.5688 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "294/294 - 2s - loss: 630.8729 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "294/294 - 2s - loss: 651.6236 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "294/294 - 1s - loss: 331.0609 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "294/294 - 2s - loss: 535.5518 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "294/294 - 2s - loss: 495.1527 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 48/100\n",
            "294/294 - 2s - loss: 861.5622 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "294/294 - 1s - loss: 1134.6479 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "294/294 - 2s - loss: 456.5105 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 51/100\n",
            "294/294 - 1s - loss: 1074.5652 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "294/294 - 1s - loss: 277.6666 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "294/294 - 2s - loss: 370.6502 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "294/294 - 2s - loss: 2067.6008 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 55/100\n",
            "294/294 - 2s - loss: 0.9032 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "294/294 - 2s - loss: 481.8091 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "294/294 - 2s - loss: 512.2675 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "294/294 - 2s - loss: 1595.3683 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "294/294 - 1s - loss: 31.2828 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "294/294 - 1s - loss: 153.2097 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "294/294 - 2s - loss: 655.7386 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 62/100\n",
            "294/294 - 2s - loss: 456.8618 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "294/294 - 1s - loss: 1465.0599 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "294/294 - 2s - loss: 117.6603 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "294/294 - 2s - loss: 753.9698 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "294/294 - 2s - loss: 191.9397 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "294/294 - 2s - loss: 488.9397 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "294/294 - 2s - loss: 1350.0521 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 69/100\n",
            "294/294 - 2s - loss: 2.2121 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 70/100\n",
            "294/294 - 1s - loss: 1211.5814 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "294/294 - 1s - loss: 77.7560 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "294/294 - 2s - loss: 532.6928 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "294/294 - 2s - loss: 1125.3610 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "294/294 - 1s - loss: 18.4744 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "294/294 - 2s - loss: 892.3975 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 76/100\n",
            "294/294 - 2s - loss: 457.6603 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 77/100\n",
            "294/294 - 2s - loss: 1245.6685 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "294/294 - 2s - loss: 0.2654 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "294/294 - 2s - loss: 1780.9534 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "294/294 - 2s - loss: 32.6871 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "294/294 - 1s - loss: 225.1548 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "294/294 - 1s - loss: 427.4960 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "294/294 - 2s - loss: 468.9714 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 84/100\n",
            "294/294 - 2s - loss: 1511.6877 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "294/294 - 2s - loss: 26.4276 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "294/294 - 1s - loss: 504.4176 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "294/294 - 2s - loss: 1024.8950 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "294/294 - 2s - loss: 116.5855 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "294/294 - 1s - loss: 608.1074 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "294/294 - 2s - loss: 1050.1287 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 91/100\n",
            "294/294 - 2s - loss: 147.0549 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "294/294 - 2s - loss: 523.8082 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "294/294 - 2s - loss: 738.9569 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "294/294 - 1s - loss: 231.1457 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "294/294 - 1s - loss: 937.3934 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "294/294 - 2s - loss: 104.2781 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "294/294 - 2s - loss: 613.0853 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 98/100\n",
            "294/294 - 2s - loss: 533.5510 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "294/294 - 1s - loss: 886.6767 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "294/294 - 2s - loss: 390.2953 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 1/100\n",
            "294/294 - 3s - loss: 32745652.0000 - acc: 0.9932 - val_loss: nan - val_acc: 1.0000 - 3s/epoch - 11ms/step\n",
            "Epoch 2/100\n",
            "294/294 - 1s - loss: 61.6658 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "294/294 - 1s - loss: 15.7750 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "294/294 - 2s - loss: 6.6890 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "294/294 - 2s - loss: 6.2578 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "294/294 - 2s - loss: 5.8487 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "294/294 - 1s - loss: 5.4480 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "294/294 - 2s - loss: 19.3759 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 9/100\n",
            "294/294 - 2s - loss: 17.7200 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "294/294 - 2s - loss: 46.5687 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "294/294 - 2s - loss: 41.7591 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "294/294 - 2s - loss: 64.4179 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "294/294 - 2s - loss: 149.1797 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "294/294 - 2s - loss: 31.4975 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "294/294 - 2s - loss: 253.8831 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "294/294 - 2s - loss: 55.1156 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "294/294 - 1s - loss: 91.1421 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "294/294 - 1s - loss: 180.3671 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "294/294 - 2s - loss: 180.1831 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "294/294 - 2s - loss: 143.6502 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "294/294 - 2s - loss: 186.9722 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "294/294 - 1s - loss: 142.4087 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "294/294 - 2s - loss: 148.9552 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 24/100\n",
            "294/294 - 2s - loss: 181.2495 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "294/294 - 1s - loss: 189.6802 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "294/294 - 1s - loss: 110.7554 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "294/294 - 1s - loss: 244.1321 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "294/294 - 1s - loss: 254.4093 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "294/294 - 2s - loss: 473.0663 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "294/294 - 2s - loss: 731.0443 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "294/294 - 2s - loss: 382.8964 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 32/100\n",
            "294/294 - 2s - loss: 490.1022 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "294/294 - 2s - loss: 1215.1941 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "294/294 - 1s - loss: 183.9295 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "294/294 - 2s - loss: 324.6418 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "294/294 - 1s - loss: 455.4005 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "294/294 - 2s - loss: 630.2125 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "294/294 - 2s - loss: 341.5250 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 39/100\n",
            "294/294 - 2s - loss: 502.0286 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "294/294 - 2s - loss: 442.4632 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "294/294 - 2s - loss: 697.6408 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "294/294 - 2s - loss: 133.6060 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "294/294 - 2s - loss: 728.0552 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "294/294 - 2s - loss: 377.4180 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "294/294 - 2s - loss: 719.1235 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 46/100\n",
            "294/294 - 2s - loss: 378.6454 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "294/294 - 2s - loss: 360.0612 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "294/294 - 1s - loss: 1994.2711 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "294/294 - 2s - loss: 0.3348 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "294/294 - 1s - loss: 53.5219 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "294/294 - 1s - loss: 1292.6354 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "294/294 - 2s - loss: 85.5182 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 53/100\n",
            "294/294 - 2s - loss: 218.9319 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 54/100\n",
            "294/294 - 2s - loss: 505.2318 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "294/294 - 2s - loss: 452.9395 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "294/294 - 2s - loss: 834.5668 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "294/294 - 1s - loss: 163.7735 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "294/294 - 1s - loss: 530.0265 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "294/294 - 2s - loss: 221.9529 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "294/294 - 2s - loss: 917.6321 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 61/100\n",
            "294/294 - 1s - loss: 482.8596 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "294/294 - 2s - loss: 147.0660 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "294/294 - 1s - loss: 362.7350 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "294/294 - 2s - loss: 597.3552 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "294/294 - 2s - loss: 172.7825 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "294/294 - 1s - loss: 693.9621 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "294/294 - 2s - loss: 559.5950 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 8ms/step\n",
            "Epoch 68/100\n",
            "294/294 - 1s - loss: 220.9312 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "294/294 - 2s - loss: 374.8822 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "294/294 - 2s - loss: 503.6480 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "294/294 - 2s - loss: 536.0805 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "294/294 - 2s - loss: 492.0203 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "294/294 - 1s - loss: 171.8355 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "294/294 - 2s - loss: 740.9547 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "294/294 - 2s - loss: 347.2332 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 76/100\n",
            "294/294 - 2s - loss: 1128.2317 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "294/294 - 2s - loss: 67.9034 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "294/294 - 1s - loss: 251.7888 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "294/294 - 2s - loss: 826.4142 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "294/294 - 1s - loss: 212.5776 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "294/294 - 1s - loss: 341.0703 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "294/294 - 2s - loss: 491.7633 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 83/100\n",
            "294/294 - 1s - loss: 560.0659 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "294/294 - 2s - loss: 114.6217 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "294/294 - 2s - loss: 621.5507 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 86/100\n",
            "294/294 - 2s - loss: 494.3960 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 87/100\n",
            "294/294 - 2s - loss: 332.7574 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "294/294 - 2s - loss: 428.5914 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 89/100\n",
            "294/294 - 2s - loss: 494.9160 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 90/100\n",
            "294/294 - 2s - loss: 821.5289 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "294/294 - 2s - loss: 211.7446 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "294/294 - 2s - loss: 345.7407 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "294/294 - 2s - loss: 144.2822 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "294/294 - 2s - loss: 508.8334 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "294/294 - 1s - loss: 349.1756 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "294/294 - 2s - loss: 996.0209 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 97/100\n",
            "294/294 - 1s - loss: 1070.2313 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "294/294 - 1s - loss: 323.8463 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "294/294 - 2s - loss: 73.4315 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "294/294 - 2s - loss: 1153.9706 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 1/100\n",
            "294/294 - 2s - loss: 38734648.0000 - acc: 0.9625 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "294/294 - 2s - loss: 31.6853 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "294/294 - 2s - loss: 6.6827 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "294/294 - 2s - loss: 6.4627 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "294/294 - 2s - loss: 6.2036 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "294/294 - 2s - loss: 5.9072 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "294/294 - 2s - loss: 5.5808 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 8/100\n",
            "294/294 - 2s - loss: 5.2385 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 9/100\n",
            "294/294 - 2s - loss: 4.8516 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "294/294 - 2s - loss: 4.4618 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "294/294 - 1s - loss: 4.0705 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "294/294 - 1s - loss: 3.6750 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "294/294 - 2s - loss: 3.3404 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "294/294 - 2s - loss: 43.2073 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "294/294 - 2s - loss: 2.5905 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "294/294 - 2s - loss: 33.2010 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "294/294 - 2s - loss: 127.7867 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "294/294 - 2s - loss: 174.2606 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "294/294 - 1s - loss: 7.2734 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "294/294 - 2s - loss: 166.1398 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "294/294 - 2s - loss: 102.0537 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "294/294 - 2s - loss: 208.0368 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "294/294 - 2s - loss: 252.1887 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 24/100\n",
            "294/294 - 2s - loss: 88.5190 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 25/100\n",
            "294/294 - 2s - loss: 578.1783 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 26/100\n",
            "294/294 - 2s - loss: 247.2404 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "294/294 - 2s - loss: 648.4465 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "294/294 - 2s - loss: 464.8151 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "294/294 - 1s - loss: 403.6140 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "294/294 - 2s - loss: 1178.9468 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 31/100\n",
            "294/294 - 1s - loss: 203.5750 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "294/294 - 2s - loss: 559.1843 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "294/294 - 1s - loss: 1464.3225 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "294/294 - 2s - loss: 192.6676 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "294/294 - 2s - loss: 612.8165 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "294/294 - 2s - loss: 522.4344 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "294/294 - 2s - loss: 571.4618 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "294/294 - 2s - loss: 818.0123 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "294/294 - 2s - loss: 551.0021 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "294/294 - 2s - loss: 665.9166 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "294/294 - 2s - loss: 717.2579 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "294/294 - 1s - loss: 2065.6975 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "294/294 - 1s - loss: 4.2508 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "294/294 - 2s - loss: 488.1257 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "294/294 - 2s - loss: 845.5870 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 46/100\n",
            "294/294 - 2s - loss: 510.1035 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "294/294 - 2s - loss: 456.0100 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "294/294 - 2s - loss: 722.3995 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "294/294 - 2s - loss: 1164.2625 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 50/100\n",
            "294/294 - 2s - loss: 145.3902 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "294/294 - 2s - loss: 688.5955 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 52/100\n",
            "294/294 - 2s - loss: 356.3011 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "294/294 - 2s - loss: 1044.5612 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "294/294 - 2s - loss: 523.7690 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "294/294 - 1s - loss: 878.6713 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "294/294 - 2s - loss: 258.9088 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "294/294 - 1s - loss: 996.0015 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "294/294 - 2s - loss: 512.3807 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "294/294 - 2s - loss: 1954.8987 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "294/294 - 2s - loss: 1.4182 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "294/294 - 1s - loss: 258.1111 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "294/294 - 2s - loss: 933.7192 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "294/294 - 2s - loss: 83.0815 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "294/294 - 1s - loss: 1108.5797 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "294/294 - 2s - loss: 438.0516 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "294/294 - 2s - loss: 613.0715 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 67/100\n",
            "294/294 - 1s - loss: 846.5816 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "294/294 - 1s - loss: 835.8032 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "294/294 - 2s - loss: 34.0630 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "294/294 - 1s - loss: 574.5125 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "294/294 - 2s - loss: 566.2414 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "294/294 - 2s - loss: 740.1389 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "294/294 - 2s - loss: 882.0089 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 74/100\n",
            "294/294 - 2s - loss: 301.4171 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "294/294 - 2s - loss: 676.3291 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "294/294 - 2s - loss: 669.6422 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "294/294 - 2s - loss: 535.3663 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "294/294 - 2s - loss: 618.3506 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "294/294 - 2s - loss: 938.3385 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 80/100\n",
            "294/294 - 2s - loss: 293.2801 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 81/100\n",
            "294/294 - 2s - loss: 942.1984 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "294/294 - 1s - loss: 345.1757 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "294/294 - 1s - loss: 429.2249 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "294/294 - 2s - loss: 616.9773 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 85/100\n",
            "294/294 - 2s - loss: 743.2143 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "294/294 - 2s - loss: 829.3945 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 87/100\n",
            "294/294 - 2s - loss: 145.3945 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 88/100\n",
            "294/294 - 2s - loss: 764.8670 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "294/294 - 2s - loss: 889.0618 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "294/294 - 2s - loss: 214.0539 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "294/294 - 2s - loss: 1090.7067 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "294/294 - 2s - loss: 150.3061 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "294/294 - 2s - loss: 960.2204 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "294/294 - 2s - loss: 840.2428 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "294/294 - 1s - loss: 180.3372 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "294/294 - 1s - loss: 417.2265 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "294/294 - 1s - loss: 1584.3676 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "294/294 - 2s - loss: 5.1002 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "294/294 - 2s - loss: 1590.1383 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "294/294 - 2s - loss: 2.6670 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 1/100\n",
            "294/294 - 2s - loss: 33544238.0000 - acc: 0.9966 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "294/294 - 2s - loss: 110.4553 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "294/294 - 1s - loss: 11.1006 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "294/294 - 1s - loss: 125.0522 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "294/294 - 2s - loss: 24.8694 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "294/294 - 2s - loss: 7.9015 - acc: 0.9999 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "294/294 - 2s - loss: 33.1136 - acc: 0.9999 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 8/100\n",
            "294/294 - 1s - loss: 55.8951 - acc: 0.9999 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "294/294 - 2s - loss: 33.8507 - acc: 0.9999 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "294/294 - 2s - loss: 34.1287 - acc: 0.9999 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "294/294 - 2s - loss: 98.2140 - acc: 0.9999 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "294/294 - 2s - loss: 66.0869 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "294/294 - 1s - loss: 68.7262 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "294/294 - 2s - loss: 123.8352 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 15/100\n",
            "294/294 - 2s - loss: 101.0225 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "294/294 - 2s - loss: 27.7137 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "294/294 - 2s - loss: 94.0243 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "294/294 - 2s - loss: 171.3483 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "294/294 - 2s - loss: 108.4671 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "294/294 - 1s - loss: 51.6155 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "294/294 - 2s - loss: 113.4316 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 22/100\n",
            "294/294 - 2s - loss: 143.7167 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "294/294 - 1s - loss: 54.8253 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "294/294 - 2s - loss: 247.6346 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "294/294 - 2s - loss: 66.3149 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "294/294 - 2s - loss: 101.2638 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "294/294 - 2s - loss: 279.6873 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "294/294 - 2s - loss: 23.2896 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 29/100\n",
            "294/294 - 1s - loss: 158.0211 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "294/294 - 2s - loss: 356.5312 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "294/294 - 2s - loss: 553.2680 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "294/294 - 2s - loss: 348.2289 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "294/294 - 2s - loss: 745.6901 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "294/294 - 2s - loss: 127.7233 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "294/294 - 2s - loss: 639.9755 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "294/294 - 2s - loss: 234.8462 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "294/294 - 2s - loss: 425.9672 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "294/294 - 2s - loss: 517.8798 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "294/294 - 1s - loss: 308.1628 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "294/294 - 2s - loss: 408.0785 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "294/294 - 1s - loss: 322.9729 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "294/294 - 2s - loss: 466.4665 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 43/100\n",
            "294/294 - 1s - loss: 467.1401 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "294/294 - 1s - loss: 411.0709 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "294/294 - 2s - loss: 453.9821 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "294/294 - 2s - loss: 319.4230 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "294/294 - 2s - loss: 305.9005 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "294/294 - 2s - loss: 544.7243 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "294/294 - 2s - loss: 356.0216 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 50/100\n",
            "294/294 - 2s - loss: 233.8018 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 51/100\n",
            "294/294 - 1s - loss: 541.0262 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "294/294 - 2s - loss: 519.0034 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "294/294 - 1s - loss: 442.7679 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "294/294 - 2s - loss: 372.6909 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "294/294 - 1s - loss: 276.1384 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "294/294 - 2s - loss: 452.2871 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "294/294 - 2s - loss: 449.0875 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "294/294 - 2s - loss: 421.8183 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "294/294 - 1s - loss: 480.1328 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "294/294 - 2s - loss: 427.5241 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "294/294 - 2s - loss: 332.9366 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "294/294 - 2s - loss: 333.0891 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "294/294 - 2s - loss: 949.0848 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "294/294 - 2s - loss: 45.7418 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "294/294 - 2s - loss: 766.7066 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "294/294 - 1s - loss: 373.2512 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "294/294 - 2s - loss: 14.3366 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "294/294 - 2s - loss: 523.0500 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "294/294 - 1s - loss: 360.3210 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "294/294 - 2s - loss: 409.8473 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 71/100\n",
            "294/294 - 2s - loss: 346.7156 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "294/294 - 2s - loss: 303.0255 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "294/294 - 2s - loss: 501.2843 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "294/294 - 2s - loss: 226.5831 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 75/100\n",
            "294/294 - 2s - loss: 429.3258 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "294/294 - 2s - loss: 668.2652 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "294/294 - 2s - loss: 295.5698 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 78/100\n",
            "294/294 - 2s - loss: 206.3651 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "294/294 - 1s - loss: 457.1207 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "294/294 - 2s - loss: 438.5416 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "294/294 - 1s - loss: 239.0385 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "294/294 - 1s - loss: 425.7550 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "294/294 - 2s - loss: 259.2159 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "294/294 - 2s - loss: 491.3594 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 85/100\n",
            "294/294 - 2s - loss: 696.6392 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "294/294 - 2s - loss: 165.4406 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "294/294 - 2s - loss: 145.0831 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "294/294 - 1s - loss: 296.4101 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "294/294 - 1s - loss: 933.6042 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "294/294 - 2s - loss: 106.6085 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "294/294 - 2s - loss: 211.1312 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 92/100\n",
            "294/294 - 2s - loss: 558.2875 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "294/294 - 2s - loss: 329.5085 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "294/294 - 2s - loss: 412.1741 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 95/100\n",
            "294/294 - 2s - loss: 157.7041 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "294/294 - 2s - loss: 554.3112 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "294/294 - 2s - loss: 320.7810 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "294/294 - 2s - loss: 317.8558 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "294/294 - 2s - loss: 366.9072 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "294/294 - 2s - loss: 336.5844 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 1/100\n",
            "294/294 - 2s - loss: 26170094.0000 - acc: 0.9829 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "294/294 - 1s - loss: 5.6117 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "294/294 - 2s - loss: 39.8080 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 4/100\n",
            "294/294 - 2s - loss: 11.2243 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "294/294 - 2s - loss: 9.1712 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 6/100\n",
            "294/294 - 2s - loss: 23.0667 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "294/294 - 2s - loss: 19.3938 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "294/294 - 2s - loss: 26.6180 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "294/294 - 2s - loss: 41.8813 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "294/294 - 2s - loss: 3.6192 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "294/294 - 2s - loss: 23.6237 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "294/294 - 2s - loss: 23.4602 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "294/294 - 2s - loss: 34.5751 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "294/294 - 2s - loss: 68.1170 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "294/294 - 2s - loss: 46.9601 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "294/294 - 2s - loss: 106.9980 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "294/294 - 1s - loss: 108.4896 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "294/294 - 2s - loss: 235.5993 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "294/294 - 2s - loss: 80.6612 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 20/100\n",
            "294/294 - 2s - loss: 182.0458 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "294/294 - 2s - loss: 189.0382 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "294/294 - 2s - loss: 320.5081 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "294/294 - 2s - loss: 360.7557 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 24/100\n",
            "294/294 - 2s - loss: 246.9724 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "294/294 - 2s - loss: 206.7111 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 26/100\n",
            "294/294 - 2s - loss: 900.6918 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 27/100\n",
            "294/294 - 2s - loss: 2.8741 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "294/294 - 1s - loss: 375.4260 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "294/294 - 1s - loss: 530.4930 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "294/294 - 1s - loss: 839.1854 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "294/294 - 2s - loss: 859.2533 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "294/294 - 2s - loss: 295.3747 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 33/100\n",
            "294/294 - 2s - loss: 624.9800 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 34/100\n",
            "294/294 - 1s - loss: 878.3184 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "294/294 - 2s - loss: 446.7378 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 36/100\n",
            "294/294 - 2s - loss: 879.5917 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "294/294 - 2s - loss: 468.0533 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "294/294 - 1s - loss: 741.5182 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "294/294 - 2s - loss: 681.3990 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "294/294 - 2s - loss: 709.5210 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "294/294 - 1s - loss: 792.5400 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "294/294 - 2s - loss: 1048.5591 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "294/294 - 1s - loss: 453.3757 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "294/294 - 2s - loss: 662.0002 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "294/294 - 2s - loss: 730.0915 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "294/294 - 2s - loss: 554.5667 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 47/100\n",
            "294/294 - 2s - loss: 760.7760 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "294/294 - 2s - loss: 960.6347 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "294/294 - 1s - loss: 665.5451 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "294/294 - 2s - loss: 184.6279 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 51/100\n",
            "294/294 - 2s - loss: 604.4247 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 52/100\n",
            "294/294 - 2s - loss: 659.1450 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "294/294 - 2s - loss: 720.8648 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 54/100\n",
            "294/294 - 2s - loss: 597.7654 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "294/294 - 1s - loss: 450.5840 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "294/294 - 2s - loss: 1213.1576 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "294/294 - 1s - loss: 889.9943 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "294/294 - 2s - loss: 362.8843 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "294/294 - 1s - loss: 265.1223 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "294/294 - 2s - loss: 757.2513 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 61/100\n",
            "294/294 - 2s - loss: 354.3685 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 62/100\n",
            "294/294 - 2s - loss: 1304.0573 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "294/294 - 2s - loss: 555.6050 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "294/294 - 2s - loss: 232.1980 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "294/294 - 2s - loss: 665.4378 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "294/294 - 2s - loss: 1716.0427 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 67/100\n",
            "294/294 - 2s - loss: 116.8021 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "294/294 - 2s - loss: 336.4473 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "294/294 - 2s - loss: 1128.4574 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "294/294 - 2s - loss: 241.0854 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "294/294 - 2s - loss: 263.8849 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "294/294 - 2s - loss: 829.5002 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "294/294 - 2s - loss: 830.4515 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 74/100\n",
            "294/294 - 2s - loss: 421.3456 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 75/100\n",
            "294/294 - 1s - loss: 1204.3120 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "294/294 - 2s - loss: 189.9065 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "294/294 - 2s - loss: 334.1321 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "294/294 - 2s - loss: 933.2061 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "294/294 - 2s - loss: 533.0757 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "294/294 - 1s - loss: 359.2635 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "294/294 - 2s - loss: 568.1479 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 82/100\n",
            "294/294 - 2s - loss: 579.1027 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 83/100\n",
            "294/294 - 2s - loss: 531.0479 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "294/294 - 2s - loss: 689.5215 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "294/294 - 1s - loss: 304.5977 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "294/294 - 2s - loss: 845.4537 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 87/100\n",
            "294/294 - 2s - loss: 720.9432 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 88/100\n",
            "294/294 - 2s - loss: 210.0443 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 89/100\n",
            "294/294 - 1s - loss: 564.9105 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "294/294 - 2s - loss: 550.1135 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "294/294 - 2s - loss: 603.8306 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "294/294 - 1s - loss: 338.6542 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "294/294 - 2s - loss: 1685.7158 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "294/294 - 2s - loss: 43.6547 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 95/100\n",
            "294/294 - 2s - loss: 1611.7699 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 7ms/step\n",
            "Epoch 96/100\n",
            "294/294 - 2s - loss: 7.2797 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 6ms/step\n",
            "Epoch 97/100\n",
            "294/294 - 2s - loss: 1154.8549 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "294/294 - 2s - loss: 245.7620 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "294/294 - 1s - loss: 438.2632 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 1s/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "294/294 - 2s - loss: 416.8091 - acc: 1.0000 - val_loss: nan - val_acc: 1.0000 - 2s/epoch - 5ms/step\n"
          ]
        }
      ]
    }
  ]
}